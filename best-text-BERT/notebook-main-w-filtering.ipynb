{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: TITAN X (Pascal)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from bunch import Bunch\n",
    "from pytorch_transformers import BertTokenizer, BertModel, WarmupLinearSchedule, AdamW\n",
    "from dataset import TrainTRECDataset, TestTRECDataset\n",
    "from model import TRECCARModel\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "CONFIG_FILE = \"config.json\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acoustic-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_from_json(json_file):\n",
    "    \"\"\"\n",
    "        Get the config from a json file\n",
    "        :param json_file:\n",
    "        :return: config(namespace) or config(dictionary)\n",
    "        \"\"\"\n",
    "    # parse the configurations from the config json file provided\n",
    "    with open(json_file, 'r') as config_file:\n",
    "        config_dict = json.load(config_file)\n",
    "\n",
    "    # convert the dictionary to a namespace using bunch lib\n",
    "    config = Bunch(config_dict)\n",
    "\n",
    "    return config, config_dict\n",
    "\n",
    "\n",
    "def format_time(elapsed_time):\n",
    "    \"\"\"\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    \"\"\"\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed_time)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resistant-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../pretrained_download_dir/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches :  1\n"
     ]
    }
   ],
   "source": [
    "config, _ = get_config_from_json(CONFIG_FILE)\n",
    "seed_val = config.cmd_args['seed']\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "os.makedirs(config.data['results_dir'], exist_ok=True)\n",
    "\n",
    "# Loading Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(config[\"bert_token_file\"], cache_dir=config.data['pretrained_download_dir'])\n",
    "dataset = TrainTRECDataset(config.data['train_data'], config, is_train=True, bert_tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(dataset=dataset,\n",
    "                              batch_size=config.training[\"train_batch_size\"],\n",
    "                              pin_memory=config.cmd_args['device'] == 'cuda:0',\n",
    "                              num_workers=config.training['num_workers'],\n",
    "                              shuffle=True)\n",
    "n_train_batches = len(train_dataloader)\n",
    "print(\"Number of train batches : \", n_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "major-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../pretrained_download_dir/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../pretrained_download_dir/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    }
   ],
   "source": [
    "# Creating instance of BertModel\n",
    "net = TRECCARModel(config, freeze_bert=True)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.MarginRankingLoss(margin=1, size_average=True)\n",
    "opti = AdamW(net.parameters(),\n",
    "             lr=2e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "             eps=1e-8,  # args.adam_epsilon  - default is 1e-8.\n",
    "             correct_bias=False\n",
    "             )\n",
    "# opti = optim.Adam(net.parameters(), lr=2e-5)\n",
    "\n",
    "# no_decay = ['bias', 'LayerNorm.weight']\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {'params': [p for n, p in net.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "#     {'params': [p for n, p in net.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "# ]\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generic-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = config.training['epochs']\n",
    "display_step = config['training']['display_step']\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(opti,\n",
    "                                            num_warmup_steps=0,  # Default value in run_glue.py\n",
    "                                            num_training_steps=total_steps)\n",
    "# scheduler = WarmupLinearSchedule(opti, warmup_steps=config.training[\"warmup_proportion\"],\n",
    "#                                  t_total=config.training[\"total_training_steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "august-banks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./exp2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.data['results_dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "significant-combat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ...\n",
      "Training...\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/raid6/home/ramraj/2021/ir/entity-reranking/best-text-BERT/dataset.py\", line 152, in __getitem__\n    negInst = self.data_df[self.data_df['qID'] != qID].sample(n=3, replace=True, random_state=1).iloc[0]\n  File \"/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/pandas/core/generic.py\", line 5350, in sample\n    locs = rs.choice(axis_length, size=n, replace=replace, p=weights)\n  File \"mtrand.pyx\", line 903, in numpy.random.mtrand.RandomState.choice\nValueError: a must be greater than 0 unless no samples are taken\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-86e1cfbffcba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: IMPORTANT !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Clear gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: check validity !\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/raid6/home/ramraj/2021/ir/entity-reranking/best-text-BERT/dataset.py\", line 152, in __getitem__\n    negInst = self.data_df[self.data_df['qID'] != qID].sample(n=3, replace=True, random_state=1).iloc[0]\n  File \"/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/pandas/core/generic.py\", line 5350, in sample\n    locs = rs.choice(axis_length, size=n, replace=replace, p=weights)\n  File \"mtrand.pyx\", line 903, in numpy.random.mtrand.RandomState.choice\nValueError: a must be greater than 0 unless no samples are taken\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_stats = []\n",
    "history = defaultdict(list)\n",
    "\n",
    "resume_epoch = 0\n",
    "print_every = 1 # 10\n",
    "save_every = 200 # 1000\n",
    "\n",
    "print('Initializing ...')\n",
    "print(\"Training...\")\n",
    "\n",
    "total_t0 = time.time()\n",
    "for epoch_idx in range(resume_epoch, num_epochs):\n",
    "    total_loss = 0\n",
    "    total_score = 0\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_idx + 1, num_epochs))\n",
    "    print('Training...')\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    net.train()  # TODO: IMPORTANT !\n",
    "    for batch_idx, train_batch_data in enumerate(train_dataloader):\n",
    "        # Clear gradients\n",
    "        net.zero_grad()  # TODO: check validity !\n",
    "        opti.zero_grad()\n",
    "\n",
    "        # Converting these to cuda tensors\n",
    "        pos_ids, pos_mask, pos_type_ids, \\\n",
    "        neg_ids, neg_mask, neg_type_ids, \\\n",
    "        seqA_len, posSeqB_len, negSeqB_len, \\\n",
    "        label = train_batch_data\n",
    "\n",
    "        pos_ids, pos_mask, pos_type_ids, \\\n",
    "        neg_ids, neg_mask, neg_type_ids, \\\n",
    "        seqA_len, posSeqB_len, negSeqB_len, \\\n",
    "        label = pos_ids.to(device), pos_mask.to(device), pos_type_ids.to(device), \\\n",
    "                neg_ids.to(device), neg_mask.to(device), neg_type_ids.to(device), \\\n",
    "                seqA_len.to(device), posSeqB_len.to(device), negSeqB_len.to(device), \\\n",
    "                label.to(device)\n",
    "\n",
    "        pos_net_output = net(pos_ids, attn_masks=pos_mask, type_ids=pos_type_ids)\n",
    "        neg_net_output = net(neg_ids, attn_masks=neg_mask, type_ids=neg_type_ids)\n",
    "        # # TODO: do i need a softmax or not ?\n",
    "\n",
    "        # Computing loss\n",
    "        # loss = criterion(net_output, label.float())\n",
    "        loss = criterion(pos_net_output, neg_net_output, label.float())\n",
    "        batch_loss = loss.item()\n",
    "        # total_train_loss += loss.item()\n",
    "\n",
    "        # Back propagating the gradients\n",
    "        loss.backward()\n",
    "        if config.training['gradient_clipping']['use']:\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), config.training['gradient_clipping']['clip_value'])\n",
    "\n",
    "        # Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        # Progress update every display_step batches.\n",
    "        # if batch_idx % display_step == 0 and not batch_idx == 0:\n",
    "        #     elapsed = format_time(time.time() - t0)\n",
    "        #     # print('  Batch {:>5,}  of  {:>5,}  :  loss - {:>5,.2f}    Elapsed: {:}.'.format(batch_idx,\n",
    "        #     #                                                                                 len(train_dataloader),\n",
    "        #     #                                                                                 loss, elapsed))\n",
    "        #     print('  Epoch {:>5,}  of  {:>5,}  :  Batch {:>5,}  of  {:>5,}  :  \\\n",
    "        #     loss - {:>5,.2f}    Elapsed: {:}.'.format(epoch_idx + 1, num_epochs,\n",
    "        #                                               batch_idx + 1, len(train_dataloader),\n",
    "        #                                               loss, elapsed))\n",
    "        #     training_stats.append(\n",
    "        #         {\n",
    "        #             'epoch': epoch_idx + 1,\n",
    "        #             'batch': batch_idx + 1,\n",
    "        #             'step': (epoch_idx * n_train_batches) + batch_idx + 1,\n",
    "        #             'Training Loss': loss,\n",
    "        #             # 'Training Loss': avg_train_loss,\n",
    "        #             # 'Training Time': training_time,\n",
    "        #         }\n",
    "        #     )\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        with open(os.path.join(config.data['results_dir'], 'train-log-epoch.txt' ), 'a') as f:\n",
    "                f.write(str(batch_idx+1) + '\\t' + str(batch_idx+1) + '\\t' + str(batch_loss) + '\\t' + '\\n')\n",
    "        # writer.add_scalar('training loss', loss.item(), epoch * n_train_batches + batch_idx)\n",
    "        # writer.add_scalar('training score', batch_score, epoch * n_train_batches + batch_idx)\n",
    "\n",
    "        training_stats.append(\n",
    "                {\n",
    "                    'epoch': epoch_idx + 1,\n",
    "                    'batch': batch_idx + 1,\n",
    "                    'step': (epoch_idx * n_train_batches) + batch_idx + 1,\n",
    "                    'Training Loss': batch_loss,\n",
    "                    # 'Training Loss': avg_train_loss,\n",
    "                    # 'Training Time': training_time,\n",
    "                }\n",
    "            )\n",
    "                \n",
    "        if batch_idx % print_every == 0: # Print progress\n",
    "            total_loss_avg = total_loss / print_every \n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('| TRAIN SET | Epoch [{:02d}/{:02d}], Step [{:04d}/{:04d}], Loss: {:.4f} | Elapsed: {:}'\n",
    "                          .format(epoch_idx+1, num_epochs, batch_idx, int(n_train_batches), total_loss_avg, elapsed))\n",
    "            total_loss = 0              \n",
    "        \n",
    "        if ( (batch_idx == n_train_batches-1) or ((batch_idx+1) % save_every == 0) ): # Save checkpoint\n",
    "            directory = os.path.join(config.data['results_dir'], 'ranking-pytorch-model')\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save(net.state_dict(),\n",
    "                       os.path.join(directory, 'epoch-{}.batch-{}.{}.pt'.format(epoch_idx+1, batch_idx+1, 'checkpoint')))\n",
    "\n",
    "\n",
    "    scheduler.step()  # TODO: IMPORTANT !\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "history_df = pd.DataFrame({\"step\": [e['step'] for e in training_stats],\n",
    "                           \"Training Loss\": [e['Training Loss'] for e in training_stats]})\n",
    "# history_df.to_csv(os.path.join(config.data['results_dir'], \"history.csv\"), index=False)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "\n",
    "if not config.cmd_args['mode'] == \"experiment\":\n",
    "    torch.save(net, os.path.join(config.data['results_dir'], \"model-dump.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_csv(os.path.join(config.data['results_dir'], \"history.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dimensional-titanium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history_df = pd.DataFrame({\"step\": [e['step'] for e in training_stats],\n",
    "#                            \"Training Loss\": [e['Training Loss'].cpu() for e in training_stats]})\n",
    "# # history_df.to_csv(os.path.join(config.data['results_dir'], \"history.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "\n",
    "if not config.cmd_args['mode'] == \"experiment\":\n",
    "    torch.save(net, os.path.join(config.data['results_dir'], \"model-dump.pkl\"))\n",
    "# ========================================\n",
    "#               NOT Validation, Just Testing\n",
    "# ========================================\n",
    "print(\"\")\n",
    "print(\"Validation...\")\n",
    "t0 = time.time()\n",
    "\n",
    "test_dataset = TestTRECDataset(config.data['test_data'], config, is_train=False, bert_tokenizer=tokenizer)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=config.training[\"test_batch_size\"],\n",
    "                             pin_memory=config.cmd_args['device'] == 'cuda',\n",
    "                             num_workers=config.training['num_workers'],\n",
    "                             shuffle=True)\n",
    "n_test_batches = len(test_dataloader)\n",
    "print(\"Number of test batches : \", n_test_batches, \"\\n\")\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-creativity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qID_list = []\n",
    "paraID_list = []\n",
    "pScore_list = []\n",
    "t1 = time.time()\n",
    "for batch_idx, test_batch_data in enumerate(test_dataloader):\n",
    "    # Converting these to cuda tensors\n",
    "    input_seq, input_mask, input_type_ids, label, qID, passageID, seqA_len, seqB_len = test_batch_data\n",
    "    input_seq, input_mask, input_type_ids, \\\n",
    "    seqA_len, seqB_len = input_seq.to(device), input_mask.to(device), input_type_ids.to(device), \\\n",
    "                         seqA_len.to(device), seqB_len.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net_output = net(input_seq, attn_masks=input_mask, type_ids=input_type_ids)\n",
    "        net_output = net_output.detach().cpu().numpy()\n",
    "\n",
    "        for i in range(len(qID)):\n",
    "            qID_list.append(qID[i])\n",
    "            paraID_list.append(passageID[i])\n",
    "            pScore_list.append(net_output[i])\n",
    "    elapsed = format_time(time.time() - t1)\n",
    "    \n",
    "    if batch_idx % 50 == 0:\n",
    "        print('  Batch {:>5,}  of  {:>5,}  :  processed    Elapsed: {:}.'.format(batch_idx,\n",
    "                                                                             n_test_batches,\n",
    "                                                                             elapsed))\n",
    "\n",
    "pScore_list = [float(e) for e in pScore_list]\n",
    "predicted_df = pd.DataFrame({\"qID\": qID_list,\n",
    "                             \"pID\": paraID_list,\n",
    "                             \"pScore\": pScore_list}, columns=[\"qID\", \"pID\", \"pScore\"])\n",
    "if not config.cmd_args['mode'] == \"experiment\":\n",
    "    predicted_df.to_csv(os.path.join(config.data['results_dir'], \"predictions.csv\"))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "#               Reverse Sorting Relevance\n",
    "# ================================================\n",
    "predicted_df = predicted_df[['qID', 'pID', 'pScore']]\n",
    "grouped_pred_df = predicted_df.groupby([\"qID\"])\n",
    "num_queries = len(grouped_pred_df)\n",
    "missing_q_sets = 0\n",
    "save_ranked_file = os.path.join(config.data['results_dir'], \"ranked.test.relevance.txt\")\n",
    "with open(save_ranked_file, 'w') as write_file:\n",
    "    q_cnt = 1\n",
    "    for name, row_group in grouped_pred_df:\n",
    "        rank_cnt = 1\n",
    "\n",
    "        # ======= SORTING =======\n",
    "        sorted_row_group = row_group.sort_values(by='pScore', ascending=False, inplace=False)\n",
    "        # =======================\n",
    "\n",
    "        if len(sorted_row_group) != 100:\n",
    "            # print(\">>>>>>>>>>> Missing query %s with shape %s\" % (name, sorted_row_group.shape))\n",
    "            # print(\">>>>>>>>>>> Missing query with size %s\" % sorted_row_group.shape[0])\n",
    "            missing_q_sets += 1\n",
    "\n",
    "        for i, row in sorted_row_group.iterrows():\n",
    "            write_file.write(\"%s\\tQ0\\t%s\\t%s\\t%s\\trchan31\\n\" % \\\n",
    "                             (row[\"qID\"], row[\"pID\"], rank_cnt, row[\"pScore\"]))\n",
    "            rank_cnt += 1\n",
    "\n",
    "        if q_cnt % 100 == 0: print(\"Finished composing for query number : %s / %s\" % (q_cnt, num_queries))\n",
    "        q_cnt += 1\n",
    "print()\n",
    "print(\"Missing query-doc pairs : \", missing_q_sets)\n",
    "print(\"Done train, val, and test !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ready-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranked.test.relevance.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amazing-proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\tcbf3d5427fd8d7956c027fddd46e14b3779aa94b\t96\t2.5369160175323486\trchan31\r\n",
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\te2d8413a1f00b1a8c29bea03766fbd7bb5d7b309\t97\t2.5269246101379395\trchan31\r\n",
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\t97596ad40e87e4528aac5f7b22005884819853d1\t98\t2.51876163482666\trchan31\r\n",
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\t8b3652a6bc32fb5b9a0b8efebb02f5609a43d075\t99\t2.4430224895477295\trchan31\r\n",
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\tc13cea34c7beba80a6026cc1721a1bad12e77497\t100\t2.0023608207702637\trchan31\r\n"
     ]
    }
   ],
   "source": [
    "! tail -5 exp1/ranked.test.relevance.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stopped-injection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatic-test.pages.cbor-hierarchical.qrels\r\n",
      "lenient.benchmarkY1test.cbor.hierarchical.qrels\r\n",
      "manual.benchmarkY1test.cbor.hierarchical.qrels\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../Eval/qrelsY1-test.V2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "oriental-survey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\trchan31\r\n",
      "num_q                 \tall\t2254\r\n",
      "num_ret               \tall\t225156\r\n",
      "num_rel               \tall\t6192\r\n",
      "num_rel_ret           \tall\t2375\r\n",
      "map                   \tall\t0.0935\r\n",
      "gm_map                \tall\t0.0034\r\n",
      "Rprec                 \tall\t0.0572\r\n",
      "bpref                 \tall\t0.4689\r\n",
      "recip_rank            \tall\t0.1524\r\n",
      "iprec_at_recall_0.00  \tall\t0.1565\r\n",
      "iprec_at_recall_0.10  \tall\t0.1562\r\n",
      "iprec_at_recall_0.20  \tall\t0.1461\r\n",
      "iprec_at_recall_0.30  \tall\t0.1229\r\n",
      "iprec_at_recall_0.40  \tall\t0.0981\r\n",
      "iprec_at_recall_0.50  \tall\t0.0941\r\n",
      "iprec_at_recall_0.60  \tall\t0.0684\r\n",
      "iprec_at_recall_0.70  \tall\t0.0665\r\n",
      "iprec_at_recall_0.80  \tall\t0.0591\r\n",
      "iprec_at_recall_0.90  \tall\t0.0585\r\n",
      "iprec_at_recall_1.00  \tall\t0.0585\r\n",
      "P_5                   \tall\t0.0491\r\n",
      "P_10                  \tall\t0.0388\r\n",
      "P_15                  \tall\t0.0331\r\n",
      "P_20                  \tall\t0.0290\r\n",
      "P_30                  \tall\t0.0234\r\n",
      "P_100                 \tall\t0.0105\r\n",
      "P_200                 \tall\t0.0053\r\n",
      "P_500                 \tall\t0.0021\r\n",
      "P_1000                \tall\t0.0011\r\n"
     ]
    }
   ],
   "source": [
    "! ../Eval/trec_eval-master/trec_eval ../Eval/qrelsY1-test.V2.0/automatic-test.pages.cbor-hierarchical.qrels exp1/ranked.test.relevance.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-accessory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
