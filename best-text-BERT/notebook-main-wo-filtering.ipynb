{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moved-obligation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: TITAN X (Pascal)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from bunch import Bunch\n",
    "from pytorch_transformers import BertTokenizer, BertModel, WarmupLinearSchedule, AdamW\n",
    "from dataset import TrainTRECDataset, TestTRECDataset\n",
    "from model import TRECCARModel\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "CONFIG_FILE = \"config.json\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acoustic-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_from_json(json_file):\n",
    "    \"\"\"\n",
    "        Get the config from a json file\n",
    "        :param json_file:\n",
    "        :return: config(namespace) or config(dictionary)\n",
    "        \"\"\"\n",
    "    # parse the configurations from the config json file provided\n",
    "    with open(json_file, 'r') as config_file:\n",
    "        config_dict = json.load(config_file)\n",
    "\n",
    "    # convert the dictionary to a namespace using bunch lib\n",
    "    config = Bunch(config_dict)\n",
    "\n",
    "    return config, config_dict\n",
    "\n",
    "\n",
    "def format_time(elapsed_time):\n",
    "    \"\"\"\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    \"\"\"\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed_time)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "resistant-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../pretrained_download_dir/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train batches :  304\n"
     ]
    }
   ],
   "source": [
    "config, _ = get_config_from_json(CONFIG_FILE)\n",
    "seed_val = config.cmd_args['seed']\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "os.makedirs(config.data['results_dir'], exist_ok=True)\n",
    "\n",
    "# Loading Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(config[\"bert_token_file\"], cache_dir=config.data['pretrained_download_dir'])\n",
    "dataset = TrainTRECDataset(config.data['train_data'], config, is_train=True, bert_tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(dataset=dataset,\n",
    "                              batch_size=config.training[\"train_batch_size\"],\n",
    "                              pin_memory=config.cmd_args['device'] == 'cuda:0',\n",
    "                              num_workers=config.training['num_workers'],\n",
    "                              shuffle=True)\n",
    "n_train_batches = len(train_dataloader)\n",
    "print(\"Number of train batches : \", n_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "major-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../pretrained_download_dir/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:pytorch_transformers.modeling_utils:Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../pretrained_download_dir/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    }
   ],
   "source": [
    "# Creating instance of BertModel\n",
    "net = TRECCARModel(config, freeze_bert=True)\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.MarginRankingLoss(margin=1, size_average=True)\n",
    "opti = AdamW(net.parameters(),\n",
    "             lr=2e-5,  # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "             eps=1e-8,  # args.adam_epsilon  - default is 1e-8.\n",
    "             correct_bias=False\n",
    "             )\n",
    "# opti = optim.Adam(net.parameters(), lr=2e-5)\n",
    "\n",
    "# no_decay = ['bias', 'LayerNorm.weight']\n",
    "# optimizer_grouped_parameters = [\n",
    "#     {'params': [p for n, p in net.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "#     {'params': [p for n, p in net.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "# ]\n",
    "# optimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generic-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = config.training['epochs']\n",
    "display_step = config['training']['display_step']\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(opti,\n",
    "                                            num_warmup_steps=0,  # Default value in run_glue.py\n",
    "                                            num_training_steps=total_steps)\n",
    "# scheduler = WarmupLinearSchedule(opti, warmup_steps=config.training[\"warmup_proportion\"],\n",
    "#                                  t_total=config.training[\"total_training_steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "significant-combat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ...\n",
      "Training...\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "| TRAIN SET | Epoch [01/04], Step [0000/0304], Loss: 2.3199 | Elapsed: 0:00:01\n",
      "| TRAIN SET | Epoch [01/04], Step [0001/0304], Loss: 2.0638 | Elapsed: 0:00:02\n",
      "| TRAIN SET | Epoch [01/04], Step [0002/0304], Loss: 2.1354 | Elapsed: 0:00:02\n",
      "| TRAIN SET | Epoch [01/04], Step [0003/0304], Loss: 1.9477 | Elapsed: 0:00:03\n",
      "| TRAIN SET | Epoch [01/04], Step [0004/0304], Loss: 1.9275 | Elapsed: 0:00:04\n",
      "| TRAIN SET | Epoch [01/04], Step [0005/0304], Loss: 1.7575 | Elapsed: 0:00:04\n",
      "| TRAIN SET | Epoch [01/04], Step [0006/0304], Loss: 1.5643 | Elapsed: 0:00:05\n",
      "| TRAIN SET | Epoch [01/04], Step [0007/0304], Loss: 1.5344 | Elapsed: 0:00:05\n",
      "| TRAIN SET | Epoch [01/04], Step [0008/0304], Loss: 1.4798 | Elapsed: 0:00:06\n",
      "| TRAIN SET | Epoch [01/04], Step [0009/0304], Loss: 1.2445 | Elapsed: 0:00:07\n",
      "| TRAIN SET | Epoch [01/04], Step [0010/0304], Loss: 1.1231 | Elapsed: 0:00:07\n",
      "| TRAIN SET | Epoch [01/04], Step [0011/0304], Loss: 1.0213 | Elapsed: 0:00:08\n",
      "| TRAIN SET | Epoch [01/04], Step [0012/0304], Loss: 0.8232 | Elapsed: 0:00:09\n",
      "| TRAIN SET | Epoch [01/04], Step [0013/0304], Loss: 0.9056 | Elapsed: 0:00:09\n",
      "| TRAIN SET | Epoch [01/04], Step [0014/0304], Loss: 0.6874 | Elapsed: 0:00:10\n",
      "| TRAIN SET | Epoch [01/04], Step [0015/0304], Loss: 0.4609 | Elapsed: 0:00:10\n",
      "| TRAIN SET | Epoch [01/04], Step [0016/0304], Loss: 0.5030 | Elapsed: 0:00:11\n",
      "| TRAIN SET | Epoch [01/04], Step [0017/0304], Loss: 0.1521 | Elapsed: 0:00:12\n",
      "| TRAIN SET | Epoch [01/04], Step [0018/0304], Loss: 0.3138 | Elapsed: 0:00:12\n",
      "| TRAIN SET | Epoch [01/04], Step [0019/0304], Loss: 0.1933 | Elapsed: 0:00:13\n",
      "| TRAIN SET | Epoch [01/04], Step [0020/0304], Loss: 0.2153 | Elapsed: 0:00:14\n",
      "| TRAIN SET | Epoch [01/04], Step [0021/0304], Loss: 0.0931 | Elapsed: 0:00:14\n",
      "| TRAIN SET | Epoch [01/04], Step [0022/0304], Loss: 0.1420 | Elapsed: 0:00:15\n",
      "| TRAIN SET | Epoch [01/04], Step [0023/0304], Loss: 0.0506 | Elapsed: 0:00:16\n",
      "| TRAIN SET | Epoch [01/04], Step [0024/0304], Loss: 0.1388 | Elapsed: 0:00:16\n",
      "| TRAIN SET | Epoch [01/04], Step [0025/0304], Loss: 0.0810 | Elapsed: 0:00:17\n",
      "| TRAIN SET | Epoch [01/04], Step [0026/0304], Loss: 0.0451 | Elapsed: 0:00:17\n",
      "| TRAIN SET | Epoch [01/04], Step [0027/0304], Loss: 0.0900 | Elapsed: 0:00:18\n",
      "| TRAIN SET | Epoch [01/04], Step [0028/0304], Loss: 0.0438 | Elapsed: 0:00:19\n",
      "| TRAIN SET | Epoch [01/04], Step [0029/0304], Loss: 0.1516 | Elapsed: 0:00:19\n",
      "| TRAIN SET | Epoch [01/04], Step [0030/0304], Loss: 0.0718 | Elapsed: 0:00:20\n",
      "| TRAIN SET | Epoch [01/04], Step [0031/0304], Loss: 0.0492 | Elapsed: 0:00:21\n",
      "| TRAIN SET | Epoch [01/04], Step [0032/0304], Loss: 0.0695 | Elapsed: 0:00:21\n",
      "| TRAIN SET | Epoch [01/04], Step [0033/0304], Loss: 0.0000 | Elapsed: 0:00:22\n",
      "| TRAIN SET | Epoch [01/04], Step [0034/0304], Loss: 0.0980 | Elapsed: 0:00:22\n",
      "| TRAIN SET | Epoch [01/04], Step [0035/0304], Loss: 0.1371 | Elapsed: 0:00:23\n",
      "| TRAIN SET | Epoch [01/04], Step [0036/0304], Loss: 0.1828 | Elapsed: 0:00:24\n",
      "| TRAIN SET | Epoch [01/04], Step [0037/0304], Loss: 0.0661 | Elapsed: 0:00:24\n",
      "| TRAIN SET | Epoch [01/04], Step [0038/0304], Loss: 0.0591 | Elapsed: 0:00:25\n",
      "| TRAIN SET | Epoch [01/04], Step [0039/0304], Loss: 0.0904 | Elapsed: 0:00:26\n",
      "| TRAIN SET | Epoch [01/04], Step [0040/0304], Loss: 0.0179 | Elapsed: 0:00:26\n",
      "| TRAIN SET | Epoch [01/04], Step [0041/0304], Loss: 0.0679 | Elapsed: 0:00:27\n",
      "| TRAIN SET | Epoch [01/04], Step [0042/0304], Loss: 0.0918 | Elapsed: 0:00:28\n",
      "| TRAIN SET | Epoch [01/04], Step [0043/0304], Loss: 0.0545 | Elapsed: 0:00:28\n",
      "| TRAIN SET | Epoch [01/04], Step [0044/0304], Loss: 0.0355 | Elapsed: 0:00:29\n",
      "| TRAIN SET | Epoch [01/04], Step [0045/0304], Loss: 0.0517 | Elapsed: 0:00:29\n",
      "| TRAIN SET | Epoch [01/04], Step [0046/0304], Loss: 0.0461 | Elapsed: 0:00:30\n",
      "| TRAIN SET | Epoch [01/04], Step [0047/0304], Loss: 0.1193 | Elapsed: 0:00:31\n",
      "| TRAIN SET | Epoch [01/04], Step [0048/0304], Loss: 0.0053 | Elapsed: 0:00:31\n",
      "| TRAIN SET | Epoch [01/04], Step [0049/0304], Loss: 0.0000 | Elapsed: 0:00:32\n",
      "| TRAIN SET | Epoch [01/04], Step [0050/0304], Loss: 0.1537 | Elapsed: 0:00:33\n",
      "| TRAIN SET | Epoch [01/04], Step [0051/0304], Loss: 0.0852 | Elapsed: 0:00:33\n",
      "| TRAIN SET | Epoch [01/04], Step [0052/0304], Loss: 0.0050 | Elapsed: 0:00:34\n",
      "| TRAIN SET | Epoch [01/04], Step [0053/0304], Loss: 0.1021 | Elapsed: 0:00:35\n",
      "| TRAIN SET | Epoch [01/04], Step [0054/0304], Loss: 0.2203 | Elapsed: 0:00:35\n",
      "| TRAIN SET | Epoch [01/04], Step [0055/0304], Loss: 0.0772 | Elapsed: 0:00:36\n",
      "| TRAIN SET | Epoch [01/04], Step [0056/0304], Loss: 0.1660 | Elapsed: 0:00:36\n",
      "| TRAIN SET | Epoch [01/04], Step [0057/0304], Loss: 0.0493 | Elapsed: 0:00:37\n",
      "| TRAIN SET | Epoch [01/04], Step [0058/0304], Loss: 0.0327 | Elapsed: 0:00:38\n",
      "| TRAIN SET | Epoch [01/04], Step [0059/0304], Loss: 0.0707 | Elapsed: 0:00:38\n",
      "| TRAIN SET | Epoch [01/04], Step [0060/0304], Loss: 0.0000 | Elapsed: 0:00:39\n",
      "| TRAIN SET | Epoch [01/04], Step [0061/0304], Loss: 0.0754 | Elapsed: 0:00:40\n",
      "| TRAIN SET | Epoch [01/04], Step [0062/0304], Loss: 0.0000 | Elapsed: 0:00:40\n",
      "| TRAIN SET | Epoch [01/04], Step [0063/0304], Loss: 0.0098 | Elapsed: 0:00:41\n",
      "| TRAIN SET | Epoch [01/04], Step [0064/0304], Loss: 0.0000 | Elapsed: 0:00:42\n",
      "| TRAIN SET | Epoch [01/04], Step [0065/0304], Loss: 0.0635 | Elapsed: 0:00:42\n",
      "| TRAIN SET | Epoch [01/04], Step [0066/0304], Loss: 0.0934 | Elapsed: 0:00:43\n",
      "| TRAIN SET | Epoch [01/04], Step [0067/0304], Loss: 0.1521 | Elapsed: 0:00:43\n",
      "| TRAIN SET | Epoch [01/04], Step [0068/0304], Loss: 0.0753 | Elapsed: 0:00:44\n",
      "| TRAIN SET | Epoch [01/04], Step [0069/0304], Loss: 0.1941 | Elapsed: 0:00:45\n",
      "| TRAIN SET | Epoch [01/04], Step [0070/0304], Loss: 0.0791 | Elapsed: 0:00:45\n",
      "| TRAIN SET | Epoch [01/04], Step [0071/0304], Loss: 0.0283 | Elapsed: 0:00:46\n",
      "| TRAIN SET | Epoch [01/04], Step [0072/0304], Loss: 0.1619 | Elapsed: 0:00:47\n",
      "| TRAIN SET | Epoch [01/04], Step [0073/0304], Loss: 0.1433 | Elapsed: 0:00:47\n",
      "| TRAIN SET | Epoch [01/04], Step [0074/0304], Loss: 0.0119 | Elapsed: 0:00:48\n",
      "| TRAIN SET | Epoch [01/04], Step [0075/0304], Loss: 0.0000 | Elapsed: 0:00:49\n",
      "| TRAIN SET | Epoch [01/04], Step [0076/0304], Loss: 0.0667 | Elapsed: 0:00:49\n",
      "| TRAIN SET | Epoch [01/04], Step [0077/0304], Loss: 0.0596 | Elapsed: 0:00:50\n",
      "| TRAIN SET | Epoch [01/04], Step [0078/0304], Loss: 0.1194 | Elapsed: 0:00:50\n",
      "| TRAIN SET | Epoch [01/04], Step [0079/0304], Loss: 0.1648 | Elapsed: 0:00:51\n",
      "| TRAIN SET | Epoch [01/04], Step [0080/0304], Loss: 0.0556 | Elapsed: 0:00:52\n",
      "| TRAIN SET | Epoch [01/04], Step [0081/0304], Loss: 0.0044 | Elapsed: 0:00:52\n",
      "| TRAIN SET | Epoch [01/04], Step [0082/0304], Loss: 0.0403 | Elapsed: 0:00:53\n",
      "| TRAIN SET | Epoch [01/04], Step [0083/0304], Loss: 0.0823 | Elapsed: 0:00:54\n",
      "| TRAIN SET | Epoch [01/04], Step [0084/0304], Loss: 0.2528 | Elapsed: 0:00:54\n",
      "| TRAIN SET | Epoch [01/04], Step [0085/0304], Loss: 0.0661 | Elapsed: 0:00:55\n",
      "| TRAIN SET | Epoch [01/04], Step [0086/0304], Loss: 0.0823 | Elapsed: 0:00:56\n",
      "| TRAIN SET | Epoch [01/04], Step [0087/0304], Loss: 0.0691 | Elapsed: 0:00:56\n",
      "| TRAIN SET | Epoch [01/04], Step [0088/0304], Loss: 0.0815 | Elapsed: 0:00:57\n",
      "| TRAIN SET | Epoch [01/04], Step [0089/0304], Loss: 0.1740 | Elapsed: 0:00:58\n",
      "| TRAIN SET | Epoch [01/04], Step [0090/0304], Loss: 0.0758 | Elapsed: 0:00:58\n",
      "| TRAIN SET | Epoch [01/04], Step [0091/0304], Loss: 0.0845 | Elapsed: 0:00:59\n",
      "| TRAIN SET | Epoch [01/04], Step [0092/0304], Loss: 0.1496 | Elapsed: 0:00:59\n",
      "| TRAIN SET | Epoch [01/04], Step [0093/0304], Loss: 0.0865 | Elapsed: 0:01:00\n",
      "| TRAIN SET | Epoch [01/04], Step [0094/0304], Loss: 0.0000 | Elapsed: 0:01:01\n",
      "| TRAIN SET | Epoch [01/04], Step [0095/0304], Loss: 0.1256 | Elapsed: 0:01:01\n",
      "| TRAIN SET | Epoch [01/04], Step [0096/0304], Loss: 0.0801 | Elapsed: 0:01:02\n",
      "| TRAIN SET | Epoch [01/04], Step [0097/0304], Loss: 0.1009 | Elapsed: 0:01:03\n",
      "| TRAIN SET | Epoch [01/04], Step [0098/0304], Loss: 0.0310 | Elapsed: 0:01:03\n",
      "| TRAIN SET | Epoch [01/04], Step [0099/0304], Loss: 0.0000 | Elapsed: 0:01:04\n",
      "| TRAIN SET | Epoch [01/04], Step [0100/0304], Loss: 0.0969 | Elapsed: 0:01:05\n",
      "| TRAIN SET | Epoch [01/04], Step [0101/0304], Loss: 0.0000 | Elapsed: 0:01:06\n",
      "| TRAIN SET | Epoch [01/04], Step [0102/0304], Loss: 0.1188 | Elapsed: 0:01:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [01/04], Step [0103/0304], Loss: 0.0810 | Elapsed: 0:01:07\n",
      "| TRAIN SET | Epoch [01/04], Step [0104/0304], Loss: 0.0000 | Elapsed: 0:01:08\n",
      "| TRAIN SET | Epoch [01/04], Step [0105/0304], Loss: 0.0962 | Elapsed: 0:01:09\n",
      "| TRAIN SET | Epoch [01/04], Step [0106/0304], Loss: 0.0000 | Elapsed: 0:01:09\n",
      "| TRAIN SET | Epoch [01/04], Step [0107/0304], Loss: 0.0000 | Elapsed: 0:01:10\n",
      "| TRAIN SET | Epoch [01/04], Step [0108/0304], Loss: 0.1211 | Elapsed: 0:01:11\n",
      "| TRAIN SET | Epoch [01/04], Step [0109/0304], Loss: 0.0895 | Elapsed: 0:01:11\n",
      "| TRAIN SET | Epoch [01/04], Step [0110/0304], Loss: 0.0575 | Elapsed: 0:01:12\n",
      "| TRAIN SET | Epoch [01/04], Step [0111/0304], Loss: 0.3378 | Elapsed: 0:01:13\n",
      "| TRAIN SET | Epoch [01/04], Step [0112/0304], Loss: 0.1087 | Elapsed: 0:01:13\n",
      "| TRAIN SET | Epoch [01/04], Step [0113/0304], Loss: 0.0573 | Elapsed: 0:01:14\n",
      "| TRAIN SET | Epoch [01/04], Step [0114/0304], Loss: 0.0000 | Elapsed: 0:01:14\n",
      "| TRAIN SET | Epoch [01/04], Step [0115/0304], Loss: 0.1173 | Elapsed: 0:01:15\n",
      "| TRAIN SET | Epoch [01/04], Step [0116/0304], Loss: 0.0767 | Elapsed: 0:01:16\n",
      "| TRAIN SET | Epoch [01/04], Step [0117/0304], Loss: 0.0000 | Elapsed: 0:01:16\n",
      "| TRAIN SET | Epoch [01/04], Step [0118/0304], Loss: 0.0000 | Elapsed: 0:01:17\n",
      "| TRAIN SET | Epoch [01/04], Step [0119/0304], Loss: 0.0000 | Elapsed: 0:01:18\n",
      "| TRAIN SET | Epoch [01/04], Step [0120/0304], Loss: 0.0245 | Elapsed: 0:01:18\n",
      "| TRAIN SET | Epoch [01/04], Step [0121/0304], Loss: 0.0472 | Elapsed: 0:01:19\n",
      "| TRAIN SET | Epoch [01/04], Step [0122/0304], Loss: 0.0951 | Elapsed: 0:01:20\n",
      "| TRAIN SET | Epoch [01/04], Step [0123/0304], Loss: 0.0149 | Elapsed: 0:01:20\n",
      "| TRAIN SET | Epoch [01/04], Step [0124/0304], Loss: 0.0000 | Elapsed: 0:01:21\n",
      "| TRAIN SET | Epoch [01/04], Step [0125/0304], Loss: 0.0764 | Elapsed: 0:01:22\n",
      "| TRAIN SET | Epoch [01/04], Step [0126/0304], Loss: 0.1529 | Elapsed: 0:01:22\n",
      "| TRAIN SET | Epoch [01/04], Step [0127/0304], Loss: 0.0000 | Elapsed: 0:01:23\n",
      "| TRAIN SET | Epoch [01/04], Step [0128/0304], Loss: 0.0000 | Elapsed: 0:01:23\n",
      "| TRAIN SET | Epoch [01/04], Step [0129/0304], Loss: 0.0556 | Elapsed: 0:01:24\n",
      "| TRAIN SET | Epoch [01/04], Step [0130/0304], Loss: 0.0405 | Elapsed: 0:01:25\n",
      "| TRAIN SET | Epoch [01/04], Step [0131/0304], Loss: 0.1497 | Elapsed: 0:01:25\n",
      "| TRAIN SET | Epoch [01/04], Step [0132/0304], Loss: 0.0329 | Elapsed: 0:01:26\n",
      "| TRAIN SET | Epoch [01/04], Step [0133/0304], Loss: 0.0118 | Elapsed: 0:01:27\n",
      "| TRAIN SET | Epoch [01/04], Step [0134/0304], Loss: 0.1044 | Elapsed: 0:01:27\n",
      "| TRAIN SET | Epoch [01/04], Step [0135/0304], Loss: 0.0636 | Elapsed: 0:01:28\n",
      "| TRAIN SET | Epoch [01/04], Step [0136/0304], Loss: 0.0226 | Elapsed: 0:01:29\n",
      "| TRAIN SET | Epoch [01/04], Step [0137/0304], Loss: 0.1503 | Elapsed: 0:01:29\n",
      "| TRAIN SET | Epoch [01/04], Step [0138/0304], Loss: 0.0768 | Elapsed: 0:01:30\n",
      "| TRAIN SET | Epoch [01/04], Step [0139/0304], Loss: 0.0481 | Elapsed: 0:01:30\n",
      "| TRAIN SET | Epoch [01/04], Step [0140/0304], Loss: 0.0381 | Elapsed: 0:01:31\n",
      "| TRAIN SET | Epoch [01/04], Step [0141/0304], Loss: 0.0000 | Elapsed: 0:01:32\n",
      "| TRAIN SET | Epoch [01/04], Step [0142/0304], Loss: 0.0000 | Elapsed: 0:01:32\n",
      "| TRAIN SET | Epoch [01/04], Step [0143/0304], Loss: 0.0116 | Elapsed: 0:01:33\n",
      "| TRAIN SET | Epoch [01/04], Step [0144/0304], Loss: 0.0201 | Elapsed: 0:01:34\n",
      "| TRAIN SET | Epoch [01/04], Step [0145/0304], Loss: 0.0000 | Elapsed: 0:01:34\n",
      "| TRAIN SET | Epoch [01/04], Step [0146/0304], Loss: 0.0905 | Elapsed: 0:01:35\n",
      "| TRAIN SET | Epoch [01/04], Step [0147/0304], Loss: 0.0000 | Elapsed: 0:01:36\n",
      "| TRAIN SET | Epoch [01/04], Step [0148/0304], Loss: 0.0424 | Elapsed: 0:01:36\n",
      "| TRAIN SET | Epoch [01/04], Step [0149/0304], Loss: 0.0131 | Elapsed: 0:01:37\n",
      "| TRAIN SET | Epoch [01/04], Step [0150/0304], Loss: 0.0000 | Elapsed: 0:01:38\n",
      "| TRAIN SET | Epoch [01/04], Step [0151/0304], Loss: 0.0000 | Elapsed: 0:01:38\n",
      "| TRAIN SET | Epoch [01/04], Step [0152/0304], Loss: 0.0874 | Elapsed: 0:01:39\n",
      "| TRAIN SET | Epoch [01/04], Step [0153/0304], Loss: 0.1001 | Elapsed: 0:01:39\n",
      "| TRAIN SET | Epoch [01/04], Step [0154/0304], Loss: 0.0454 | Elapsed: 0:01:40\n",
      "| TRAIN SET | Epoch [01/04], Step [0155/0304], Loss: 0.0861 | Elapsed: 0:01:41\n",
      "| TRAIN SET | Epoch [01/04], Step [0156/0304], Loss: 0.0412 | Elapsed: 0:01:41\n",
      "| TRAIN SET | Epoch [01/04], Step [0157/0304], Loss: 0.0737 | Elapsed: 0:01:42\n",
      "| TRAIN SET | Epoch [01/04], Step [0158/0304], Loss: 0.0215 | Elapsed: 0:01:43\n",
      "| TRAIN SET | Epoch [01/04], Step [0159/0304], Loss: 0.0000 | Elapsed: 0:01:43\n",
      "| TRAIN SET | Epoch [01/04], Step [0160/0304], Loss: 0.0000 | Elapsed: 0:01:44\n",
      "| TRAIN SET | Epoch [01/04], Step [0161/0304], Loss: 0.0000 | Elapsed: 0:01:45\n",
      "| TRAIN SET | Epoch [01/04], Step [0162/0304], Loss: 0.0611 | Elapsed: 0:01:45\n",
      "| TRAIN SET | Epoch [01/04], Step [0163/0304], Loss: 0.0986 | Elapsed: 0:01:46\n",
      "| TRAIN SET | Epoch [01/04], Step [0164/0304], Loss: 0.0000 | Elapsed: 0:01:47\n",
      "| TRAIN SET | Epoch [01/04], Step [0165/0304], Loss: 0.2072 | Elapsed: 0:01:47\n",
      "| TRAIN SET | Epoch [01/04], Step [0166/0304], Loss: 0.0230 | Elapsed: 0:01:48\n",
      "| TRAIN SET | Epoch [01/04], Step [0167/0304], Loss: 0.0349 | Elapsed: 0:01:48\n",
      "| TRAIN SET | Epoch [01/04], Step [0168/0304], Loss: 0.0021 | Elapsed: 0:01:49\n",
      "| TRAIN SET | Epoch [01/04], Step [0169/0304], Loss: 0.0696 | Elapsed: 0:01:50\n",
      "| TRAIN SET | Epoch [01/04], Step [0170/0304], Loss: 0.0021 | Elapsed: 0:01:50\n",
      "| TRAIN SET | Epoch [01/04], Step [0171/0304], Loss: 0.0000 | Elapsed: 0:01:51\n",
      "| TRAIN SET | Epoch [01/04], Step [0172/0304], Loss: 0.0501 | Elapsed: 0:01:52\n",
      "| TRAIN SET | Epoch [01/04], Step [0173/0304], Loss: 0.0000 | Elapsed: 0:01:52\n",
      "| TRAIN SET | Epoch [01/04], Step [0174/0304], Loss: 0.0547 | Elapsed: 0:01:53\n",
      "| TRAIN SET | Epoch [01/04], Step [0175/0304], Loss: 0.1379 | Elapsed: 0:01:54\n",
      "| TRAIN SET | Epoch [01/04], Step [0176/0304], Loss: 0.0000 | Elapsed: 0:01:54\n",
      "| TRAIN SET | Epoch [01/04], Step [0177/0304], Loss: 0.0000 | Elapsed: 0:01:55\n",
      "| TRAIN SET | Epoch [01/04], Step [0178/0304], Loss: 0.0000 | Elapsed: 0:01:56\n",
      "| TRAIN SET | Epoch [01/04], Step [0179/0304], Loss: 0.1104 | Elapsed: 0:01:56\n",
      "| TRAIN SET | Epoch [01/04], Step [0180/0304], Loss: 0.0374 | Elapsed: 0:01:57\n",
      "| TRAIN SET | Epoch [01/04], Step [0181/0304], Loss: 0.0000 | Elapsed: 0:01:58\n",
      "| TRAIN SET | Epoch [01/04], Step [0182/0304], Loss: 0.0250 | Elapsed: 0:01:58\n",
      "| TRAIN SET | Epoch [01/04], Step [0183/0304], Loss: 0.0000 | Elapsed: 0:01:59\n",
      "| TRAIN SET | Epoch [01/04], Step [0184/0304], Loss: 0.0575 | Elapsed: 0:01:59\n",
      "| TRAIN SET | Epoch [01/04], Step [0185/0304], Loss: 0.1505 | Elapsed: 0:02:00\n",
      "| TRAIN SET | Epoch [01/04], Step [0186/0304], Loss: 0.0563 | Elapsed: 0:02:01\n",
      "| TRAIN SET | Epoch [01/04], Step [0187/0304], Loss: 0.0000 | Elapsed: 0:02:01\n",
      "| TRAIN SET | Epoch [01/04], Step [0188/0304], Loss: 0.0151 | Elapsed: 0:02:02\n",
      "| TRAIN SET | Epoch [01/04], Step [0189/0304], Loss: 0.1592 | Elapsed: 0:02:03\n",
      "| TRAIN SET | Epoch [01/04], Step [0190/0304], Loss: 0.0367 | Elapsed: 0:02:03\n",
      "| TRAIN SET | Epoch [01/04], Step [0191/0304], Loss: 0.0000 | Elapsed: 0:02:04\n",
      "| TRAIN SET | Epoch [01/04], Step [0192/0304], Loss: 0.0000 | Elapsed: 0:02:05\n",
      "| TRAIN SET | Epoch [01/04], Step [0193/0304], Loss: 0.0068 | Elapsed: 0:02:05\n",
      "| TRAIN SET | Epoch [01/04], Step [0194/0304], Loss: 0.0000 | Elapsed: 0:02:06\n",
      "| TRAIN SET | Epoch [01/04], Step [0195/0304], Loss: 0.0000 | Elapsed: 0:02:07\n",
      "| TRAIN SET | Epoch [01/04], Step [0196/0304], Loss: 0.1844 | Elapsed: 0:02:07\n",
      "| TRAIN SET | Epoch [01/04], Step [0197/0304], Loss: 0.0861 | Elapsed: 0:02:08\n",
      "| TRAIN SET | Epoch [01/04], Step [0198/0304], Loss: 0.0000 | Elapsed: 0:02:09\n",
      "| TRAIN SET | Epoch [01/04], Step [0199/0304], Loss: 0.1135 | Elapsed: 0:02:09\n",
      "| TRAIN SET | Epoch [01/04], Step [0200/0304], Loss: 0.0443 | Elapsed: 0:02:11\n",
      "| TRAIN SET | Epoch [01/04], Step [0201/0304], Loss: 0.0504 | Elapsed: 0:02:11\n",
      "| TRAIN SET | Epoch [01/04], Step [0202/0304], Loss: 0.0715 | Elapsed: 0:02:12\n",
      "| TRAIN SET | Epoch [01/04], Step [0203/0304], Loss: 0.0000 | Elapsed: 0:02:13\n",
      "| TRAIN SET | Epoch [01/04], Step [0204/0304], Loss: 0.0543 | Elapsed: 0:02:13\n",
      "| TRAIN SET | Epoch [01/04], Step [0205/0304], Loss: 0.0000 | Elapsed: 0:02:14\n",
      "| TRAIN SET | Epoch [01/04], Step [0206/0304], Loss: 0.0000 | Elapsed: 0:02:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [01/04], Step [0207/0304], Loss: 0.0000 | Elapsed: 0:02:15\n",
      "| TRAIN SET | Epoch [01/04], Step [0208/0304], Loss: 0.0000 | Elapsed: 0:02:16\n",
      "| TRAIN SET | Epoch [01/04], Step [0209/0304], Loss: 0.0611 | Elapsed: 0:02:17\n",
      "| TRAIN SET | Epoch [01/04], Step [0210/0304], Loss: 0.0000 | Elapsed: 0:02:17\n",
      "| TRAIN SET | Epoch [01/04], Step [0211/0304], Loss: 0.1067 | Elapsed: 0:02:18\n",
      "| TRAIN SET | Epoch [01/04], Step [0212/0304], Loss: 0.1338 | Elapsed: 0:02:18\n",
      "| TRAIN SET | Epoch [01/04], Step [0213/0304], Loss: 0.1897 | Elapsed: 0:02:19\n",
      "| TRAIN SET | Epoch [01/04], Step [0214/0304], Loss: 0.1129 | Elapsed: 0:02:20\n",
      "| TRAIN SET | Epoch [01/04], Step [0215/0304], Loss: 0.0000 | Elapsed: 0:02:20\n",
      "| TRAIN SET | Epoch [01/04], Step [0216/0304], Loss: 0.0000 | Elapsed: 0:02:21\n",
      "| TRAIN SET | Epoch [01/04], Step [0217/0304], Loss: 0.0914 | Elapsed: 0:02:22\n",
      "| TRAIN SET | Epoch [01/04], Step [0218/0304], Loss: 0.1214 | Elapsed: 0:02:22\n",
      "| TRAIN SET | Epoch [01/04], Step [0219/0304], Loss: 0.0445 | Elapsed: 0:02:23\n",
      "| TRAIN SET | Epoch [01/04], Step [0220/0304], Loss: 0.0000 | Elapsed: 0:02:24\n",
      "| TRAIN SET | Epoch [01/04], Step [0221/0304], Loss: 0.0507 | Elapsed: 0:02:24\n",
      "| TRAIN SET | Epoch [01/04], Step [0222/0304], Loss: 0.0632 | Elapsed: 0:02:25\n",
      "| TRAIN SET | Epoch [01/04], Step [0223/0304], Loss: 0.2056 | Elapsed: 0:02:26\n",
      "| TRAIN SET | Epoch [01/04], Step [0224/0304], Loss: 0.0625 | Elapsed: 0:02:26\n",
      "| TRAIN SET | Epoch [01/04], Step [0225/0304], Loss: 0.0000 | Elapsed: 0:02:27\n",
      "| TRAIN SET | Epoch [01/04], Step [0226/0304], Loss: 0.0482 | Elapsed: 0:02:28\n",
      "| TRAIN SET | Epoch [01/04], Step [0227/0304], Loss: 0.0000 | Elapsed: 0:02:28\n",
      "| TRAIN SET | Epoch [01/04], Step [0228/0304], Loss: 0.0000 | Elapsed: 0:02:29\n",
      "| TRAIN SET | Epoch [01/04], Step [0229/0304], Loss: 0.2326 | Elapsed: 0:02:29\n",
      "| TRAIN SET | Epoch [01/04], Step [0230/0304], Loss: 0.0787 | Elapsed: 0:02:30\n",
      "| TRAIN SET | Epoch [01/04], Step [0231/0304], Loss: 0.0049 | Elapsed: 0:02:31\n",
      "| TRAIN SET | Epoch [01/04], Step [0232/0304], Loss: 0.0628 | Elapsed: 0:02:31\n",
      "| TRAIN SET | Epoch [01/04], Step [0233/0304], Loss: 0.0000 | Elapsed: 0:02:32\n",
      "| TRAIN SET | Epoch [01/04], Step [0234/0304], Loss: 0.0000 | Elapsed: 0:02:33\n",
      "| TRAIN SET | Epoch [01/04], Step [0235/0304], Loss: 0.3350 | Elapsed: 0:02:33\n",
      "| TRAIN SET | Epoch [01/04], Step [0236/0304], Loss: 0.0097 | Elapsed: 0:02:34\n",
      "| TRAIN SET | Epoch [01/04], Step [0237/0304], Loss: 0.0000 | Elapsed: 0:02:35\n",
      "| TRAIN SET | Epoch [01/04], Step [0238/0304], Loss: 0.0633 | Elapsed: 0:02:35\n",
      "| TRAIN SET | Epoch [01/04], Step [0239/0304], Loss: 0.0124 | Elapsed: 0:02:36\n",
      "| TRAIN SET | Epoch [01/04], Step [0240/0304], Loss: 0.0050 | Elapsed: 0:02:37\n",
      "| TRAIN SET | Epoch [01/04], Step [0241/0304], Loss: 0.0321 | Elapsed: 0:02:37\n",
      "| TRAIN SET | Epoch [01/04], Step [0242/0304], Loss: 0.0745 | Elapsed: 0:02:38\n",
      "| TRAIN SET | Epoch [01/04], Step [0243/0304], Loss: 0.0028 | Elapsed: 0:02:39\n",
      "| TRAIN SET | Epoch [01/04], Step [0244/0304], Loss: 0.0000 | Elapsed: 0:02:39\n",
      "| TRAIN SET | Epoch [01/04], Step [0245/0304], Loss: 0.0000 | Elapsed: 0:02:40\n",
      "| TRAIN SET | Epoch [01/04], Step [0246/0304], Loss: 0.1072 | Elapsed: 0:02:40\n",
      "| TRAIN SET | Epoch [01/04], Step [0247/0304], Loss: 0.0000 | Elapsed: 0:02:41\n",
      "| TRAIN SET | Epoch [01/04], Step [0248/0304], Loss: 0.0464 | Elapsed: 0:02:42\n",
      "| TRAIN SET | Epoch [01/04], Step [0249/0304], Loss: 0.0622 | Elapsed: 0:02:42\n",
      "| TRAIN SET | Epoch [01/04], Step [0250/0304], Loss: 0.0364 | Elapsed: 0:02:43\n",
      "| TRAIN SET | Epoch [01/04], Step [0251/0304], Loss: 0.0660 | Elapsed: 0:02:44\n",
      "| TRAIN SET | Epoch [01/04], Step [0252/0304], Loss: 0.1740 | Elapsed: 0:02:44\n",
      "| TRAIN SET | Epoch [01/04], Step [0253/0304], Loss: 0.0405 | Elapsed: 0:02:45\n",
      "| TRAIN SET | Epoch [01/04], Step [0254/0304], Loss: 0.0468 | Elapsed: 0:02:46\n",
      "| TRAIN SET | Epoch [01/04], Step [0255/0304], Loss: 0.0151 | Elapsed: 0:02:46\n",
      "| TRAIN SET | Epoch [01/04], Step [0256/0304], Loss: 0.0567 | Elapsed: 0:02:47\n",
      "| TRAIN SET | Epoch [01/04], Step [0257/0304], Loss: 0.0336 | Elapsed: 0:02:48\n",
      "| TRAIN SET | Epoch [01/04], Step [0258/0304], Loss: 0.0542 | Elapsed: 0:02:48\n",
      "| TRAIN SET | Epoch [01/04], Step [0259/0304], Loss: 0.0430 | Elapsed: 0:02:49\n",
      "| TRAIN SET | Epoch [01/04], Step [0260/0304], Loss: 0.0002 | Elapsed: 0:02:50\n",
      "| TRAIN SET | Epoch [01/04], Step [0261/0304], Loss: 0.0580 | Elapsed: 0:02:50\n",
      "| TRAIN SET | Epoch [01/04], Step [0262/0304], Loss: 0.2972 | Elapsed: 0:02:51\n",
      "| TRAIN SET | Epoch [01/04], Step [0263/0304], Loss: 0.0587 | Elapsed: 0:02:51\n",
      "| TRAIN SET | Epoch [01/04], Step [0264/0304], Loss: 0.0325 | Elapsed: 0:02:52\n",
      "| TRAIN SET | Epoch [01/04], Step [0265/0304], Loss: 0.0530 | Elapsed: 0:02:53\n",
      "| TRAIN SET | Epoch [01/04], Step [0266/0304], Loss: 0.0000 | Elapsed: 0:02:53\n",
      "| TRAIN SET | Epoch [01/04], Step [0267/0304], Loss: 0.0000 | Elapsed: 0:02:54\n",
      "| TRAIN SET | Epoch [01/04], Step [0268/0304], Loss: 0.1594 | Elapsed: 0:02:55\n",
      "| TRAIN SET | Epoch [01/04], Step [0269/0304], Loss: 0.0528 | Elapsed: 0:02:55\n",
      "| TRAIN SET | Epoch [01/04], Step [0270/0304], Loss: 0.0000 | Elapsed: 0:02:56\n",
      "| TRAIN SET | Epoch [01/04], Step [0271/0304], Loss: 0.2144 | Elapsed: 0:02:57\n",
      "| TRAIN SET | Epoch [01/04], Step [0272/0304], Loss: 0.0000 | Elapsed: 0:02:57\n",
      "| TRAIN SET | Epoch [01/04], Step [0273/0304], Loss: 0.2063 | Elapsed: 0:02:58\n",
      "| TRAIN SET | Epoch [01/04], Step [0274/0304], Loss: 0.1118 | Elapsed: 0:02:59\n",
      "| TRAIN SET | Epoch [01/04], Step [0275/0304], Loss: 0.0000 | Elapsed: 0:02:59\n",
      "| TRAIN SET | Epoch [01/04], Step [0276/0304], Loss: 0.1534 | Elapsed: 0:03:00\n",
      "| TRAIN SET | Epoch [01/04], Step [0277/0304], Loss: 0.0000 | Elapsed: 0:03:01\n",
      "| TRAIN SET | Epoch [01/04], Step [0278/0304], Loss: 0.1069 | Elapsed: 0:03:01\n",
      "| TRAIN SET | Epoch [01/04], Step [0279/0304], Loss: 0.0000 | Elapsed: 0:03:02\n",
      "| TRAIN SET | Epoch [01/04], Step [0280/0304], Loss: 0.0000 | Elapsed: 0:03:03\n",
      "| TRAIN SET | Epoch [01/04], Step [0281/0304], Loss: 0.0601 | Elapsed: 0:03:03\n",
      "| TRAIN SET | Epoch [01/04], Step [0282/0304], Loss: 0.0056 | Elapsed: 0:03:04\n",
      "| TRAIN SET | Epoch [01/04], Step [0283/0304], Loss: 0.0000 | Elapsed: 0:03:04\n",
      "| TRAIN SET | Epoch [01/04], Step [0284/0304], Loss: 0.0817 | Elapsed: 0:03:05\n",
      "| TRAIN SET | Epoch [01/04], Step [0285/0304], Loss: 0.0000 | Elapsed: 0:03:06\n",
      "| TRAIN SET | Epoch [01/04], Step [0286/0304], Loss: 0.0042 | Elapsed: 0:03:06\n",
      "| TRAIN SET | Epoch [01/04], Step [0287/0304], Loss: 0.0000 | Elapsed: 0:03:07\n",
      "| TRAIN SET | Epoch [01/04], Step [0288/0304], Loss: 0.0075 | Elapsed: 0:03:08\n",
      "| TRAIN SET | Epoch [01/04], Step [0289/0304], Loss: 0.0449 | Elapsed: 0:03:08\n",
      "| TRAIN SET | Epoch [01/04], Step [0290/0304], Loss: 0.0755 | Elapsed: 0:03:09\n",
      "| TRAIN SET | Epoch [01/04], Step [0291/0304], Loss: 0.0567 | Elapsed: 0:03:10\n",
      "| TRAIN SET | Epoch [01/04], Step [0292/0304], Loss: 0.1863 | Elapsed: 0:03:10\n",
      "| TRAIN SET | Epoch [01/04], Step [0293/0304], Loss: 0.0000 | Elapsed: 0:03:11\n",
      "| TRAIN SET | Epoch [01/04], Step [0294/0304], Loss: 0.0492 | Elapsed: 0:03:12\n",
      "| TRAIN SET | Epoch [01/04], Step [0295/0304], Loss: 0.0455 | Elapsed: 0:03:12\n",
      "| TRAIN SET | Epoch [01/04], Step [0296/0304], Loss: 0.0847 | Elapsed: 0:03:13\n",
      "| TRAIN SET | Epoch [01/04], Step [0297/0304], Loss: 0.1387 | Elapsed: 0:03:14\n",
      "| TRAIN SET | Epoch [01/04], Step [0298/0304], Loss: 0.0472 | Elapsed: 0:03:14\n",
      "| TRAIN SET | Epoch [01/04], Step [0299/0304], Loss: 0.0611 | Elapsed: 0:03:15\n",
      "| TRAIN SET | Epoch [01/04], Step [0300/0304], Loss: 0.0488 | Elapsed: 0:03:16\n",
      "| TRAIN SET | Epoch [01/04], Step [0301/0304], Loss: 0.0822 | Elapsed: 0:03:17\n",
      "| TRAIN SET | Epoch [01/04], Step [0302/0304], Loss: 0.0000 | Elapsed: 0:03:18\n",
      "| TRAIN SET | Epoch [01/04], Step [0303/0304], Loss: 0.0550 | Elapsed: 0:03:18\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:03:19\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "| TRAIN SET | Epoch [02/04], Step [0000/0304], Loss: 0.0000 | Elapsed: 0:00:01\n",
      "| TRAIN SET | Epoch [02/04], Step [0001/0304], Loss: 0.0000 | Elapsed: 0:00:02\n",
      "| TRAIN SET | Epoch [02/04], Step [0002/0304], Loss: 0.0141 | Elapsed: 0:00:02\n",
      "| TRAIN SET | Epoch [02/04], Step [0003/0304], Loss: 0.1027 | Elapsed: 0:00:03\n",
      "| TRAIN SET | Epoch [02/04], Step [0004/0304], Loss: 0.0000 | Elapsed: 0:00:04\n",
      "| TRAIN SET | Epoch [02/04], Step [0005/0304], Loss: 0.1062 | Elapsed: 0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [02/04], Step [0006/0304], Loss: 0.0000 | Elapsed: 0:00:05\n",
      "| TRAIN SET | Epoch [02/04], Step [0007/0304], Loss: 0.0000 | Elapsed: 0:00:05\n",
      "| TRAIN SET | Epoch [02/04], Step [0008/0304], Loss: 0.0351 | Elapsed: 0:00:06\n",
      "| TRAIN SET | Epoch [02/04], Step [0009/0304], Loss: 0.0000 | Elapsed: 0:00:07\n",
      "| TRAIN SET | Epoch [02/04], Step [0010/0304], Loss: 0.1050 | Elapsed: 0:00:07\n",
      "| TRAIN SET | Epoch [02/04], Step [0011/0304], Loss: 0.0000 | Elapsed: 0:00:08\n",
      "| TRAIN SET | Epoch [02/04], Step [0012/0304], Loss: 0.1011 | Elapsed: 0:00:09\n",
      "| TRAIN SET | Epoch [02/04], Step [0013/0304], Loss: 0.0000 | Elapsed: 0:00:09\n",
      "| TRAIN SET | Epoch [02/04], Step [0014/0304], Loss: 0.0000 | Elapsed: 0:00:10\n",
      "| TRAIN SET | Epoch [02/04], Step [0015/0304], Loss: 0.0044 | Elapsed: 0:00:11\n",
      "| TRAIN SET | Epoch [02/04], Step [0016/0304], Loss: 0.0000 | Elapsed: 0:00:11\n",
      "| TRAIN SET | Epoch [02/04], Step [0017/0304], Loss: 0.0000 | Elapsed: 0:00:12\n",
      "| TRAIN SET | Epoch [02/04], Step [0018/0304], Loss: 0.0038 | Elapsed: 0:00:13\n",
      "| TRAIN SET | Epoch [02/04], Step [0019/0304], Loss: 0.0710 | Elapsed: 0:00:13\n",
      "| TRAIN SET | Epoch [02/04], Step [0020/0304], Loss: 0.0277 | Elapsed: 0:00:14\n",
      "| TRAIN SET | Epoch [02/04], Step [0021/0304], Loss: 0.0000 | Elapsed: 0:00:14\n",
      "| TRAIN SET | Epoch [02/04], Step [0022/0304], Loss: 0.0492 | Elapsed: 0:00:15\n",
      "| TRAIN SET | Epoch [02/04], Step [0023/0304], Loss: 0.1420 | Elapsed: 0:00:16\n",
      "| TRAIN SET | Epoch [02/04], Step [0024/0304], Loss: 0.0000 | Elapsed: 0:00:16\n",
      "| TRAIN SET | Epoch [02/04], Step [0025/0304], Loss: 0.0000 | Elapsed: 0:00:17\n",
      "| TRAIN SET | Epoch [02/04], Step [0026/0304], Loss: 0.0106 | Elapsed: 0:00:18\n",
      "| TRAIN SET | Epoch [02/04], Step [0027/0304], Loss: 0.0272 | Elapsed: 0:00:18\n",
      "| TRAIN SET | Epoch [02/04], Step [0028/0304], Loss: 0.0644 | Elapsed: 0:00:19\n",
      "| TRAIN SET | Epoch [02/04], Step [0029/0304], Loss: 0.0000 | Elapsed: 0:00:20\n",
      "| TRAIN SET | Epoch [02/04], Step [0030/0304], Loss: 0.1083 | Elapsed: 0:00:20\n",
      "| TRAIN SET | Epoch [02/04], Step [0031/0304], Loss: 0.0620 | Elapsed: 0:00:21\n",
      "| TRAIN SET | Epoch [02/04], Step [0032/0304], Loss: 0.0000 | Elapsed: 0:00:22\n",
      "| TRAIN SET | Epoch [02/04], Step [0033/0304], Loss: 0.1806 | Elapsed: 0:00:22\n",
      "| TRAIN SET | Epoch [02/04], Step [0034/0304], Loss: 0.0000 | Elapsed: 0:00:23\n",
      "| TRAIN SET | Epoch [02/04], Step [0035/0304], Loss: 0.0033 | Elapsed: 0:00:23\n",
      "| TRAIN SET | Epoch [02/04], Step [0036/0304], Loss: 0.1113 | Elapsed: 0:00:24\n",
      "| TRAIN SET | Epoch [02/04], Step [0037/0304], Loss: 0.2505 | Elapsed: 0:00:25\n",
      "| TRAIN SET | Epoch [02/04], Step [0038/0304], Loss: 0.0558 | Elapsed: 0:00:25\n",
      "| TRAIN SET | Epoch [02/04], Step [0039/0304], Loss: 0.0000 | Elapsed: 0:00:26\n",
      "| TRAIN SET | Epoch [02/04], Step [0040/0304], Loss: 0.0000 | Elapsed: 0:00:27\n",
      "| TRAIN SET | Epoch [02/04], Step [0041/0304], Loss: 0.0858 | Elapsed: 0:00:27\n",
      "| TRAIN SET | Epoch [02/04], Step [0042/0304], Loss: 0.0000 | Elapsed: 0:00:28\n",
      "| TRAIN SET | Epoch [02/04], Step [0043/0304], Loss: 0.3301 | Elapsed: 0:00:29\n",
      "| TRAIN SET | Epoch [02/04], Step [0044/0304], Loss: 0.0113 | Elapsed: 0:00:29\n",
      "| TRAIN SET | Epoch [02/04], Step [0045/0304], Loss: 0.0904 | Elapsed: 0:00:30\n",
      "| TRAIN SET | Epoch [02/04], Step [0046/0304], Loss: 0.1864 | Elapsed: 0:00:31\n",
      "| TRAIN SET | Epoch [02/04], Step [0047/0304], Loss: 0.2746 | Elapsed: 0:00:31\n",
      "| TRAIN SET | Epoch [02/04], Step [0048/0304], Loss: 0.0000 | Elapsed: 0:00:32\n",
      "| TRAIN SET | Epoch [02/04], Step [0049/0304], Loss: 0.0000 | Elapsed: 0:00:33\n",
      "| TRAIN SET | Epoch [02/04], Step [0050/0304], Loss: 0.1346 | Elapsed: 0:00:33\n",
      "| TRAIN SET | Epoch [02/04], Step [0051/0304], Loss: 0.1113 | Elapsed: 0:00:34\n",
      "| TRAIN SET | Epoch [02/04], Step [0052/0304], Loss: 0.0568 | Elapsed: 0:00:35\n",
      "| TRAIN SET | Epoch [02/04], Step [0053/0304], Loss: 0.0000 | Elapsed: 0:00:35\n",
      "| TRAIN SET | Epoch [02/04], Step [0054/0304], Loss: 0.0000 | Elapsed: 0:00:36\n",
      "| TRAIN SET | Epoch [02/04], Step [0055/0304], Loss: 0.0191 | Elapsed: 0:00:36\n",
      "| TRAIN SET | Epoch [02/04], Step [0056/0304], Loss: 0.2732 | Elapsed: 0:00:37\n",
      "| TRAIN SET | Epoch [02/04], Step [0057/0304], Loss: 0.0000 | Elapsed: 0:00:38\n",
      "| TRAIN SET | Epoch [02/04], Step [0058/0304], Loss: 0.1213 | Elapsed: 0:00:38\n",
      "| TRAIN SET | Epoch [02/04], Step [0059/0304], Loss: 0.1068 | Elapsed: 0:00:39\n",
      "| TRAIN SET | Epoch [02/04], Step [0060/0304], Loss: 0.1127 | Elapsed: 0:00:40\n",
      "| TRAIN SET | Epoch [02/04], Step [0061/0304], Loss: 0.1021 | Elapsed: 0:00:40\n",
      "| TRAIN SET | Epoch [02/04], Step [0062/0304], Loss: 0.0840 | Elapsed: 0:00:41\n",
      "| TRAIN SET | Epoch [02/04], Step [0063/0304], Loss: 0.0678 | Elapsed: 0:00:42\n",
      "| TRAIN SET | Epoch [02/04], Step [0064/0304], Loss: 0.0000 | Elapsed: 0:00:42\n",
      "| TRAIN SET | Epoch [02/04], Step [0065/0304], Loss: 0.0145 | Elapsed: 0:00:43\n",
      "| TRAIN SET | Epoch [02/04], Step [0066/0304], Loss: 0.1093 | Elapsed: 0:00:44\n",
      "| TRAIN SET | Epoch [02/04], Step [0067/0304], Loss: 0.0682 | Elapsed: 0:00:44\n",
      "| TRAIN SET | Epoch [02/04], Step [0068/0304], Loss: 0.0736 | Elapsed: 0:00:45\n",
      "| TRAIN SET | Epoch [02/04], Step [0069/0304], Loss: 0.0000 | Elapsed: 0:00:46\n",
      "| TRAIN SET | Epoch [02/04], Step [0070/0304], Loss: 0.1320 | Elapsed: 0:00:46\n",
      "| TRAIN SET | Epoch [02/04], Step [0071/0304], Loss: 0.1218 | Elapsed: 0:00:47\n",
      "| TRAIN SET | Epoch [02/04], Step [0072/0304], Loss: 0.0715 | Elapsed: 0:00:48\n",
      "| TRAIN SET | Epoch [02/04], Step [0073/0304], Loss: 0.1061 | Elapsed: 0:00:48\n",
      "| TRAIN SET | Epoch [02/04], Step [0074/0304], Loss: 0.2394 | Elapsed: 0:00:49\n",
      "| TRAIN SET | Epoch [02/04], Step [0075/0304], Loss: 0.0000 | Elapsed: 0:00:49\n",
      "| TRAIN SET | Epoch [02/04], Step [0076/0304], Loss: 0.0585 | Elapsed: 0:00:50\n",
      "| TRAIN SET | Epoch [02/04], Step [0077/0304], Loss: 0.0764 | Elapsed: 0:00:51\n",
      "| TRAIN SET | Epoch [02/04], Step [0078/0304], Loss: 0.0000 | Elapsed: 0:00:51\n",
      "| TRAIN SET | Epoch [02/04], Step [0079/0304], Loss: 0.0672 | Elapsed: 0:00:52\n",
      "| TRAIN SET | Epoch [02/04], Step [0080/0304], Loss: 0.3355 | Elapsed: 0:00:53\n",
      "| TRAIN SET | Epoch [02/04], Step [0081/0304], Loss: 0.0000 | Elapsed: 0:00:53\n",
      "| TRAIN SET | Epoch [02/04], Step [0082/0304], Loss: 0.2652 | Elapsed: 0:00:54\n",
      "| TRAIN SET | Epoch [02/04], Step [0083/0304], Loss: 0.0000 | Elapsed: 0:00:55\n",
      "| TRAIN SET | Epoch [02/04], Step [0084/0304], Loss: 0.1425 | Elapsed: 0:00:55\n",
      "| TRAIN SET | Epoch [02/04], Step [0085/0304], Loss: 0.0000 | Elapsed: 0:00:56\n",
      "| TRAIN SET | Epoch [02/04], Step [0086/0304], Loss: 0.0000 | Elapsed: 0:00:57\n",
      "| TRAIN SET | Epoch [02/04], Step [0087/0304], Loss: 0.0000 | Elapsed: 0:00:57\n",
      "| TRAIN SET | Epoch [02/04], Step [0088/0304], Loss: 0.0130 | Elapsed: 0:00:58\n",
      "| TRAIN SET | Epoch [02/04], Step [0089/0304], Loss: 0.0478 | Elapsed: 0:00:59\n",
      "| TRAIN SET | Epoch [02/04], Step [0090/0304], Loss: 0.0243 | Elapsed: 0:00:59\n",
      "| TRAIN SET | Epoch [02/04], Step [0091/0304], Loss: 0.0039 | Elapsed: 0:01:00\n",
      "| TRAIN SET | Epoch [02/04], Step [0092/0304], Loss: 0.0000 | Elapsed: 0:01:01\n",
      "| TRAIN SET | Epoch [02/04], Step [0093/0304], Loss: 0.0492 | Elapsed: 0:01:01\n",
      "| TRAIN SET | Epoch [02/04], Step [0094/0304], Loss: 0.1080 | Elapsed: 0:01:02\n",
      "| TRAIN SET | Epoch [02/04], Step [0095/0304], Loss: 0.0000 | Elapsed: 0:01:02\n",
      "| TRAIN SET | Epoch [02/04], Step [0096/0304], Loss: 0.0000 | Elapsed: 0:01:03\n",
      "| TRAIN SET | Epoch [02/04], Step [0097/0304], Loss: 0.0692 | Elapsed: 0:01:04\n",
      "| TRAIN SET | Epoch [02/04], Step [0098/0304], Loss: 0.0000 | Elapsed: 0:01:04\n",
      "| TRAIN SET | Epoch [02/04], Step [0099/0304], Loss: 0.0110 | Elapsed: 0:01:05\n",
      "| TRAIN SET | Epoch [02/04], Step [0100/0304], Loss: 0.0282 | Elapsed: 0:01:07\n",
      "| TRAIN SET | Epoch [02/04], Step [0101/0304], Loss: 0.3690 | Elapsed: 0:01:07\n",
      "| TRAIN SET | Epoch [02/04], Step [0102/0304], Loss: 0.0000 | Elapsed: 0:01:08\n",
      "| TRAIN SET | Epoch [02/04], Step [0103/0304], Loss: 0.0031 | Elapsed: 0:01:09\n",
      "| TRAIN SET | Epoch [02/04], Step [0104/0304], Loss: 0.0000 | Elapsed: 0:01:09\n",
      "| TRAIN SET | Epoch [02/04], Step [0105/0304], Loss: 0.0000 | Elapsed: 0:01:10\n",
      "| TRAIN SET | Epoch [02/04], Step [0106/0304], Loss: 0.2215 | Elapsed: 0:01:10\n",
      "| TRAIN SET | Epoch [02/04], Step [0107/0304], Loss: 0.0000 | Elapsed: 0:01:11\n",
      "| TRAIN SET | Epoch [02/04], Step [0108/0304], Loss: 0.0000 | Elapsed: 0:01:12\n",
      "| TRAIN SET | Epoch [02/04], Step [0109/0304], Loss: 0.0000 | Elapsed: 0:01:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [02/04], Step [0110/0304], Loss: 0.1378 | Elapsed: 0:01:13\n",
      "| TRAIN SET | Epoch [02/04], Step [0111/0304], Loss: 0.0916 | Elapsed: 0:01:14\n",
      "| TRAIN SET | Epoch [02/04], Step [0112/0304], Loss: 0.0321 | Elapsed: 0:01:14\n",
      "| TRAIN SET | Epoch [02/04], Step [0113/0304], Loss: 0.0258 | Elapsed: 0:01:15\n",
      "| TRAIN SET | Epoch [02/04], Step [0114/0304], Loss: 0.0000 | Elapsed: 0:01:16\n",
      "| TRAIN SET | Epoch [02/04], Step [0115/0304], Loss: 0.0000 | Elapsed: 0:01:16\n",
      "| TRAIN SET | Epoch [02/04], Step [0116/0304], Loss: 0.0533 | Elapsed: 0:01:17\n",
      "| TRAIN SET | Epoch [02/04], Step [0117/0304], Loss: 0.0043 | Elapsed: 0:01:18\n",
      "| TRAIN SET | Epoch [02/04], Step [0118/0304], Loss: 0.0000 | Elapsed: 0:01:18\n",
      "| TRAIN SET | Epoch [02/04], Step [0119/0304], Loss: 0.2322 | Elapsed: 0:01:19\n",
      "| TRAIN SET | Epoch [02/04], Step [0120/0304], Loss: 0.1430 | Elapsed: 0:01:20\n",
      "| TRAIN SET | Epoch [02/04], Step [0121/0304], Loss: 0.0112 | Elapsed: 0:01:20\n",
      "| TRAIN SET | Epoch [02/04], Step [0122/0304], Loss: 0.0000 | Elapsed: 0:01:21\n",
      "| TRAIN SET | Epoch [02/04], Step [0123/0304], Loss: 0.0000 | Elapsed: 0:01:21\n",
      "| TRAIN SET | Epoch [02/04], Step [0124/0304], Loss: 0.0000 | Elapsed: 0:01:22\n",
      "| TRAIN SET | Epoch [02/04], Step [0125/0304], Loss: 0.0431 | Elapsed: 0:01:23\n",
      "| TRAIN SET | Epoch [02/04], Step [0126/0304], Loss: 0.0380 | Elapsed: 0:01:23\n",
      "| TRAIN SET | Epoch [02/04], Step [0127/0304], Loss: 0.0544 | Elapsed: 0:01:24\n",
      "| TRAIN SET | Epoch [02/04], Step [0128/0304], Loss: 0.0522 | Elapsed: 0:01:25\n",
      "| TRAIN SET | Epoch [02/04], Step [0129/0304], Loss: 0.0003 | Elapsed: 0:01:25\n",
      "| TRAIN SET | Epoch [02/04], Step [0130/0304], Loss: 0.0272 | Elapsed: 0:01:26\n",
      "| TRAIN SET | Epoch [02/04], Step [0131/0304], Loss: 0.0000 | Elapsed: 0:01:27\n",
      "| TRAIN SET | Epoch [02/04], Step [0132/0304], Loss: 0.0937 | Elapsed: 0:01:27\n",
      "| TRAIN SET | Epoch [02/04], Step [0133/0304], Loss: 0.0000 | Elapsed: 0:01:28\n",
      "| TRAIN SET | Epoch [02/04], Step [0134/0304], Loss: 0.0301 | Elapsed: 0:01:29\n",
      "| TRAIN SET | Epoch [02/04], Step [0135/0304], Loss: 0.0000 | Elapsed: 0:01:29\n",
      "| TRAIN SET | Epoch [02/04], Step [0136/0304], Loss: 0.0469 | Elapsed: 0:01:30\n",
      "| TRAIN SET | Epoch [02/04], Step [0137/0304], Loss: 0.2424 | Elapsed: 0:01:31\n",
      "| TRAIN SET | Epoch [02/04], Step [0138/0304], Loss: 0.0127 | Elapsed: 0:01:31\n",
      "| TRAIN SET | Epoch [02/04], Step [0139/0304], Loss: 0.0539 | Elapsed: 0:01:32\n",
      "| TRAIN SET | Epoch [02/04], Step [0140/0304], Loss: 0.0136 | Elapsed: 0:01:32\n",
      "| TRAIN SET | Epoch [02/04], Step [0141/0304], Loss: 0.0280 | Elapsed: 0:01:33\n",
      "| TRAIN SET | Epoch [02/04], Step [0142/0304], Loss: 0.0071 | Elapsed: 0:01:34\n",
      "| TRAIN SET | Epoch [02/04], Step [0143/0304], Loss: 0.0000 | Elapsed: 0:01:34\n",
      "| TRAIN SET | Epoch [02/04], Step [0144/0304], Loss: 0.0000 | Elapsed: 0:01:35\n",
      "| TRAIN SET | Epoch [02/04], Step [0145/0304], Loss: 0.0000 | Elapsed: 0:01:36\n",
      "| TRAIN SET | Epoch [02/04], Step [0146/0304], Loss: 0.0000 | Elapsed: 0:01:36\n",
      "| TRAIN SET | Epoch [02/04], Step [0147/0304], Loss: 0.0238 | Elapsed: 0:01:37\n",
      "| TRAIN SET | Epoch [02/04], Step [0148/0304], Loss: 0.0000 | Elapsed: 0:01:38\n",
      "| TRAIN SET | Epoch [02/04], Step [0149/0304], Loss: 0.0900 | Elapsed: 0:01:38\n",
      "| TRAIN SET | Epoch [02/04], Step [0150/0304], Loss: 0.0121 | Elapsed: 0:01:39\n",
      "| TRAIN SET | Epoch [02/04], Step [0151/0304], Loss: 0.0727 | Elapsed: 0:01:40\n",
      "| TRAIN SET | Epoch [02/04], Step [0152/0304], Loss: 0.0031 | Elapsed: 0:01:40\n",
      "| TRAIN SET | Epoch [02/04], Step [0153/0304], Loss: 0.0000 | Elapsed: 0:01:41\n",
      "| TRAIN SET | Epoch [02/04], Step [0154/0304], Loss: 0.0000 | Elapsed: 0:01:42\n",
      "| TRAIN SET | Epoch [02/04], Step [0155/0304], Loss: 0.0000 | Elapsed: 0:01:42\n",
      "| TRAIN SET | Epoch [02/04], Step [0156/0304], Loss: 0.1248 | Elapsed: 0:01:43\n",
      "| TRAIN SET | Epoch [02/04], Step [0157/0304], Loss: 0.0056 | Elapsed: 0:01:44\n",
      "| TRAIN SET | Epoch [02/04], Step [0158/0304], Loss: 0.0000 | Elapsed: 0:01:44\n",
      "| TRAIN SET | Epoch [02/04], Step [0159/0304], Loss: 0.0684 | Elapsed: 0:01:45\n",
      "| TRAIN SET | Epoch [02/04], Step [0160/0304], Loss: 0.0679 | Elapsed: 0:01:45\n",
      "| TRAIN SET | Epoch [02/04], Step [0161/0304], Loss: 0.0000 | Elapsed: 0:01:46\n",
      "| TRAIN SET | Epoch [02/04], Step [0162/0304], Loss: 0.0000 | Elapsed: 0:01:47\n",
      "| TRAIN SET | Epoch [02/04], Step [0163/0304], Loss: 0.0651 | Elapsed: 0:01:47\n",
      "| TRAIN SET | Epoch [02/04], Step [0164/0304], Loss: 0.0000 | Elapsed: 0:01:48\n",
      "| TRAIN SET | Epoch [02/04], Step [0165/0304], Loss: 0.0643 | Elapsed: 0:01:49\n",
      "| TRAIN SET | Epoch [02/04], Step [0166/0304], Loss: 0.0445 | Elapsed: 0:01:49\n",
      "| TRAIN SET | Epoch [02/04], Step [0167/0304], Loss: 0.0463 | Elapsed: 0:01:50\n",
      "| TRAIN SET | Epoch [02/04], Step [0168/0304], Loss: 0.0069 | Elapsed: 0:01:51\n",
      "| TRAIN SET | Epoch [02/04], Step [0169/0304], Loss: 0.0123 | Elapsed: 0:01:51\n",
      "| TRAIN SET | Epoch [02/04], Step [0170/0304], Loss: 0.1261 | Elapsed: 0:01:52\n",
      "| TRAIN SET | Epoch [02/04], Step [0171/0304], Loss: 0.0000 | Elapsed: 0:01:53\n",
      "| TRAIN SET | Epoch [02/04], Step [0172/0304], Loss: 0.0022 | Elapsed: 0:01:53\n",
      "| TRAIN SET | Epoch [02/04], Step [0173/0304], Loss: 0.0547 | Elapsed: 0:01:54\n",
      "| TRAIN SET | Epoch [02/04], Step [0174/0304], Loss: 0.0156 | Elapsed: 0:01:55\n",
      "| TRAIN SET | Epoch [02/04], Step [0175/0304], Loss: 0.0495 | Elapsed: 0:01:55\n",
      "| TRAIN SET | Epoch [02/04], Step [0176/0304], Loss: 0.0000 | Elapsed: 0:01:56\n",
      "| TRAIN SET | Epoch [02/04], Step [0177/0304], Loss: 0.0000 | Elapsed: 0:01:57\n",
      "| TRAIN SET | Epoch [02/04], Step [0178/0304], Loss: 0.0000 | Elapsed: 0:01:57\n",
      "| TRAIN SET | Epoch [02/04], Step [0179/0304], Loss: 0.1212 | Elapsed: 0:01:58\n",
      "| TRAIN SET | Epoch [02/04], Step [0180/0304], Loss: 0.1137 | Elapsed: 0:01:58\n",
      "| TRAIN SET | Epoch [02/04], Step [0181/0304], Loss: 0.0911 | Elapsed: 0:01:59\n",
      "| TRAIN SET | Epoch [02/04], Step [0182/0304], Loss: 0.0986 | Elapsed: 0:02:00\n",
      "| TRAIN SET | Epoch [02/04], Step [0183/0304], Loss: 0.1214 | Elapsed: 0:02:00\n",
      "| TRAIN SET | Epoch [02/04], Step [0184/0304], Loss: 0.0921 | Elapsed: 0:02:01\n",
      "| TRAIN SET | Epoch [02/04], Step [0185/0304], Loss: 0.0641 | Elapsed: 0:02:02\n",
      "| TRAIN SET | Epoch [02/04], Step [0186/0304], Loss: 0.0745 | Elapsed: 0:02:02\n",
      "| TRAIN SET | Epoch [02/04], Step [0187/0304], Loss: 0.0652 | Elapsed: 0:02:03\n",
      "| TRAIN SET | Epoch [02/04], Step [0188/0304], Loss: 0.0000 | Elapsed: 0:02:04\n",
      "| TRAIN SET | Epoch [02/04], Step [0189/0304], Loss: 0.0138 | Elapsed: 0:02:04\n",
      "| TRAIN SET | Epoch [02/04], Step [0190/0304], Loss: 0.0105 | Elapsed: 0:02:05\n",
      "| TRAIN SET | Epoch [02/04], Step [0191/0304], Loss: 0.0000 | Elapsed: 0:02:06\n",
      "| TRAIN SET | Epoch [02/04], Step [0192/0304], Loss: 0.0000 | Elapsed: 0:02:06\n",
      "| TRAIN SET | Epoch [02/04], Step [0193/0304], Loss: 0.0603 | Elapsed: 0:02:07\n",
      "| TRAIN SET | Epoch [02/04], Step [0194/0304], Loss: 0.0000 | Elapsed: 0:02:08\n",
      "| TRAIN SET | Epoch [02/04], Step [0195/0304], Loss: 0.0000 | Elapsed: 0:02:08\n",
      "| TRAIN SET | Epoch [02/04], Step [0196/0304], Loss: 0.1334 | Elapsed: 0:02:09\n",
      "| TRAIN SET | Epoch [02/04], Step [0197/0304], Loss: 0.0527 | Elapsed: 0:02:10\n",
      "| TRAIN SET | Epoch [02/04], Step [0198/0304], Loss: 0.0160 | Elapsed: 0:02:10\n",
      "| TRAIN SET | Epoch [02/04], Step [0199/0304], Loss: 0.0686 | Elapsed: 0:02:11\n",
      "| TRAIN SET | Epoch [02/04], Step [0200/0304], Loss: 0.0000 | Elapsed: 0:02:12\n",
      "| TRAIN SET | Epoch [02/04], Step [0201/0304], Loss: 0.0000 | Elapsed: 0:02:13\n",
      "| TRAIN SET | Epoch [02/04], Step [0202/0304], Loss: 0.0000 | Elapsed: 0:02:14\n",
      "| TRAIN SET | Epoch [02/04], Step [0203/0304], Loss: 0.0768 | Elapsed: 0:02:14\n",
      "| TRAIN SET | Epoch [02/04], Step [0204/0304], Loss: 0.0000 | Elapsed: 0:02:15\n",
      "| TRAIN SET | Epoch [02/04], Step [0205/0304], Loss: 0.0000 | Elapsed: 0:02:16\n",
      "| TRAIN SET | Epoch [02/04], Step [0206/0304], Loss: 0.0332 | Elapsed: 0:02:16\n",
      "| TRAIN SET | Epoch [02/04], Step [0207/0304], Loss: 0.0000 | Elapsed: 0:02:17\n",
      "| TRAIN SET | Epoch [02/04], Step [0208/0304], Loss: 0.0633 | Elapsed: 0:02:17\n",
      "| TRAIN SET | Epoch [02/04], Step [0209/0304], Loss: 0.0563 | Elapsed: 0:02:18\n",
      "| TRAIN SET | Epoch [02/04], Step [0210/0304], Loss: 0.0408 | Elapsed: 0:02:19\n",
      "| TRAIN SET | Epoch [02/04], Step [0211/0304], Loss: 0.0000 | Elapsed: 0:02:19\n",
      "| TRAIN SET | Epoch [02/04], Step [0212/0304], Loss: 0.1075 | Elapsed: 0:02:20\n",
      "| TRAIN SET | Epoch [02/04], Step [0213/0304], Loss: 0.0416 | Elapsed: 0:02:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [02/04], Step [0214/0304], Loss: 0.0840 | Elapsed: 0:02:21\n",
      "| TRAIN SET | Epoch [02/04], Step [0215/0304], Loss: 0.0472 | Elapsed: 0:02:22\n",
      "| TRAIN SET | Epoch [02/04], Step [0216/0304], Loss: 0.2139 | Elapsed: 0:02:23\n",
      "| TRAIN SET | Epoch [02/04], Step [0217/0304], Loss: 0.0506 | Elapsed: 0:02:23\n",
      "| TRAIN SET | Epoch [02/04], Step [0218/0304], Loss: 0.0359 | Elapsed: 0:02:24\n",
      "| TRAIN SET | Epoch [02/04], Step [0219/0304], Loss: 0.0255 | Elapsed: 0:02:25\n",
      "| TRAIN SET | Epoch [02/04], Step [0220/0304], Loss: 0.0018 | Elapsed: 0:02:25\n",
      "| TRAIN SET | Epoch [02/04], Step [0221/0304], Loss: 0.1350 | Elapsed: 0:02:26\n",
      "| TRAIN SET | Epoch [02/04], Step [0222/0304], Loss: 0.0000 | Elapsed: 0:02:27\n",
      "| TRAIN SET | Epoch [02/04], Step [0223/0304], Loss: 0.1151 | Elapsed: 0:02:27\n",
      "| TRAIN SET | Epoch [02/04], Step [0224/0304], Loss: 0.0000 | Elapsed: 0:02:28\n",
      "| TRAIN SET | Epoch [02/04], Step [0225/0304], Loss: 0.0736 | Elapsed: 0:02:28\n",
      "| TRAIN SET | Epoch [02/04], Step [0226/0304], Loss: 0.0012 | Elapsed: 0:02:29\n",
      "| TRAIN SET | Epoch [02/04], Step [0227/0304], Loss: 0.0000 | Elapsed: 0:02:30\n",
      "| TRAIN SET | Epoch [02/04], Step [0228/0304], Loss: 0.0577 | Elapsed: 0:02:30\n",
      "| TRAIN SET | Epoch [02/04], Step [0229/0304], Loss: 0.0757 | Elapsed: 0:02:31\n",
      "| TRAIN SET | Epoch [02/04], Step [0230/0304], Loss: 0.0106 | Elapsed: 0:02:32\n",
      "| TRAIN SET | Epoch [02/04], Step [0231/0304], Loss: 0.0934 | Elapsed: 0:02:32\n",
      "| TRAIN SET | Epoch [02/04], Step [0232/0304], Loss: 0.0031 | Elapsed: 0:02:33\n",
      "| TRAIN SET | Epoch [02/04], Step [0233/0304], Loss: 0.0000 | Elapsed: 0:02:34\n",
      "| TRAIN SET | Epoch [02/04], Step [0234/0304], Loss: 0.0638 | Elapsed: 0:02:34\n",
      "| TRAIN SET | Epoch [02/04], Step [0235/0304], Loss: 0.0000 | Elapsed: 0:02:35\n",
      "| TRAIN SET | Epoch [02/04], Step [0236/0304], Loss: 0.0543 | Elapsed: 0:02:36\n",
      "| TRAIN SET | Epoch [02/04], Step [0237/0304], Loss: 0.0000 | Elapsed: 0:02:36\n",
      "| TRAIN SET | Epoch [02/04], Step [0238/0304], Loss: 0.4355 | Elapsed: 0:02:37\n",
      "| TRAIN SET | Epoch [02/04], Step [0239/0304], Loss: 0.0000 | Elapsed: 0:02:38\n",
      "| TRAIN SET | Epoch [02/04], Step [0240/0304], Loss: 0.1111 | Elapsed: 0:02:38\n",
      "| TRAIN SET | Epoch [02/04], Step [0241/0304], Loss: 0.0031 | Elapsed: 0:02:39\n",
      "| TRAIN SET | Epoch [02/04], Step [0242/0304], Loss: 0.0000 | Elapsed: 0:02:40\n",
      "| TRAIN SET | Epoch [02/04], Step [0243/0304], Loss: 0.0404 | Elapsed: 0:02:40\n",
      "| TRAIN SET | Epoch [02/04], Step [0244/0304], Loss: 0.0000 | Elapsed: 0:02:41\n",
      "| TRAIN SET | Epoch [02/04], Step [0245/0304], Loss: 0.0049 | Elapsed: 0:02:41\n",
      "| TRAIN SET | Epoch [02/04], Step [0246/0304], Loss: 0.0189 | Elapsed: 0:02:42\n",
      "| TRAIN SET | Epoch [02/04], Step [0247/0304], Loss: 0.0428 | Elapsed: 0:02:43\n",
      "| TRAIN SET | Epoch [02/04], Step [0248/0304], Loss: 0.0000 | Elapsed: 0:02:43\n",
      "| TRAIN SET | Epoch [02/04], Step [0249/0304], Loss: 0.0470 | Elapsed: 0:02:44\n",
      "| TRAIN SET | Epoch [02/04], Step [0250/0304], Loss: 0.0560 | Elapsed: 0:02:45\n",
      "| TRAIN SET | Epoch [02/04], Step [0251/0304], Loss: 0.0000 | Elapsed: 0:02:45\n",
      "| TRAIN SET | Epoch [02/04], Step [0252/0304], Loss: 0.0062 | Elapsed: 0:02:46\n",
      "| TRAIN SET | Epoch [02/04], Step [0253/0304], Loss: 0.0474 | Elapsed: 0:02:47\n",
      "| TRAIN SET | Epoch [02/04], Step [0254/0304], Loss: 0.0714 | Elapsed: 0:02:47\n",
      "| TRAIN SET | Epoch [02/04], Step [0255/0304], Loss: 0.0597 | Elapsed: 0:02:48\n",
      "| TRAIN SET | Epoch [02/04], Step [0256/0304], Loss: 0.0000 | Elapsed: 0:02:49\n",
      "| TRAIN SET | Epoch [02/04], Step [0257/0304], Loss: 0.0000 | Elapsed: 0:02:49\n",
      "| TRAIN SET | Epoch [02/04], Step [0258/0304], Loss: 0.0000 | Elapsed: 0:02:50\n",
      "| TRAIN SET | Epoch [02/04], Step [0259/0304], Loss: 0.0000 | Elapsed: 0:02:51\n",
      "| TRAIN SET | Epoch [02/04], Step [0260/0304], Loss: 0.0340 | Elapsed: 0:02:51\n",
      "| TRAIN SET | Epoch [02/04], Step [0261/0304], Loss: 0.0000 | Elapsed: 0:02:52\n",
      "| TRAIN SET | Epoch [02/04], Step [0262/0304], Loss: 0.0000 | Elapsed: 0:02:53\n",
      "| TRAIN SET | Epoch [02/04], Step [0263/0304], Loss: 0.0035 | Elapsed: 0:02:53\n",
      "| TRAIN SET | Epoch [02/04], Step [0264/0304], Loss: 0.0265 | Elapsed: 0:02:54\n",
      "| TRAIN SET | Epoch [02/04], Step [0265/0304], Loss: 0.0000 | Elapsed: 0:02:54\n",
      "| TRAIN SET | Epoch [02/04], Step [0266/0304], Loss: 0.0000 | Elapsed: 0:02:55\n",
      "| TRAIN SET | Epoch [02/04], Step [0267/0304], Loss: 0.1260 | Elapsed: 0:02:56\n",
      "| TRAIN SET | Epoch [02/04], Step [0268/0304], Loss: 0.0858 | Elapsed: 0:02:56\n",
      "| TRAIN SET | Epoch [02/04], Step [0269/0304], Loss: 0.1008 | Elapsed: 0:02:57\n",
      "| TRAIN SET | Epoch [02/04], Step [0270/0304], Loss: 0.1044 | Elapsed: 0:02:58\n",
      "| TRAIN SET | Epoch [02/04], Step [0271/0304], Loss: 0.0000 | Elapsed: 0:02:58\n",
      "| TRAIN SET | Epoch [02/04], Step [0272/0304], Loss: 0.0000 | Elapsed: 0:02:59\n",
      "| TRAIN SET | Epoch [02/04], Step [0273/0304], Loss: 0.1101 | Elapsed: 0:03:00\n",
      "| TRAIN SET | Epoch [02/04], Step [0274/0304], Loss: 0.0000 | Elapsed: 0:03:00\n",
      "| TRAIN SET | Epoch [02/04], Step [0275/0304], Loss: 0.1329 | Elapsed: 0:03:01\n",
      "| TRAIN SET | Epoch [02/04], Step [0276/0304], Loss: 0.0000 | Elapsed: 0:03:02\n",
      "| TRAIN SET | Epoch [02/04], Step [0277/0304], Loss: 0.0631 | Elapsed: 0:03:02\n",
      "| TRAIN SET | Epoch [02/04], Step [0278/0304], Loss: 0.0000 | Elapsed: 0:03:03\n",
      "| TRAIN SET | Epoch [02/04], Step [0279/0304], Loss: 0.0017 | Elapsed: 0:03:04\n",
      "| TRAIN SET | Epoch [02/04], Step [0280/0304], Loss: 0.0903 | Elapsed: 0:03:04\n",
      "| TRAIN SET | Epoch [02/04], Step [0281/0304], Loss: 0.0311 | Elapsed: 0:03:05\n",
      "| TRAIN SET | Epoch [02/04], Step [0282/0304], Loss: 0.0000 | Elapsed: 0:03:06\n",
      "| TRAIN SET | Epoch [02/04], Step [0283/0304], Loss: 0.0000 | Elapsed: 0:03:06\n",
      "| TRAIN SET | Epoch [02/04], Step [0284/0304], Loss: 0.0258 | Elapsed: 0:03:07\n",
      "| TRAIN SET | Epoch [02/04], Step [0285/0304], Loss: 0.0168 | Elapsed: 0:03:07\n",
      "| TRAIN SET | Epoch [02/04], Step [0286/0304], Loss: 0.0000 | Elapsed: 0:03:08\n",
      "| TRAIN SET | Epoch [02/04], Step [0287/0304], Loss: 0.0077 | Elapsed: 0:03:09\n",
      "| TRAIN SET | Epoch [02/04], Step [0288/0304], Loss: 0.0000 | Elapsed: 0:03:09\n",
      "| TRAIN SET | Epoch [02/04], Step [0289/0304], Loss: 0.0164 | Elapsed: 0:03:10\n",
      "| TRAIN SET | Epoch [02/04], Step [0290/0304], Loss: 0.0000 | Elapsed: 0:03:11\n",
      "| TRAIN SET | Epoch [02/04], Step [0291/0304], Loss: 0.0005 | Elapsed: 0:03:11\n",
      "| TRAIN SET | Epoch [02/04], Step [0292/0304], Loss: 0.0418 | Elapsed: 0:03:12\n",
      "| TRAIN SET | Epoch [02/04], Step [0293/0304], Loss: 0.1305 | Elapsed: 0:03:13\n",
      "| TRAIN SET | Epoch [02/04], Step [0294/0304], Loss: 0.0115 | Elapsed: 0:03:13\n",
      "| TRAIN SET | Epoch [02/04], Step [0295/0304], Loss: 0.0095 | Elapsed: 0:03:14\n",
      "| TRAIN SET | Epoch [02/04], Step [0296/0304], Loss: 0.0671 | Elapsed: 0:03:15\n",
      "| TRAIN SET | Epoch [02/04], Step [0297/0304], Loss: 0.0568 | Elapsed: 0:03:15\n",
      "| TRAIN SET | Epoch [02/04], Step [0298/0304], Loss: 0.0525 | Elapsed: 0:03:16\n",
      "| TRAIN SET | Epoch [02/04], Step [0299/0304], Loss: 0.0000 | Elapsed: 0:03:17\n",
      "| TRAIN SET | Epoch [02/04], Step [0300/0304], Loss: 0.0000 | Elapsed: 0:03:18\n",
      "| TRAIN SET | Epoch [02/04], Step [0301/0304], Loss: 0.0000 | Elapsed: 0:03:19\n",
      "| TRAIN SET | Epoch [02/04], Step [0302/0304], Loss: 0.0468 | Elapsed: 0:03:19\n",
      "| TRAIN SET | Epoch [02/04], Step [0303/0304], Loss: 0.1624 | Elapsed: 0:03:20\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:03:21\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "| TRAIN SET | Epoch [03/04], Step [0000/0304], Loss: 0.0000 | Elapsed: 0:00:01\n",
      "| TRAIN SET | Epoch [03/04], Step [0001/0304], Loss: 0.0000 | Elapsed: 0:00:02\n",
      "| TRAIN SET | Epoch [03/04], Step [0002/0304], Loss: 0.0000 | Elapsed: 0:00:02\n",
      "| TRAIN SET | Epoch [03/04], Step [0003/0304], Loss: 0.0000 | Elapsed: 0:00:03\n",
      "| TRAIN SET | Epoch [03/04], Step [0004/0304], Loss: 0.0000 | Elapsed: 0:00:04\n",
      "| TRAIN SET | Epoch [03/04], Step [0005/0304], Loss: 0.0000 | Elapsed: 0:00:04\n",
      "| TRAIN SET | Epoch [03/04], Step [0006/0304], Loss: 0.0627 | Elapsed: 0:00:05\n",
      "| TRAIN SET | Epoch [03/04], Step [0007/0304], Loss: 0.0555 | Elapsed: 0:00:06\n",
      "| TRAIN SET | Epoch [03/04], Step [0008/0304], Loss: 0.0321 | Elapsed: 0:00:06\n",
      "| TRAIN SET | Epoch [03/04], Step [0009/0304], Loss: 0.0000 | Elapsed: 0:00:07\n",
      "| TRAIN SET | Epoch [03/04], Step [0010/0304], Loss: 0.0338 | Elapsed: 0:00:07\n",
      "| TRAIN SET | Epoch [03/04], Step [0011/0304], Loss: 0.0000 | Elapsed: 0:00:08\n",
      "| TRAIN SET | Epoch [03/04], Step [0012/0304], Loss: 0.1014 | Elapsed: 0:00:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [03/04], Step [0013/0304], Loss: 0.0414 | Elapsed: 0:00:09\n",
      "| TRAIN SET | Epoch [03/04], Step [0014/0304], Loss: 0.1100 | Elapsed: 0:00:10\n",
      "| TRAIN SET | Epoch [03/04], Step [0015/0304], Loss: 0.2024 | Elapsed: 0:00:11\n",
      "| TRAIN SET | Epoch [03/04], Step [0016/0304], Loss: 0.0000 | Elapsed: 0:00:11\n",
      "| TRAIN SET | Epoch [03/04], Step [0017/0304], Loss: 0.0984 | Elapsed: 0:00:12\n",
      "| TRAIN SET | Epoch [03/04], Step [0018/0304], Loss: 0.0000 | Elapsed: 0:00:13\n",
      "| TRAIN SET | Epoch [03/04], Step [0019/0304], Loss: 0.0000 | Elapsed: 0:00:13\n",
      "| TRAIN SET | Epoch [03/04], Step [0020/0304], Loss: 0.0000 | Elapsed: 0:00:14\n",
      "| TRAIN SET | Epoch [03/04], Step [0021/0304], Loss: 0.0000 | Elapsed: 0:00:15\n",
      "| TRAIN SET | Epoch [03/04], Step [0022/0304], Loss: 0.0087 | Elapsed: 0:00:15\n",
      "| TRAIN SET | Epoch [03/04], Step [0023/0304], Loss: 0.1390 | Elapsed: 0:00:16\n",
      "| TRAIN SET | Epoch [03/04], Step [0024/0304], Loss: 0.0259 | Elapsed: 0:00:16\n",
      "| TRAIN SET | Epoch [03/04], Step [0025/0304], Loss: 0.0232 | Elapsed: 0:00:17\n",
      "| TRAIN SET | Epoch [03/04], Step [0026/0304], Loss: 0.0042 | Elapsed: 0:00:18\n",
      "| TRAIN SET | Epoch [03/04], Step [0027/0304], Loss: 0.0000 | Elapsed: 0:00:18\n",
      "| TRAIN SET | Epoch [03/04], Step [0028/0304], Loss: 0.1146 | Elapsed: 0:00:19\n",
      "| TRAIN SET | Epoch [03/04], Step [0029/0304], Loss: 0.0316 | Elapsed: 0:00:20\n",
      "| TRAIN SET | Epoch [03/04], Step [0030/0304], Loss: 0.0945 | Elapsed: 0:00:20\n",
      "| TRAIN SET | Epoch [03/04], Step [0031/0304], Loss: 0.3765 | Elapsed: 0:00:21\n",
      "| TRAIN SET | Epoch [03/04], Step [0032/0304], Loss: 0.0961 | Elapsed: 0:00:22\n",
      "| TRAIN SET | Epoch [03/04], Step [0033/0304], Loss: 0.0377 | Elapsed: 0:00:22\n",
      "| TRAIN SET | Epoch [03/04], Step [0034/0304], Loss: 0.0000 | Elapsed: 0:00:23\n",
      "| TRAIN SET | Epoch [03/04], Step [0035/0304], Loss: 0.0000 | Elapsed: 0:00:24\n",
      "| TRAIN SET | Epoch [03/04], Step [0036/0304], Loss: 0.0800 | Elapsed: 0:00:24\n",
      "| TRAIN SET | Epoch [03/04], Step [0037/0304], Loss: 0.0000 | Elapsed: 0:00:25\n",
      "| TRAIN SET | Epoch [03/04], Step [0038/0304], Loss: 0.0837 | Elapsed: 0:00:26\n",
      "| TRAIN SET | Epoch [03/04], Step [0039/0304], Loss: 0.0000 | Elapsed: 0:00:26\n",
      "| TRAIN SET | Epoch [03/04], Step [0040/0304], Loss: 0.2131 | Elapsed: 0:00:27\n",
      "| TRAIN SET | Epoch [03/04], Step [0041/0304], Loss: 0.0678 | Elapsed: 0:00:28\n",
      "| TRAIN SET | Epoch [03/04], Step [0042/0304], Loss: 0.0000 | Elapsed: 0:00:28\n",
      "| TRAIN SET | Epoch [03/04], Step [0043/0304], Loss: 0.0209 | Elapsed: 0:00:29\n",
      "| TRAIN SET | Epoch [03/04], Step [0044/0304], Loss: 0.0000 | Elapsed: 0:00:29\n",
      "| TRAIN SET | Epoch [03/04], Step [0045/0304], Loss: 0.0000 | Elapsed: 0:00:30\n",
      "| TRAIN SET | Epoch [03/04], Step [0046/0304], Loss: 0.0000 | Elapsed: 0:00:31\n",
      "| TRAIN SET | Epoch [03/04], Step [0047/0304], Loss: 0.0892 | Elapsed: 0:00:31\n",
      "| TRAIN SET | Epoch [03/04], Step [0048/0304], Loss: 0.0517 | Elapsed: 0:00:32\n",
      "| TRAIN SET | Epoch [03/04], Step [0049/0304], Loss: 0.1257 | Elapsed: 0:00:33\n",
      "| TRAIN SET | Epoch [03/04], Step [0050/0304], Loss: 0.0517 | Elapsed: 0:00:33\n",
      "| TRAIN SET | Epoch [03/04], Step [0051/0304], Loss: 0.0000 | Elapsed: 0:00:34\n",
      "| TRAIN SET | Epoch [03/04], Step [0052/0304], Loss: 0.0000 | Elapsed: 0:00:35\n",
      "| TRAIN SET | Epoch [03/04], Step [0053/0304], Loss: 0.0000 | Elapsed: 0:00:35\n",
      "| TRAIN SET | Epoch [03/04], Step [0054/0304], Loss: 0.0000 | Elapsed: 0:00:36\n",
      "| TRAIN SET | Epoch [03/04], Step [0055/0304], Loss: 0.1366 | Elapsed: 0:00:37\n",
      "| TRAIN SET | Epoch [03/04], Step [0056/0304], Loss: 0.0000 | Elapsed: 0:00:37\n",
      "| TRAIN SET | Epoch [03/04], Step [0057/0304], Loss: 0.0000 | Elapsed: 0:00:38\n",
      "| TRAIN SET | Epoch [03/04], Step [0058/0304], Loss: 0.0500 | Elapsed: 0:00:39\n",
      "| TRAIN SET | Epoch [03/04], Step [0059/0304], Loss: 0.0000 | Elapsed: 0:00:39\n",
      "| TRAIN SET | Epoch [03/04], Step [0060/0304], Loss: 0.0857 | Elapsed: 0:00:40\n",
      "| TRAIN SET | Epoch [03/04], Step [0061/0304], Loss: 0.1227 | Elapsed: 0:00:40\n",
      "| TRAIN SET | Epoch [03/04], Step [0062/0304], Loss: 0.0556 | Elapsed: 0:00:41\n",
      "| TRAIN SET | Epoch [03/04], Step [0063/0304], Loss: 0.3955 | Elapsed: 0:00:42\n",
      "| TRAIN SET | Epoch [03/04], Step [0064/0304], Loss: 0.0000 | Elapsed: 0:00:42\n",
      "| TRAIN SET | Epoch [03/04], Step [0065/0304], Loss: 0.0000 | Elapsed: 0:00:43\n",
      "| TRAIN SET | Epoch [03/04], Step [0066/0304], Loss: 0.0000 | Elapsed: 0:00:44\n",
      "| TRAIN SET | Epoch [03/04], Step [0067/0304], Loss: 0.0433 | Elapsed: 0:00:44\n",
      "| TRAIN SET | Epoch [03/04], Step [0068/0304], Loss: 0.1525 | Elapsed: 0:00:45\n",
      "| TRAIN SET | Epoch [03/04], Step [0069/0304], Loss: 0.0000 | Elapsed: 0:00:46\n",
      "| TRAIN SET | Epoch [03/04], Step [0070/0304], Loss: 0.0087 | Elapsed: 0:00:46\n",
      "| TRAIN SET | Epoch [03/04], Step [0071/0304], Loss: 0.0805 | Elapsed: 0:00:47\n",
      "| TRAIN SET | Epoch [03/04], Step [0072/0304], Loss: 0.0675 | Elapsed: 0:00:48\n",
      "| TRAIN SET | Epoch [03/04], Step [0073/0304], Loss: 0.0000 | Elapsed: 0:00:48\n",
      "| TRAIN SET | Epoch [03/04], Step [0074/0304], Loss: 0.0000 | Elapsed: 0:00:49\n",
      "| TRAIN SET | Epoch [03/04], Step [0075/0304], Loss: 0.0656 | Elapsed: 0:00:50\n",
      "| TRAIN SET | Epoch [03/04], Step [0076/0304], Loss: 0.0694 | Elapsed: 0:00:50\n",
      "| TRAIN SET | Epoch [03/04], Step [0077/0304], Loss: 0.1581 | Elapsed: 0:00:51\n",
      "| TRAIN SET | Epoch [03/04], Step [0078/0304], Loss: 0.0000 | Elapsed: 0:00:52\n",
      "| TRAIN SET | Epoch [03/04], Step [0079/0304], Loss: 0.0355 | Elapsed: 0:00:52\n",
      "| TRAIN SET | Epoch [03/04], Step [0080/0304], Loss: 0.0278 | Elapsed: 0:00:53\n",
      "| TRAIN SET | Epoch [03/04], Step [0081/0304], Loss: 0.0000 | Elapsed: 0:00:53\n",
      "| TRAIN SET | Epoch [03/04], Step [0082/0304], Loss: 0.0684 | Elapsed: 0:00:54\n",
      "| TRAIN SET | Epoch [03/04], Step [0083/0304], Loss: 0.0543 | Elapsed: 0:00:55\n",
      "| TRAIN SET | Epoch [03/04], Step [0084/0304], Loss: 0.0838 | Elapsed: 0:00:55\n",
      "| TRAIN SET | Epoch [03/04], Step [0085/0304], Loss: 0.0716 | Elapsed: 0:00:56\n",
      "| TRAIN SET | Epoch [03/04], Step [0086/0304], Loss: 0.0000 | Elapsed: 0:00:57\n",
      "| TRAIN SET | Epoch [03/04], Step [0087/0304], Loss: 0.0354 | Elapsed: 0:00:57\n",
      "| TRAIN SET | Epoch [03/04], Step [0088/0304], Loss: 0.0000 | Elapsed: 0:00:58\n",
      "| TRAIN SET | Epoch [03/04], Step [0089/0304], Loss: 0.1482 | Elapsed: 0:00:59\n",
      "| TRAIN SET | Epoch [03/04], Step [0090/0304], Loss: 0.0000 | Elapsed: 0:00:59\n",
      "| TRAIN SET | Epoch [03/04], Step [0091/0304], Loss: 0.0279 | Elapsed: 0:01:00\n",
      "| TRAIN SET | Epoch [03/04], Step [0092/0304], Loss: 0.0000 | Elapsed: 0:01:01\n",
      "| TRAIN SET | Epoch [03/04], Step [0093/0304], Loss: 0.0346 | Elapsed: 0:01:01\n",
      "| TRAIN SET | Epoch [03/04], Step [0094/0304], Loss: 0.0000 | Elapsed: 0:01:02\n",
      "| TRAIN SET | Epoch [03/04], Step [0095/0304], Loss: 0.0000 | Elapsed: 0:01:03\n",
      "| TRAIN SET | Epoch [03/04], Step [0096/0304], Loss: 0.0716 | Elapsed: 0:01:03\n",
      "| TRAIN SET | Epoch [03/04], Step [0097/0304], Loss: 0.0000 | Elapsed: 0:01:04\n",
      "| TRAIN SET | Epoch [03/04], Step [0098/0304], Loss: 0.0000 | Elapsed: 0:01:05\n",
      "| TRAIN SET | Epoch [03/04], Step [0099/0304], Loss: 0.0000 | Elapsed: 0:01:05\n",
      "| TRAIN SET | Epoch [03/04], Step [0100/0304], Loss: 0.0040 | Elapsed: 0:01:07\n",
      "| TRAIN SET | Epoch [03/04], Step [0101/0304], Loss: 0.0637 | Elapsed: 0:01:07\n",
      "| TRAIN SET | Epoch [03/04], Step [0102/0304], Loss: 0.0330 | Elapsed: 0:01:08\n",
      "| TRAIN SET | Epoch [03/04], Step [0103/0304], Loss: 0.0000 | Elapsed: 0:01:09\n",
      "| TRAIN SET | Epoch [03/04], Step [0104/0304], Loss: 0.1587 | Elapsed: 0:01:09\n",
      "| TRAIN SET | Epoch [03/04], Step [0105/0304], Loss: 0.0510 | Elapsed: 0:01:10\n",
      "| TRAIN SET | Epoch [03/04], Step [0106/0304], Loss: 0.0789 | Elapsed: 0:01:11\n",
      "| TRAIN SET | Epoch [03/04], Step [0107/0304], Loss: 0.1188 | Elapsed: 0:01:11\n",
      "| TRAIN SET | Epoch [03/04], Step [0108/0304], Loss: 0.0380 | Elapsed: 0:01:12\n",
      "| TRAIN SET | Epoch [03/04], Step [0109/0304], Loss: 0.0000 | Elapsed: 0:01:13\n",
      "| TRAIN SET | Epoch [03/04], Step [0110/0304], Loss: 0.0137 | Elapsed: 0:01:13\n",
      "| TRAIN SET | Epoch [03/04], Step [0111/0304], Loss: 0.1896 | Elapsed: 0:01:14\n",
      "| TRAIN SET | Epoch [03/04], Step [0112/0304], Loss: 0.0000 | Elapsed: 0:01:14\n",
      "| TRAIN SET | Epoch [03/04], Step [0113/0304], Loss: 0.0000 | Elapsed: 0:01:15\n",
      "| TRAIN SET | Epoch [03/04], Step [0114/0304], Loss: 0.0000 | Elapsed: 0:01:16\n",
      "| TRAIN SET | Epoch [03/04], Step [0115/0304], Loss: 0.0709 | Elapsed: 0:01:16\n",
      "| TRAIN SET | Epoch [03/04], Step [0116/0304], Loss: 0.0000 | Elapsed: 0:01:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [03/04], Step [0117/0304], Loss: 0.0000 | Elapsed: 0:01:18\n",
      "| TRAIN SET | Epoch [03/04], Step [0118/0304], Loss: 0.0539 | Elapsed: 0:01:18\n",
      "| TRAIN SET | Epoch [03/04], Step [0119/0304], Loss: 0.0637 | Elapsed: 0:01:19\n",
      "| TRAIN SET | Epoch [03/04], Step [0120/0304], Loss: 0.0123 | Elapsed: 0:01:20\n",
      "| TRAIN SET | Epoch [03/04], Step [0121/0304], Loss: 0.0048 | Elapsed: 0:01:20\n",
      "| TRAIN SET | Epoch [03/04], Step [0122/0304], Loss: 0.0000 | Elapsed: 0:01:21\n",
      "| TRAIN SET | Epoch [03/04], Step [0123/0304], Loss: 0.0442 | Elapsed: 0:01:22\n",
      "| TRAIN SET | Epoch [03/04], Step [0124/0304], Loss: 0.0000 | Elapsed: 0:01:22\n",
      "| TRAIN SET | Epoch [03/04], Step [0125/0304], Loss: 0.0556 | Elapsed: 0:01:23\n",
      "| TRAIN SET | Epoch [03/04], Step [0126/0304], Loss: 0.0000 | Elapsed: 0:01:24\n",
      "| TRAIN SET | Epoch [03/04], Step [0127/0304], Loss: 0.0000 | Elapsed: 0:01:24\n",
      "| TRAIN SET | Epoch [03/04], Step [0128/0304], Loss: 0.0405 | Elapsed: 0:01:25\n",
      "| TRAIN SET | Epoch [03/04], Step [0129/0304], Loss: 0.0357 | Elapsed: 0:01:26\n",
      "| TRAIN SET | Epoch [03/04], Step [0130/0304], Loss: 0.0239 | Elapsed: 0:01:26\n",
      "| TRAIN SET | Epoch [03/04], Step [0131/0304], Loss: 0.0206 | Elapsed: 0:01:27\n",
      "| TRAIN SET | Epoch [03/04], Step [0132/0304], Loss: 0.1002 | Elapsed: 0:01:27\n",
      "| TRAIN SET | Epoch [03/04], Step [0133/0304], Loss: 0.0734 | Elapsed: 0:01:28\n",
      "| TRAIN SET | Epoch [03/04], Step [0134/0304], Loss: 0.0131 | Elapsed: 0:01:29\n",
      "| TRAIN SET | Epoch [03/04], Step [0135/0304], Loss: 0.0440 | Elapsed: 0:01:29\n",
      "| TRAIN SET | Epoch [03/04], Step [0136/0304], Loss: 0.0000 | Elapsed: 0:01:30\n",
      "| TRAIN SET | Epoch [03/04], Step [0137/0304], Loss: 0.0407 | Elapsed: 0:01:31\n",
      "| TRAIN SET | Epoch [03/04], Step [0138/0304], Loss: 0.0000 | Elapsed: 0:01:31\n",
      "| TRAIN SET | Epoch [03/04], Step [0139/0304], Loss: 0.1661 | Elapsed: 0:01:32\n",
      "| TRAIN SET | Epoch [03/04], Step [0140/0304], Loss: 0.0484 | Elapsed: 0:01:33\n",
      "| TRAIN SET | Epoch [03/04], Step [0141/0304], Loss: 0.0000 | Elapsed: 0:01:33\n",
      "| TRAIN SET | Epoch [03/04], Step [0142/0304], Loss: 0.0587 | Elapsed: 0:01:34\n",
      "| TRAIN SET | Epoch [03/04], Step [0143/0304], Loss: 0.0730 | Elapsed: 0:01:35\n",
      "| TRAIN SET | Epoch [03/04], Step [0144/0304], Loss: 0.0000 | Elapsed: 0:01:35\n",
      "| TRAIN SET | Epoch [03/04], Step [0145/0304], Loss: 0.0000 | Elapsed: 0:01:36\n",
      "| TRAIN SET | Epoch [03/04], Step [0146/0304], Loss: 0.0000 | Elapsed: 0:01:37\n",
      "| TRAIN SET | Epoch [03/04], Step [0147/0304], Loss: 0.0323 | Elapsed: 0:01:37\n",
      "| TRAIN SET | Epoch [03/04], Step [0148/0304], Loss: 0.0000 | Elapsed: 0:01:38\n",
      "| TRAIN SET | Epoch [03/04], Step [0149/0304], Loss: 0.0000 | Elapsed: 0:01:39\n",
      "| TRAIN SET | Epoch [03/04], Step [0150/0304], Loss: 0.0584 | Elapsed: 0:01:39\n",
      "| TRAIN SET | Epoch [03/04], Step [0151/0304], Loss: 0.0168 | Elapsed: 0:01:40\n",
      "| TRAIN SET | Epoch [03/04], Step [0152/0304], Loss: 0.1337 | Elapsed: 0:01:40\n",
      "| TRAIN SET | Epoch [03/04], Step [0153/0304], Loss: 0.0672 | Elapsed: 0:01:41\n",
      "| TRAIN SET | Epoch [03/04], Step [0154/0304], Loss: 0.0156 | Elapsed: 0:01:42\n",
      "| TRAIN SET | Epoch [03/04], Step [0155/0304], Loss: 0.0000 | Elapsed: 0:01:42\n",
      "| TRAIN SET | Epoch [03/04], Step [0156/0304], Loss: 0.0634 | Elapsed: 0:01:43\n",
      "| TRAIN SET | Epoch [03/04], Step [0157/0304], Loss: 0.0000 | Elapsed: 0:01:44\n",
      "| TRAIN SET | Epoch [03/04], Step [0158/0304], Loss: 0.0434 | Elapsed: 0:01:44\n",
      "| TRAIN SET | Epoch [03/04], Step [0159/0304], Loss: 0.1336 | Elapsed: 0:01:45\n",
      "| TRAIN SET | Epoch [03/04], Step [0160/0304], Loss: 0.0703 | Elapsed: 0:01:46\n",
      "| TRAIN SET | Epoch [03/04], Step [0161/0304], Loss: 0.0000 | Elapsed: 0:01:46\n",
      "| TRAIN SET | Epoch [03/04], Step [0162/0304], Loss: 0.0541 | Elapsed: 0:01:47\n",
      "| TRAIN SET | Epoch [03/04], Step [0163/0304], Loss: 0.0169 | Elapsed: 0:01:48\n",
      "| TRAIN SET | Epoch [03/04], Step [0164/0304], Loss: 0.0591 | Elapsed: 0:01:48\n",
      "| TRAIN SET | Epoch [03/04], Step [0165/0304], Loss: 0.0000 | Elapsed: 0:01:49\n",
      "| TRAIN SET | Epoch [03/04], Step [0166/0304], Loss: 0.0349 | Elapsed: 0:01:50\n",
      "| TRAIN SET | Epoch [03/04], Step [0167/0304], Loss: 0.0890 | Elapsed: 0:01:50\n",
      "| TRAIN SET | Epoch [03/04], Step [0168/0304], Loss: 0.0000 | Elapsed: 0:01:51\n",
      "| TRAIN SET | Epoch [03/04], Step [0169/0304], Loss: 0.0257 | Elapsed: 0:01:52\n",
      "| TRAIN SET | Epoch [03/04], Step [0170/0304], Loss: 0.0642 | Elapsed: 0:01:52\n",
      "| TRAIN SET | Epoch [03/04], Step [0171/0304], Loss: 0.0223 | Elapsed: 0:01:53\n",
      "| TRAIN SET | Epoch [03/04], Step [0172/0304], Loss: 0.0000 | Elapsed: 0:01:54\n",
      "| TRAIN SET | Epoch [03/04], Step [0173/0304], Loss: 0.0000 | Elapsed: 0:01:54\n",
      "| TRAIN SET | Epoch [03/04], Step [0174/0304], Loss: 0.0000 | Elapsed: 0:01:55\n",
      "| TRAIN SET | Epoch [03/04], Step [0175/0304], Loss: 0.0000 | Elapsed: 0:01:55\n",
      "| TRAIN SET | Epoch [03/04], Step [0176/0304], Loss: 0.0787 | Elapsed: 0:01:56\n",
      "| TRAIN SET | Epoch [03/04], Step [0177/0304], Loss: 0.0000 | Elapsed: 0:01:57\n",
      "| TRAIN SET | Epoch [03/04], Step [0178/0304], Loss: 0.0780 | Elapsed: 0:01:57\n",
      "| TRAIN SET | Epoch [03/04], Step [0179/0304], Loss: 0.3664 | Elapsed: 0:01:58\n",
      "| TRAIN SET | Epoch [03/04], Step [0180/0304], Loss: 0.0000 | Elapsed: 0:01:59\n",
      "| TRAIN SET | Epoch [03/04], Step [0181/0304], Loss: 0.0000 | Elapsed: 0:01:59\n",
      "| TRAIN SET | Epoch [03/04], Step [0182/0304], Loss: 0.1755 | Elapsed: 0:02:00\n",
      "| TRAIN SET | Epoch [03/04], Step [0183/0304], Loss: 0.0000 | Elapsed: 0:02:01\n",
      "| TRAIN SET | Epoch [03/04], Step [0184/0304], Loss: 0.0972 | Elapsed: 0:02:01\n",
      "| TRAIN SET | Epoch [03/04], Step [0185/0304], Loss: 0.0000 | Elapsed: 0:02:02\n",
      "| TRAIN SET | Epoch [03/04], Step [0186/0304], Loss: 0.0000 | Elapsed: 0:02:03\n",
      "| TRAIN SET | Epoch [03/04], Step [0187/0304], Loss: 0.1304 | Elapsed: 0:02:03\n",
      "| TRAIN SET | Epoch [03/04], Step [0188/0304], Loss: 0.0000 | Elapsed: 0:02:04\n",
      "| TRAIN SET | Epoch [03/04], Step [0189/0304], Loss: 0.0000 | Elapsed: 0:02:05\n",
      "| TRAIN SET | Epoch [03/04], Step [0190/0304], Loss: 0.0000 | Elapsed: 0:02:05\n",
      "| TRAIN SET | Epoch [03/04], Step [0191/0304], Loss: 0.0283 | Elapsed: 0:02:06\n",
      "| TRAIN SET | Epoch [03/04], Step [0192/0304], Loss: 0.0448 | Elapsed: 0:02:07\n",
      "| TRAIN SET | Epoch [03/04], Step [0193/0304], Loss: 0.0000 | Elapsed: 0:02:07\n",
      "| TRAIN SET | Epoch [03/04], Step [0194/0304], Loss: 0.0000 | Elapsed: 0:02:08\n",
      "| TRAIN SET | Epoch [03/04], Step [0195/0304], Loss: 0.0668 | Elapsed: 0:02:08\n",
      "| TRAIN SET | Epoch [03/04], Step [0196/0304], Loss: 0.4284 | Elapsed: 0:02:09\n",
      "| TRAIN SET | Epoch [03/04], Step [0197/0304], Loss: 0.0000 | Elapsed: 0:02:10\n",
      "| TRAIN SET | Epoch [03/04], Step [0198/0304], Loss: 0.0894 | Elapsed: 0:02:10\n",
      "| TRAIN SET | Epoch [03/04], Step [0199/0304], Loss: 0.0961 | Elapsed: 0:02:11\n",
      "| TRAIN SET | Epoch [03/04], Step [0200/0304], Loss: 0.0000 | Elapsed: 0:02:13\n",
      "| TRAIN SET | Epoch [03/04], Step [0201/0304], Loss: 0.0825 | Elapsed: 0:02:13\n",
      "| TRAIN SET | Epoch [03/04], Step [0202/0304], Loss: 0.0000 | Elapsed: 0:02:14\n",
      "| TRAIN SET | Epoch [03/04], Step [0203/0304], Loss: 0.0660 | Elapsed: 0:02:15\n",
      "| TRAIN SET | Epoch [03/04], Step [0204/0304], Loss: 0.0000 | Elapsed: 0:02:15\n",
      "| TRAIN SET | Epoch [03/04], Step [0205/0304], Loss: 0.0000 | Elapsed: 0:02:16\n",
      "| TRAIN SET | Epoch [03/04], Step [0206/0304], Loss: 0.0000 | Elapsed: 0:02:16\n",
      "| TRAIN SET | Epoch [03/04], Step [0207/0304], Loss: 0.0000 | Elapsed: 0:02:17\n",
      "| TRAIN SET | Epoch [03/04], Step [0208/0304], Loss: 0.0325 | Elapsed: 0:02:18\n",
      "| TRAIN SET | Epoch [03/04], Step [0209/0304], Loss: 0.0000 | Elapsed: 0:02:18\n",
      "| TRAIN SET | Epoch [03/04], Step [0210/0304], Loss: 0.2076 | Elapsed: 0:02:19\n",
      "| TRAIN SET | Epoch [03/04], Step [0211/0304], Loss: 0.0720 | Elapsed: 0:02:20\n",
      "| TRAIN SET | Epoch [03/04], Step [0212/0304], Loss: 0.1970 | Elapsed: 0:02:20\n",
      "| TRAIN SET | Epoch [03/04], Step [0213/0304], Loss: 0.0840 | Elapsed: 0:02:21\n",
      "| TRAIN SET | Epoch [03/04], Step [0214/0304], Loss: 0.0601 | Elapsed: 0:02:22\n",
      "| TRAIN SET | Epoch [03/04], Step [0215/0304], Loss: 0.0000 | Elapsed: 0:02:22\n",
      "| TRAIN SET | Epoch [03/04], Step [0216/0304], Loss: 0.0000 | Elapsed: 0:02:23\n",
      "| TRAIN SET | Epoch [03/04], Step [0217/0304], Loss: 0.0459 | Elapsed: 0:02:24\n",
      "| TRAIN SET | Epoch [03/04], Step [0218/0304], Loss: 0.0000 | Elapsed: 0:02:24\n",
      "| TRAIN SET | Epoch [03/04], Step [0219/0304], Loss: 0.0000 | Elapsed: 0:02:25\n",
      "| TRAIN SET | Epoch [03/04], Step [0220/0304], Loss: 0.0000 | Elapsed: 0:02:26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [03/04], Step [0221/0304], Loss: 0.1406 | Elapsed: 0:02:26\n",
      "| TRAIN SET | Epoch [03/04], Step [0222/0304], Loss: 0.0000 | Elapsed: 0:02:27\n",
      "| TRAIN SET | Epoch [03/04], Step [0223/0304], Loss: 0.0000 | Elapsed: 0:02:28\n",
      "| TRAIN SET | Epoch [03/04], Step [0224/0304], Loss: 0.0490 | Elapsed: 0:02:28\n",
      "| TRAIN SET | Epoch [03/04], Step [0225/0304], Loss: 0.1034 | Elapsed: 0:02:29\n",
      "| TRAIN SET | Epoch [03/04], Step [0226/0304], Loss: 0.1319 | Elapsed: 0:02:29\n",
      "| TRAIN SET | Epoch [03/04], Step [0227/0304], Loss: 0.0000 | Elapsed: 0:02:30\n",
      "| TRAIN SET | Epoch [03/04], Step [0228/0304], Loss: 0.0472 | Elapsed: 0:02:31\n",
      "| TRAIN SET | Epoch [03/04], Step [0229/0304], Loss: 0.0000 | Elapsed: 0:02:31\n",
      "| TRAIN SET | Epoch [03/04], Step [0230/0304], Loss: 0.0922 | Elapsed: 0:02:32\n",
      "| TRAIN SET | Epoch [03/04], Step [0231/0304], Loss: 0.0000 | Elapsed: 0:02:33\n",
      "| TRAIN SET | Epoch [03/04], Step [0232/0304], Loss: 0.0211 | Elapsed: 0:02:33\n",
      "| TRAIN SET | Epoch [03/04], Step [0233/0304], Loss: 0.0337 | Elapsed: 0:02:34\n",
      "| TRAIN SET | Epoch [03/04], Step [0234/0304], Loss: 0.0914 | Elapsed: 0:02:35\n",
      "| TRAIN SET | Epoch [03/04], Step [0235/0304], Loss: 0.0540 | Elapsed: 0:02:35\n",
      "| TRAIN SET | Epoch [03/04], Step [0236/0304], Loss: 0.0000 | Elapsed: 0:02:36\n",
      "| TRAIN SET | Epoch [03/04], Step [0237/0304], Loss: 0.0000 | Elapsed: 0:02:37\n",
      "| TRAIN SET | Epoch [03/04], Step [0238/0304], Loss: 0.0000 | Elapsed: 0:02:37\n",
      "| TRAIN SET | Epoch [03/04], Step [0239/0304], Loss: 0.0000 | Elapsed: 0:02:38\n",
      "| TRAIN SET | Epoch [03/04], Step [0240/0304], Loss: 0.0628 | Elapsed: 0:02:39\n",
      "| TRAIN SET | Epoch [03/04], Step [0241/0304], Loss: 0.0000 | Elapsed: 0:02:39\n",
      "| TRAIN SET | Epoch [03/04], Step [0242/0304], Loss: 0.0000 | Elapsed: 0:02:40\n",
      "| TRAIN SET | Epoch [03/04], Step [0243/0304], Loss: 0.0000 | Elapsed: 0:02:41\n",
      "| TRAIN SET | Epoch [03/04], Step [0244/0304], Loss: 0.1132 | Elapsed: 0:02:41\n",
      "| TRAIN SET | Epoch [03/04], Step [0245/0304], Loss: 0.0241 | Elapsed: 0:02:42\n",
      "| TRAIN SET | Epoch [03/04], Step [0246/0304], Loss: 0.2005 | Elapsed: 0:02:43\n",
      "| TRAIN SET | Epoch [03/04], Step [0247/0304], Loss: 0.2879 | Elapsed: 0:02:43\n",
      "| TRAIN SET | Epoch [03/04], Step [0248/0304], Loss: 0.0000 | Elapsed: 0:02:44\n",
      "| TRAIN SET | Epoch [03/04], Step [0249/0304], Loss: 0.0000 | Elapsed: 0:02:44\n",
      "| TRAIN SET | Epoch [03/04], Step [0250/0304], Loss: 0.0732 | Elapsed: 0:02:45\n",
      "| TRAIN SET | Epoch [03/04], Step [0251/0304], Loss: 0.0098 | Elapsed: 0:02:46\n",
      "| TRAIN SET | Epoch [03/04], Step [0252/0304], Loss: 0.1104 | Elapsed: 0:02:46\n",
      "| TRAIN SET | Epoch [03/04], Step [0253/0304], Loss: 0.0000 | Elapsed: 0:02:47\n",
      "| TRAIN SET | Epoch [03/04], Step [0254/0304], Loss: 0.0560 | Elapsed: 0:02:48\n",
      "| TRAIN SET | Epoch [03/04], Step [0255/0304], Loss: 0.0465 | Elapsed: 0:02:48\n",
      "| TRAIN SET | Epoch [03/04], Step [0256/0304], Loss: 0.0872 | Elapsed: 0:02:49\n",
      "| TRAIN SET | Epoch [03/04], Step [0257/0304], Loss: 0.0577 | Elapsed: 0:02:50\n",
      "| TRAIN SET | Epoch [03/04], Step [0258/0304], Loss: 0.0792 | Elapsed: 0:02:50\n",
      "| TRAIN SET | Epoch [03/04], Step [0259/0304], Loss: 0.1669 | Elapsed: 0:02:51\n",
      "| TRAIN SET | Epoch [03/04], Step [0260/0304], Loss: 0.0405 | Elapsed: 0:02:52\n",
      "| TRAIN SET | Epoch [03/04], Step [0261/0304], Loss: 0.0413 | Elapsed: 0:02:52\n",
      "| TRAIN SET | Epoch [03/04], Step [0262/0304], Loss: 0.0077 | Elapsed: 0:02:53\n",
      "| TRAIN SET | Epoch [03/04], Step [0263/0304], Loss: 0.0000 | Elapsed: 0:02:54\n",
      "| TRAIN SET | Epoch [03/04], Step [0264/0304], Loss: 0.1657 | Elapsed: 0:02:54\n",
      "| TRAIN SET | Epoch [03/04], Step [0265/0304], Loss: 0.0000 | Elapsed: 0:02:55\n",
      "| TRAIN SET | Epoch [03/04], Step [0266/0304], Loss: 0.1023 | Elapsed: 0:02:56\n",
      "| TRAIN SET | Epoch [03/04], Step [0267/0304], Loss: 0.1467 | Elapsed: 0:02:56\n",
      "| TRAIN SET | Epoch [03/04], Step [0268/0304], Loss: 0.0250 | Elapsed: 0:02:57\n",
      "| TRAIN SET | Epoch [03/04], Step [0269/0304], Loss: 0.0000 | Elapsed: 0:02:58\n",
      "| TRAIN SET | Epoch [03/04], Step [0270/0304], Loss: 0.0248 | Elapsed: 0:02:58\n",
      "| TRAIN SET | Epoch [03/04], Step [0271/0304], Loss: 0.0000 | Elapsed: 0:02:59\n",
      "| TRAIN SET | Epoch [03/04], Step [0272/0304], Loss: 0.0645 | Elapsed: 0:02:59\n",
      "| TRAIN SET | Epoch [03/04], Step [0273/0304], Loss: 0.0000 | Elapsed: 0:03:00\n",
      "| TRAIN SET | Epoch [03/04], Step [0274/0304], Loss: 0.1060 | Elapsed: 0:03:01\n",
      "| TRAIN SET | Epoch [03/04], Step [0275/0304], Loss: 0.0000 | Elapsed: 0:03:01\n",
      "| TRAIN SET | Epoch [03/04], Step [0276/0304], Loss: 0.0000 | Elapsed: 0:03:02\n",
      "| TRAIN SET | Epoch [03/04], Step [0277/0304], Loss: 0.0000 | Elapsed: 0:03:03\n",
      "| TRAIN SET | Epoch [03/04], Step [0278/0304], Loss: 0.0683 | Elapsed: 0:03:03\n",
      "| TRAIN SET | Epoch [03/04], Step [0279/0304], Loss: 0.0350 | Elapsed: 0:03:04\n",
      "| TRAIN SET | Epoch [03/04], Step [0280/0304], Loss: 0.0667 | Elapsed: 0:03:05\n",
      "| TRAIN SET | Epoch [03/04], Step [0281/0304], Loss: 0.0355 | Elapsed: 0:03:05\n",
      "| TRAIN SET | Epoch [03/04], Step [0282/0304], Loss: 0.0546 | Elapsed: 0:03:06\n",
      "| TRAIN SET | Epoch [03/04], Step [0283/0304], Loss: 0.1421 | Elapsed: 0:03:07\n",
      "| TRAIN SET | Epoch [03/04], Step [0284/0304], Loss: 0.0636 | Elapsed: 0:03:07\n",
      "| TRAIN SET | Epoch [03/04], Step [0285/0304], Loss: 0.0000 | Elapsed: 0:03:08\n",
      "| TRAIN SET | Epoch [03/04], Step [0286/0304], Loss: 0.0406 | Elapsed: 0:03:09\n",
      "| TRAIN SET | Epoch [03/04], Step [0287/0304], Loss: 0.0000 | Elapsed: 0:03:09\n",
      "| TRAIN SET | Epoch [03/04], Step [0288/0304], Loss: 0.0305 | Elapsed: 0:03:10\n",
      "| TRAIN SET | Epoch [03/04], Step [0289/0304], Loss: 0.0495 | Elapsed: 0:03:10\n",
      "| TRAIN SET | Epoch [03/04], Step [0290/0304], Loss: 0.0000 | Elapsed: 0:03:11\n",
      "| TRAIN SET | Epoch [03/04], Step [0291/0304], Loss: 0.0483 | Elapsed: 0:03:12\n",
      "| TRAIN SET | Epoch [03/04], Step [0292/0304], Loss: 0.0000 | Elapsed: 0:03:12\n",
      "| TRAIN SET | Epoch [03/04], Step [0293/0304], Loss: 0.0165 | Elapsed: 0:03:13\n",
      "| TRAIN SET | Epoch [03/04], Step [0294/0304], Loss: 0.0150 | Elapsed: 0:03:14\n",
      "| TRAIN SET | Epoch [03/04], Step [0295/0304], Loss: 0.0000 | Elapsed: 0:03:14\n",
      "| TRAIN SET | Epoch [03/04], Step [0296/0304], Loss: 0.0000 | Elapsed: 0:03:15\n",
      "| TRAIN SET | Epoch [03/04], Step [0297/0304], Loss: 0.0818 | Elapsed: 0:03:16\n",
      "| TRAIN SET | Epoch [03/04], Step [0298/0304], Loss: 0.0000 | Elapsed: 0:03:16\n",
      "| TRAIN SET | Epoch [03/04], Step [0299/0304], Loss: 0.0605 | Elapsed: 0:03:17\n",
      "| TRAIN SET | Epoch [03/04], Step [0300/0304], Loss: 0.1719 | Elapsed: 0:03:18\n",
      "| TRAIN SET | Epoch [03/04], Step [0301/0304], Loss: 0.0000 | Elapsed: 0:03:19\n",
      "| TRAIN SET | Epoch [03/04], Step [0302/0304], Loss: 0.0000 | Elapsed: 0:03:20\n",
      "| TRAIN SET | Epoch [03/04], Step [0303/0304], Loss: 0.0000 | Elapsed: 0:03:20\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:03:21\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "| TRAIN SET | Epoch [04/04], Step [0000/0304], Loss: 0.0000 | Elapsed: 0:00:01\n",
      "| TRAIN SET | Epoch [04/04], Step [0001/0304], Loss: 0.0560 | Elapsed: 0:00:02\n",
      "| TRAIN SET | Epoch [04/04], Step [0002/0304], Loss: 0.0355 | Elapsed: 0:00:02\n",
      "| TRAIN SET | Epoch [04/04], Step [0003/0304], Loss: 0.1634 | Elapsed: 0:00:03\n",
      "| TRAIN SET | Epoch [04/04], Step [0004/0304], Loss: 0.0582 | Elapsed: 0:00:04\n",
      "| TRAIN SET | Epoch [04/04], Step [0005/0304], Loss: 0.0000 | Elapsed: 0:00:04\n",
      "| TRAIN SET | Epoch [04/04], Step [0006/0304], Loss: 0.0960 | Elapsed: 0:00:05\n",
      "| TRAIN SET | Epoch [04/04], Step [0007/0304], Loss: 0.0133 | Elapsed: 0:00:05\n",
      "| TRAIN SET | Epoch [04/04], Step [0008/0304], Loss: 0.0000 | Elapsed: 0:00:06\n",
      "| TRAIN SET | Epoch [04/04], Step [0009/0304], Loss: 0.1220 | Elapsed: 0:00:07\n",
      "| TRAIN SET | Epoch [04/04], Step [0010/0304], Loss: 0.0000 | Elapsed: 0:00:07\n",
      "| TRAIN SET | Epoch [04/04], Step [0011/0304], Loss: 0.1550 | Elapsed: 0:00:08\n",
      "| TRAIN SET | Epoch [04/04], Step [0012/0304], Loss: 0.1004 | Elapsed: 0:00:09\n",
      "| TRAIN SET | Epoch [04/04], Step [0013/0304], Loss: 0.0000 | Elapsed: 0:00:09\n",
      "| TRAIN SET | Epoch [04/04], Step [0014/0304], Loss: 0.0592 | Elapsed: 0:00:10\n",
      "| TRAIN SET | Epoch [04/04], Step [0015/0304], Loss: 0.0592 | Elapsed: 0:00:11\n",
      "| TRAIN SET | Epoch [04/04], Step [0016/0304], Loss: 0.0000 | Elapsed: 0:00:11\n",
      "| TRAIN SET | Epoch [04/04], Step [0017/0304], Loss: 0.0532 | Elapsed: 0:00:12\n",
      "| TRAIN SET | Epoch [04/04], Step [0018/0304], Loss: 0.1394 | Elapsed: 0:00:13\n",
      "| TRAIN SET | Epoch [04/04], Step [0019/0304], Loss: 0.0775 | Elapsed: 0:00:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [04/04], Step [0020/0304], Loss: 0.0685 | Elapsed: 0:00:14\n",
      "| TRAIN SET | Epoch [04/04], Step [0021/0304], Loss: 0.0000 | Elapsed: 0:00:14\n",
      "| TRAIN SET | Epoch [04/04], Step [0022/0304], Loss: 0.0489 | Elapsed: 0:00:15\n",
      "| TRAIN SET | Epoch [04/04], Step [0023/0304], Loss: 0.0000 | Elapsed: 0:00:16\n",
      "| TRAIN SET | Epoch [04/04], Step [0024/0304], Loss: 0.0329 | Elapsed: 0:00:17\n",
      "| TRAIN SET | Epoch [04/04], Step [0025/0304], Loss: 0.0961 | Elapsed: 0:00:17\n",
      "| TRAIN SET | Epoch [04/04], Step [0026/0304], Loss: 0.0000 | Elapsed: 0:00:18\n",
      "| TRAIN SET | Epoch [04/04], Step [0027/0304], Loss: 0.0000 | Elapsed: 0:00:19\n",
      "| TRAIN SET | Epoch [04/04], Step [0028/0304], Loss: 0.0882 | Elapsed: 0:00:19\n",
      "| TRAIN SET | Epoch [04/04], Step [0029/0304], Loss: 0.0519 | Elapsed: 0:00:20\n",
      "| TRAIN SET | Epoch [04/04], Step [0030/0304], Loss: 0.0723 | Elapsed: 0:00:21\n",
      "| TRAIN SET | Epoch [04/04], Step [0031/0304], Loss: 0.1130 | Elapsed: 0:00:21\n",
      "| TRAIN SET | Epoch [04/04], Step [0032/0304], Loss: 0.0000 | Elapsed: 0:00:22\n",
      "| TRAIN SET | Epoch [04/04], Step [0033/0304], Loss: 0.0000 | Elapsed: 0:00:23\n",
      "| TRAIN SET | Epoch [04/04], Step [0034/0304], Loss: 0.0809 | Elapsed: 0:00:23\n",
      "| TRAIN SET | Epoch [04/04], Step [0035/0304], Loss: 0.0000 | Elapsed: 0:00:24\n",
      "| TRAIN SET | Epoch [04/04], Step [0036/0304], Loss: 0.0000 | Elapsed: 0:00:25\n",
      "| TRAIN SET | Epoch [04/04], Step [0037/0304], Loss: 0.0927 | Elapsed: 0:00:25\n",
      "| TRAIN SET | Epoch [04/04], Step [0038/0304], Loss: 0.0000 | Elapsed: 0:00:26\n",
      "| TRAIN SET | Epoch [04/04], Step [0039/0304], Loss: 0.1179 | Elapsed: 0:00:26\n",
      "| TRAIN SET | Epoch [04/04], Step [0040/0304], Loss: 0.0915 | Elapsed: 0:00:27\n",
      "| TRAIN SET | Epoch [04/04], Step [0041/0304], Loss: 0.0000 | Elapsed: 0:00:28\n",
      "| TRAIN SET | Epoch [04/04], Step [0042/0304], Loss: 0.0991 | Elapsed: 0:00:28\n",
      "| TRAIN SET | Epoch [04/04], Step [0043/0304], Loss: 0.0000 | Elapsed: 0:00:29\n",
      "| TRAIN SET | Epoch [04/04], Step [0044/0304], Loss: 0.2495 | Elapsed: 0:00:30\n",
      "| TRAIN SET | Epoch [04/04], Step [0045/0304], Loss: 0.0329 | Elapsed: 0:00:30\n",
      "| TRAIN SET | Epoch [04/04], Step [0046/0304], Loss: 0.0000 | Elapsed: 0:00:31\n",
      "| TRAIN SET | Epoch [04/04], Step [0047/0304], Loss: 0.0623 | Elapsed: 0:00:32\n",
      "| TRAIN SET | Epoch [04/04], Step [0048/0304], Loss: 0.0628 | Elapsed: 0:00:32\n",
      "| TRAIN SET | Epoch [04/04], Step [0049/0304], Loss: 0.0636 | Elapsed: 0:00:33\n",
      "| TRAIN SET | Epoch [04/04], Step [0050/0304], Loss: 0.1748 | Elapsed: 0:00:34\n",
      "| TRAIN SET | Epoch [04/04], Step [0051/0304], Loss: 0.0508 | Elapsed: 0:00:34\n",
      "| TRAIN SET | Epoch [04/04], Step [0052/0304], Loss: 0.0000 | Elapsed: 0:00:35\n",
      "| TRAIN SET | Epoch [04/04], Step [0053/0304], Loss: 0.0222 | Elapsed: 0:00:36\n",
      "| TRAIN SET | Epoch [04/04], Step [0054/0304], Loss: 0.1196 | Elapsed: 0:00:36\n",
      "| TRAIN SET | Epoch [04/04], Step [0055/0304], Loss: 0.0000 | Elapsed: 0:00:37\n",
      "| TRAIN SET | Epoch [04/04], Step [0056/0304], Loss: 0.1743 | Elapsed: 0:00:38\n",
      "| TRAIN SET | Epoch [04/04], Step [0057/0304], Loss: 0.0000 | Elapsed: 0:00:38\n",
      "| TRAIN SET | Epoch [04/04], Step [0058/0304], Loss: 0.1574 | Elapsed: 0:00:39\n",
      "| TRAIN SET | Epoch [04/04], Step [0059/0304], Loss: 0.1242 | Elapsed: 0:00:39\n",
      "| TRAIN SET | Epoch [04/04], Step [0060/0304], Loss: 0.0000 | Elapsed: 0:00:40\n",
      "| TRAIN SET | Epoch [04/04], Step [0061/0304], Loss: 0.0133 | Elapsed: 0:00:41\n",
      "| TRAIN SET | Epoch [04/04], Step [0062/0304], Loss: 0.0518 | Elapsed: 0:00:41\n",
      "| TRAIN SET | Epoch [04/04], Step [0063/0304], Loss: 0.1309 | Elapsed: 0:00:42\n",
      "| TRAIN SET | Epoch [04/04], Step [0064/0304], Loss: 0.0497 | Elapsed: 0:00:43\n",
      "| TRAIN SET | Epoch [04/04], Step [0065/0304], Loss: 0.0000 | Elapsed: 0:00:43\n",
      "| TRAIN SET | Epoch [04/04], Step [0066/0304], Loss: 0.0000 | Elapsed: 0:00:44\n",
      "| TRAIN SET | Epoch [04/04], Step [0067/0304], Loss: 0.1255 | Elapsed: 0:00:45\n",
      "| TRAIN SET | Epoch [04/04], Step [0068/0304], Loss: 0.0000 | Elapsed: 0:00:45\n",
      "| TRAIN SET | Epoch [04/04], Step [0069/0304], Loss: 0.0000 | Elapsed: 0:00:46\n",
      "| TRAIN SET | Epoch [04/04], Step [0070/0304], Loss: 0.0000 | Elapsed: 0:00:47\n",
      "| TRAIN SET | Epoch [04/04], Step [0071/0304], Loss: 0.0499 | Elapsed: 0:00:47\n",
      "| TRAIN SET | Epoch [04/04], Step [0072/0304], Loss: 0.0000 | Elapsed: 0:00:48\n",
      "| TRAIN SET | Epoch [04/04], Step [0073/0304], Loss: 0.0000 | Elapsed: 0:00:49\n",
      "| TRAIN SET | Epoch [04/04], Step [0074/0304], Loss: 0.0919 | Elapsed: 0:00:49\n",
      "| TRAIN SET | Epoch [04/04], Step [0075/0304], Loss: 0.0650 | Elapsed: 0:00:50\n",
      "| TRAIN SET | Epoch [04/04], Step [0076/0304], Loss: 0.0000 | Elapsed: 0:00:50\n",
      "| TRAIN SET | Epoch [04/04], Step [0077/0304], Loss: 0.0000 | Elapsed: 0:00:51\n",
      "| TRAIN SET | Epoch [04/04], Step [0078/0304], Loss: 0.0825 | Elapsed: 0:00:52\n",
      "| TRAIN SET | Epoch [04/04], Step [0079/0304], Loss: 0.0000 | Elapsed: 0:00:52\n",
      "| TRAIN SET | Epoch [04/04], Step [0080/0304], Loss: 0.1366 | Elapsed: 0:00:53\n",
      "| TRAIN SET | Epoch [04/04], Step [0081/0304], Loss: 0.0000 | Elapsed: 0:00:54\n",
      "| TRAIN SET | Epoch [04/04], Step [0082/0304], Loss: 0.0760 | Elapsed: 0:00:54\n",
      "| TRAIN SET | Epoch [04/04], Step [0083/0304], Loss: 0.0000 | Elapsed: 0:00:55\n",
      "| TRAIN SET | Epoch [04/04], Step [0084/0304], Loss: 0.1047 | Elapsed: 0:00:56\n",
      "| TRAIN SET | Epoch [04/04], Step [0085/0304], Loss: 0.0587 | Elapsed: 0:00:56\n",
      "| TRAIN SET | Epoch [04/04], Step [0086/0304], Loss: 0.0000 | Elapsed: 0:00:57\n",
      "| TRAIN SET | Epoch [04/04], Step [0087/0304], Loss: 0.1247 | Elapsed: 0:00:58\n",
      "| TRAIN SET | Epoch [04/04], Step [0088/0304], Loss: 0.1739 | Elapsed: 0:00:58\n",
      "| TRAIN SET | Epoch [04/04], Step [0089/0304], Loss: 0.0000 | Elapsed: 0:00:59\n",
      "| TRAIN SET | Epoch [04/04], Step [0090/0304], Loss: 0.0000 | Elapsed: 0:01:00\n",
      "| TRAIN SET | Epoch [04/04], Step [0091/0304], Loss: 0.0010 | Elapsed: 0:01:00\n",
      "| TRAIN SET | Epoch [04/04], Step [0092/0304], Loss: 0.0000 | Elapsed: 0:01:01\n",
      "| TRAIN SET | Epoch [04/04], Step [0093/0304], Loss: 0.0000 | Elapsed: 0:01:02\n",
      "| TRAIN SET | Epoch [04/04], Step [0094/0304], Loss: 0.2814 | Elapsed: 0:01:02\n",
      "| TRAIN SET | Epoch [04/04], Step [0095/0304], Loss: 0.0033 | Elapsed: 0:01:03\n",
      "| TRAIN SET | Epoch [04/04], Step [0096/0304], Loss: 0.0000 | Elapsed: 0:01:03\n",
      "| TRAIN SET | Epoch [04/04], Step [0097/0304], Loss: 0.0208 | Elapsed: 0:01:04\n",
      "| TRAIN SET | Epoch [04/04], Step [0098/0304], Loss: 0.0159 | Elapsed: 0:01:05\n",
      "| TRAIN SET | Epoch [04/04], Step [0099/0304], Loss: 0.1958 | Elapsed: 0:01:05\n",
      "| TRAIN SET | Epoch [04/04], Step [0100/0304], Loss: 0.1231 | Elapsed: 0:01:07\n",
      "| TRAIN SET | Epoch [04/04], Step [0101/0304], Loss: 0.1693 | Elapsed: 0:01:08\n",
      "| TRAIN SET | Epoch [04/04], Step [0102/0304], Loss: 0.0636 | Elapsed: 0:01:08\n",
      "| TRAIN SET | Epoch [04/04], Step [0103/0304], Loss: 0.0730 | Elapsed: 0:01:09\n",
      "| TRAIN SET | Epoch [04/04], Step [0104/0304], Loss: 0.1483 | Elapsed: 0:01:10\n",
      "| TRAIN SET | Epoch [04/04], Step [0105/0304], Loss: 0.0000 | Elapsed: 0:01:10\n",
      "| TRAIN SET | Epoch [04/04], Step [0106/0304], Loss: 0.0733 | Elapsed: 0:01:11\n",
      "| TRAIN SET | Epoch [04/04], Step [0107/0304], Loss: 0.0000 | Elapsed: 0:01:11\n",
      "| TRAIN SET | Epoch [04/04], Step [0108/0304], Loss: 0.0100 | Elapsed: 0:01:12\n",
      "| TRAIN SET | Epoch [04/04], Step [0109/0304], Loss: 0.0000 | Elapsed: 0:01:13\n",
      "| TRAIN SET | Epoch [04/04], Step [0110/0304], Loss: 0.1271 | Elapsed: 0:01:13\n",
      "| TRAIN SET | Epoch [04/04], Step [0111/0304], Loss: 0.1440 | Elapsed: 0:01:14\n",
      "| TRAIN SET | Epoch [04/04], Step [0112/0304], Loss: 0.0743 | Elapsed: 0:01:15\n",
      "| TRAIN SET | Epoch [04/04], Step [0113/0304], Loss: 0.0736 | Elapsed: 0:01:15\n",
      "| TRAIN SET | Epoch [04/04], Step [0114/0304], Loss: 0.0543 | Elapsed: 0:01:16\n",
      "| TRAIN SET | Epoch [04/04], Step [0115/0304], Loss: 0.0000 | Elapsed: 0:01:17\n",
      "| TRAIN SET | Epoch [04/04], Step [0116/0304], Loss: 0.0926 | Elapsed: 0:01:17\n",
      "| TRAIN SET | Epoch [04/04], Step [0117/0304], Loss: 0.0348 | Elapsed: 0:01:18\n",
      "| TRAIN SET | Epoch [04/04], Step [0118/0304], Loss: 0.0824 | Elapsed: 0:01:19\n",
      "| TRAIN SET | Epoch [04/04], Step [0119/0304], Loss: 0.0000 | Elapsed: 0:01:19\n",
      "| TRAIN SET | Epoch [04/04], Step [0120/0304], Loss: 0.0000 | Elapsed: 0:01:20\n",
      "| TRAIN SET | Epoch [04/04], Step [0121/0304], Loss: 0.0027 | Elapsed: 0:01:21\n",
      "| TRAIN SET | Epoch [04/04], Step [0122/0304], Loss: 0.0198 | Elapsed: 0:01:21\n",
      "| TRAIN SET | Epoch [04/04], Step [0123/0304], Loss: 0.0770 | Elapsed: 0:01:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [04/04], Step [0124/0304], Loss: 0.0555 | Elapsed: 0:01:22\n",
      "| TRAIN SET | Epoch [04/04], Step [0125/0304], Loss: 0.0000 | Elapsed: 0:01:23\n",
      "| TRAIN SET | Epoch [04/04], Step [0126/0304], Loss: 0.0139 | Elapsed: 0:01:24\n",
      "| TRAIN SET | Epoch [04/04], Step [0127/0304], Loss: 0.0000 | Elapsed: 0:01:24\n",
      "| TRAIN SET | Epoch [04/04], Step [0128/0304], Loss: 0.0000 | Elapsed: 0:01:25\n",
      "| TRAIN SET | Epoch [04/04], Step [0129/0304], Loss: 0.1260 | Elapsed: 0:01:26\n",
      "| TRAIN SET | Epoch [04/04], Step [0130/0304], Loss: 0.0047 | Elapsed: 0:01:26\n",
      "| TRAIN SET | Epoch [04/04], Step [0131/0304], Loss: 0.0376 | Elapsed: 0:01:27\n",
      "| TRAIN SET | Epoch [04/04], Step [0132/0304], Loss: 0.1174 | Elapsed: 0:01:28\n",
      "| TRAIN SET | Epoch [04/04], Step [0133/0304], Loss: 0.0000 | Elapsed: 0:01:28\n",
      "| TRAIN SET | Epoch [04/04], Step [0134/0304], Loss: 0.0537 | Elapsed: 0:01:29\n",
      "| TRAIN SET | Epoch [04/04], Step [0135/0304], Loss: 0.1126 | Elapsed: 0:01:30\n",
      "| TRAIN SET | Epoch [04/04], Step [0136/0304], Loss: 0.1371 | Elapsed: 0:01:30\n",
      "| TRAIN SET | Epoch [04/04], Step [0137/0304], Loss: 0.0243 | Elapsed: 0:01:31\n",
      "| TRAIN SET | Epoch [04/04], Step [0138/0304], Loss: 0.1116 | Elapsed: 0:01:32\n",
      "| TRAIN SET | Epoch [04/04], Step [0139/0304], Loss: 0.0000 | Elapsed: 0:01:32\n",
      "| TRAIN SET | Epoch [04/04], Step [0140/0304], Loss: 0.0894 | Elapsed: 0:01:33\n",
      "| TRAIN SET | Epoch [04/04], Step [0141/0304], Loss: 0.0000 | Elapsed: 0:01:34\n",
      "| TRAIN SET | Epoch [04/04], Step [0142/0304], Loss: 0.0452 | Elapsed: 0:01:34\n",
      "| TRAIN SET | Epoch [04/04], Step [0143/0304], Loss: 0.1235 | Elapsed: 0:01:35\n",
      "| TRAIN SET | Epoch [04/04], Step [0144/0304], Loss: 0.1145 | Elapsed: 0:01:35\n",
      "| TRAIN SET | Epoch [04/04], Step [0145/0304], Loss: 0.0000 | Elapsed: 0:01:36\n",
      "| TRAIN SET | Epoch [04/04], Step [0146/0304], Loss: 0.0000 | Elapsed: 0:01:37\n",
      "| TRAIN SET | Epoch [04/04], Step [0147/0304], Loss: 0.0867 | Elapsed: 0:01:37\n",
      "| TRAIN SET | Epoch [04/04], Step [0148/0304], Loss: 0.0523 | Elapsed: 0:01:38\n",
      "| TRAIN SET | Epoch [04/04], Step [0149/0304], Loss: 0.0886 | Elapsed: 0:01:39\n",
      "| TRAIN SET | Epoch [04/04], Step [0150/0304], Loss: 0.0729 | Elapsed: 0:01:39\n",
      "| TRAIN SET | Epoch [04/04], Step [0151/0304], Loss: 0.0000 | Elapsed: 0:01:40\n",
      "| TRAIN SET | Epoch [04/04], Step [0152/0304], Loss: 0.0900 | Elapsed: 0:01:41\n",
      "| TRAIN SET | Epoch [04/04], Step [0153/0304], Loss: 0.0000 | Elapsed: 0:01:41\n",
      "| TRAIN SET | Epoch [04/04], Step [0154/0304], Loss: 0.0000 | Elapsed: 0:01:42\n",
      "| TRAIN SET | Epoch [04/04], Step [0155/0304], Loss: 0.0000 | Elapsed: 0:01:43\n",
      "| TRAIN SET | Epoch [04/04], Step [0156/0304], Loss: 0.0565 | Elapsed: 0:01:44\n",
      "| TRAIN SET | Epoch [04/04], Step [0157/0304], Loss: 0.0185 | Elapsed: 0:01:44\n",
      "| TRAIN SET | Epoch [04/04], Step [0158/0304], Loss: 0.0000 | Elapsed: 0:01:45\n",
      "| TRAIN SET | Epoch [04/04], Step [0159/0304], Loss: 0.0000 | Elapsed: 0:01:46\n",
      "| TRAIN SET | Epoch [04/04], Step [0160/0304], Loss: 0.0527 | Elapsed: 0:01:46\n",
      "| TRAIN SET | Epoch [04/04], Step [0161/0304], Loss: 0.0000 | Elapsed: 0:01:47\n",
      "| TRAIN SET | Epoch [04/04], Step [0162/0304], Loss: 0.0229 | Elapsed: 0:01:47\n",
      "| TRAIN SET | Epoch [04/04], Step [0163/0304], Loss: 0.0477 | Elapsed: 0:01:48\n",
      "| TRAIN SET | Epoch [04/04], Step [0164/0304], Loss: 0.0542 | Elapsed: 0:01:49\n",
      "| TRAIN SET | Epoch [04/04], Step [0165/0304], Loss: 0.2538 | Elapsed: 0:01:49\n",
      "| TRAIN SET | Epoch [04/04], Step [0166/0304], Loss: 0.1258 | Elapsed: 0:01:50\n",
      "| TRAIN SET | Epoch [04/04], Step [0167/0304], Loss: 0.0190 | Elapsed: 0:01:51\n",
      "| TRAIN SET | Epoch [04/04], Step [0168/0304], Loss: 0.0074 | Elapsed: 0:01:51\n",
      "| TRAIN SET | Epoch [04/04], Step [0169/0304], Loss: 0.0000 | Elapsed: 0:01:52\n",
      "| TRAIN SET | Epoch [04/04], Step [0170/0304], Loss: 0.0187 | Elapsed: 0:01:53\n",
      "| TRAIN SET | Epoch [04/04], Step [0171/0304], Loss: 0.0000 | Elapsed: 0:01:53\n",
      "| TRAIN SET | Epoch [04/04], Step [0172/0304], Loss: 0.0500 | Elapsed: 0:01:54\n",
      "| TRAIN SET | Epoch [04/04], Step [0173/0304], Loss: 0.2515 | Elapsed: 0:01:55\n",
      "| TRAIN SET | Epoch [04/04], Step [0174/0304], Loss: 0.0488 | Elapsed: 0:01:55\n",
      "| TRAIN SET | Epoch [04/04], Step [0175/0304], Loss: 0.0000 | Elapsed: 0:01:56\n",
      "| TRAIN SET | Epoch [04/04], Step [0176/0304], Loss: 0.0758 | Elapsed: 0:01:57\n",
      "| TRAIN SET | Epoch [04/04], Step [0177/0304], Loss: 0.3026 | Elapsed: 0:01:57\n",
      "| TRAIN SET | Epoch [04/04], Step [0178/0304], Loss: 0.0438 | Elapsed: 0:01:58\n",
      "| TRAIN SET | Epoch [04/04], Step [0179/0304], Loss: 0.0633 | Elapsed: 0:01:59\n",
      "| TRAIN SET | Epoch [04/04], Step [0180/0304], Loss: 0.0000 | Elapsed: 0:01:59\n",
      "| TRAIN SET | Epoch [04/04], Step [0181/0304], Loss: 0.0802 | Elapsed: 0:02:00\n",
      "| TRAIN SET | Epoch [04/04], Step [0182/0304], Loss: 0.0000 | Elapsed: 0:02:01\n",
      "| TRAIN SET | Epoch [04/04], Step [0183/0304], Loss: 0.0220 | Elapsed: 0:02:01\n",
      "| TRAIN SET | Epoch [04/04], Step [0184/0304], Loss: 0.0956 | Elapsed: 0:02:02\n",
      "| TRAIN SET | Epoch [04/04], Step [0185/0304], Loss: 0.0000 | Elapsed: 0:02:03\n",
      "| TRAIN SET | Epoch [04/04], Step [0186/0304], Loss: 0.0000 | Elapsed: 0:02:03\n",
      "| TRAIN SET | Epoch [04/04], Step [0187/0304], Loss: 0.0000 | Elapsed: 0:02:04\n",
      "| TRAIN SET | Epoch [04/04], Step [0188/0304], Loss: 0.0000 | Elapsed: 0:02:04\n",
      "| TRAIN SET | Epoch [04/04], Step [0189/0304], Loss: 0.0540 | Elapsed: 0:02:05\n",
      "| TRAIN SET | Epoch [04/04], Step [0190/0304], Loss: 0.0033 | Elapsed: 0:02:06\n",
      "| TRAIN SET | Epoch [04/04], Step [0191/0304], Loss: 0.0126 | Elapsed: 0:02:06\n",
      "| TRAIN SET | Epoch [04/04], Step [0192/0304], Loss: 0.1114 | Elapsed: 0:02:07\n",
      "| TRAIN SET | Epoch [04/04], Step [0193/0304], Loss: 0.0000 | Elapsed: 0:02:08\n",
      "| TRAIN SET | Epoch [04/04], Step [0194/0304], Loss: 0.0343 | Elapsed: 0:02:08\n",
      "| TRAIN SET | Epoch [04/04], Step [0195/0304], Loss: 0.1290 | Elapsed: 0:02:09\n",
      "| TRAIN SET | Epoch [04/04], Step [0196/0304], Loss: 0.0034 | Elapsed: 0:02:10\n",
      "| TRAIN SET | Epoch [04/04], Step [0197/0304], Loss: 0.0495 | Elapsed: 0:02:10\n",
      "| TRAIN SET | Epoch [04/04], Step [0198/0304], Loss: 0.0000 | Elapsed: 0:02:11\n",
      "| TRAIN SET | Epoch [04/04], Step [0199/0304], Loss: 0.0000 | Elapsed: 0:02:12\n",
      "| TRAIN SET | Epoch [04/04], Step [0200/0304], Loss: 0.0609 | Elapsed: 0:02:13\n",
      "| TRAIN SET | Epoch [04/04], Step [0201/0304], Loss: 0.1169 | Elapsed: 0:02:14\n",
      "| TRAIN SET | Epoch [04/04], Step [0202/0304], Loss: 0.0000 | Elapsed: 0:02:14\n",
      "| TRAIN SET | Epoch [04/04], Step [0203/0304], Loss: 0.0000 | Elapsed: 0:02:15\n",
      "| TRAIN SET | Epoch [04/04], Step [0204/0304], Loss: 0.0403 | Elapsed: 0:02:16\n",
      "| TRAIN SET | Epoch [04/04], Step [0205/0304], Loss: 0.0889 | Elapsed: 0:02:16\n",
      "| TRAIN SET | Epoch [04/04], Step [0206/0304], Loss: 0.0608 | Elapsed: 0:02:17\n",
      "| TRAIN SET | Epoch [04/04], Step [0207/0304], Loss: 0.0000 | Elapsed: 0:02:18\n",
      "| TRAIN SET | Epoch [04/04], Step [0208/0304], Loss: 0.1097 | Elapsed: 0:02:18\n",
      "| TRAIN SET | Epoch [04/04], Step [0209/0304], Loss: 0.0000 | Elapsed: 0:02:19\n",
      "| TRAIN SET | Epoch [04/04], Step [0210/0304], Loss: 0.0045 | Elapsed: 0:02:20\n",
      "| TRAIN SET | Epoch [04/04], Step [0211/0304], Loss: 0.0000 | Elapsed: 0:02:20\n",
      "| TRAIN SET | Epoch [04/04], Step [0212/0304], Loss: 0.0000 | Elapsed: 0:02:21\n",
      "| TRAIN SET | Epoch [04/04], Step [0213/0304], Loss: 0.0000 | Elapsed: 0:02:21\n",
      "| TRAIN SET | Epoch [04/04], Step [0214/0304], Loss: 0.0000 | Elapsed: 0:02:22\n",
      "| TRAIN SET | Epoch [04/04], Step [0215/0304], Loss: 0.0255 | Elapsed: 0:02:23\n",
      "| TRAIN SET | Epoch [04/04], Step [0216/0304], Loss: 0.0563 | Elapsed: 0:02:23\n",
      "| TRAIN SET | Epoch [04/04], Step [0217/0304], Loss: 0.0479 | Elapsed: 0:02:24\n",
      "| TRAIN SET | Epoch [04/04], Step [0218/0304], Loss: 0.0000 | Elapsed: 0:02:25\n",
      "| TRAIN SET | Epoch [04/04], Step [0219/0304], Loss: 0.0000 | Elapsed: 0:02:25\n",
      "| TRAIN SET | Epoch [04/04], Step [0220/0304], Loss: 0.0000 | Elapsed: 0:02:26\n",
      "| TRAIN SET | Epoch [04/04], Step [0221/0304], Loss: 0.0275 | Elapsed: 0:02:27\n",
      "| TRAIN SET | Epoch [04/04], Step [0222/0304], Loss: 0.0736 | Elapsed: 0:02:27\n",
      "| TRAIN SET | Epoch [04/04], Step [0223/0304], Loss: 0.0000 | Elapsed: 0:02:28\n",
      "| TRAIN SET | Epoch [04/04], Step [0224/0304], Loss: 0.0328 | Elapsed: 0:02:29\n",
      "| TRAIN SET | Epoch [04/04], Step [0225/0304], Loss: 0.0000 | Elapsed: 0:02:29\n",
      "| TRAIN SET | Epoch [04/04], Step [0226/0304], Loss: 0.0403 | Elapsed: 0:02:30\n",
      "| TRAIN SET | Epoch [04/04], Step [0227/0304], Loss: 0.0000 | Elapsed: 0:02:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| TRAIN SET | Epoch [04/04], Step [0228/0304], Loss: 0.0000 | Elapsed: 0:02:31\n",
      "| TRAIN SET | Epoch [04/04], Step [0229/0304], Loss: 0.0000 | Elapsed: 0:02:32\n",
      "| TRAIN SET | Epoch [04/04], Step [0230/0304], Loss: 0.1825 | Elapsed: 0:02:33\n",
      "| TRAIN SET | Epoch [04/04], Step [0231/0304], Loss: 0.0000 | Elapsed: 0:02:33\n",
      "| TRAIN SET | Epoch [04/04], Step [0232/0304], Loss: 0.0000 | Elapsed: 0:02:34\n",
      "| TRAIN SET | Epoch [04/04], Step [0233/0304], Loss: 0.0000 | Elapsed: 0:02:34\n",
      "| TRAIN SET | Epoch [04/04], Step [0234/0304], Loss: 0.3039 | Elapsed: 0:02:35\n",
      "| TRAIN SET | Epoch [04/04], Step [0235/0304], Loss: 0.0000 | Elapsed: 0:02:36\n",
      "| TRAIN SET | Epoch [04/04], Step [0236/0304], Loss: 0.0954 | Elapsed: 0:02:36\n",
      "| TRAIN SET | Epoch [04/04], Step [0237/0304], Loss: 0.1918 | Elapsed: 0:02:37\n",
      "| TRAIN SET | Epoch [04/04], Step [0238/0304], Loss: 0.0000 | Elapsed: 0:02:38\n",
      "| TRAIN SET | Epoch [04/04], Step [0239/0304], Loss: 0.0000 | Elapsed: 0:02:38\n",
      "| TRAIN SET | Epoch [04/04], Step [0240/0304], Loss: 0.0000 | Elapsed: 0:02:39\n",
      "| TRAIN SET | Epoch [04/04], Step [0241/0304], Loss: 0.1171 | Elapsed: 0:02:40\n",
      "| TRAIN SET | Epoch [04/04], Step [0242/0304], Loss: 0.0000 | Elapsed: 0:02:40\n",
      "| TRAIN SET | Epoch [04/04], Step [0243/0304], Loss: 0.0442 | Elapsed: 0:02:41\n",
      "| TRAIN SET | Epoch [04/04], Step [0244/0304], Loss: 0.0257 | Elapsed: 0:02:42\n",
      "| TRAIN SET | Epoch [04/04], Step [0245/0304], Loss: 0.0484 | Elapsed: 0:02:42\n",
      "| TRAIN SET | Epoch [04/04], Step [0246/0304], Loss: 0.0000 | Elapsed: 0:02:43\n",
      "| TRAIN SET | Epoch [04/04], Step [0247/0304], Loss: 0.0000 | Elapsed: 0:02:44\n",
      "| TRAIN SET | Epoch [04/04], Step [0248/0304], Loss: 0.0481 | Elapsed: 0:02:44\n",
      "| TRAIN SET | Epoch [04/04], Step [0249/0304], Loss: 0.1625 | Elapsed: 0:02:45\n",
      "| TRAIN SET | Epoch [04/04], Step [0250/0304], Loss: 0.0000 | Elapsed: 0:02:46\n",
      "| TRAIN SET | Epoch [04/04], Step [0251/0304], Loss: 0.0778 | Elapsed: 0:02:46\n",
      "| TRAIN SET | Epoch [04/04], Step [0252/0304], Loss: 0.0000 | Elapsed: 0:02:47\n",
      "| TRAIN SET | Epoch [04/04], Step [0253/0304], Loss: 0.0198 | Elapsed: 0:02:47\n",
      "| TRAIN SET | Epoch [04/04], Step [0254/0304], Loss: 0.0000 | Elapsed: 0:02:48\n",
      "| TRAIN SET | Epoch [04/04], Step [0255/0304], Loss: 0.0637 | Elapsed: 0:02:49\n",
      "| TRAIN SET | Epoch [04/04], Step [0256/0304], Loss: 0.0320 | Elapsed: 0:02:49\n",
      "| TRAIN SET | Epoch [04/04], Step [0257/0304], Loss: 0.0409 | Elapsed: 0:02:50\n",
      "| TRAIN SET | Epoch [04/04], Step [0258/0304], Loss: 0.0000 | Elapsed: 0:02:51\n",
      "| TRAIN SET | Epoch [04/04], Step [0259/0304], Loss: 0.0000 | Elapsed: 0:02:51\n",
      "| TRAIN SET | Epoch [04/04], Step [0260/0304], Loss: 0.0000 | Elapsed: 0:02:52\n",
      "| TRAIN SET | Epoch [04/04], Step [0261/0304], Loss: 0.0000 | Elapsed: 0:02:53\n",
      "| TRAIN SET | Epoch [04/04], Step [0262/0304], Loss: 0.0000 | Elapsed: 0:02:53\n",
      "| TRAIN SET | Epoch [04/04], Step [0263/0304], Loss: 0.0000 | Elapsed: 0:02:54\n",
      "| TRAIN SET | Epoch [04/04], Step [0264/0304], Loss: 0.0000 | Elapsed: 0:02:55\n",
      "| TRAIN SET | Epoch [04/04], Step [0265/0304], Loss: 0.0000 | Elapsed: 0:02:55\n",
      "| TRAIN SET | Epoch [04/04], Step [0266/0304], Loss: 0.0512 | Elapsed: 0:02:56\n",
      "| TRAIN SET | Epoch [04/04], Step [0267/0304], Loss: 0.0000 | Elapsed: 0:02:57\n",
      "| TRAIN SET | Epoch [04/04], Step [0268/0304], Loss: 0.0000 | Elapsed: 0:02:57\n",
      "| TRAIN SET | Epoch [04/04], Step [0269/0304], Loss: 0.0838 | Elapsed: 0:02:58\n",
      "| TRAIN SET | Epoch [04/04], Step [0270/0304], Loss: 0.1093 | Elapsed: 0:02:59\n",
      "| TRAIN SET | Epoch [04/04], Step [0271/0304], Loss: 0.0030 | Elapsed: 0:02:59\n",
      "| TRAIN SET | Epoch [04/04], Step [0272/0304], Loss: 0.1982 | Elapsed: 0:03:00\n",
      "| TRAIN SET | Epoch [04/04], Step [0273/0304], Loss: 0.2523 | Elapsed: 0:03:01\n",
      "| TRAIN SET | Epoch [04/04], Step [0274/0304], Loss: 0.0060 | Elapsed: 0:03:01\n",
      "| TRAIN SET | Epoch [04/04], Step [0275/0304], Loss: 0.0849 | Elapsed: 0:03:02\n",
      "| TRAIN SET | Epoch [04/04], Step [0276/0304], Loss: 0.0000 | Elapsed: 0:03:02\n",
      "| TRAIN SET | Epoch [04/04], Step [0277/0304], Loss: 0.0000 | Elapsed: 0:03:03\n",
      "| TRAIN SET | Epoch [04/04], Step [0278/0304], Loss: 0.0000 | Elapsed: 0:03:04\n",
      "| TRAIN SET | Epoch [04/04], Step [0279/0304], Loss: 0.0218 | Elapsed: 0:03:04\n",
      "| TRAIN SET | Epoch [04/04], Step [0280/0304], Loss: 0.0000 | Elapsed: 0:03:05\n",
      "| TRAIN SET | Epoch [04/04], Step [0281/0304], Loss: 0.0000 | Elapsed: 0:03:06\n",
      "| TRAIN SET | Epoch [04/04], Step [0282/0304], Loss: 0.1263 | Elapsed: 0:03:06\n",
      "| TRAIN SET | Epoch [04/04], Step [0283/0304], Loss: 0.2193 | Elapsed: 0:03:07\n",
      "| TRAIN SET | Epoch [04/04], Step [0284/0304], Loss: 0.0192 | Elapsed: 0:03:08\n",
      "| TRAIN SET | Epoch [04/04], Step [0285/0304], Loss: 0.0002 | Elapsed: 0:03:08\n",
      "| TRAIN SET | Epoch [04/04], Step [0286/0304], Loss: 0.0526 | Elapsed: 0:03:09\n",
      "| TRAIN SET | Epoch [04/04], Step [0287/0304], Loss: 0.0146 | Elapsed: 0:03:10\n",
      "| TRAIN SET | Epoch [04/04], Step [0288/0304], Loss: 0.0000 | Elapsed: 0:03:10\n",
      "| TRAIN SET | Epoch [04/04], Step [0289/0304], Loss: 0.0000 | Elapsed: 0:03:11\n",
      "| TRAIN SET | Epoch [04/04], Step [0290/0304], Loss: 0.0000 | Elapsed: 0:03:12\n",
      "| TRAIN SET | Epoch [04/04], Step [0291/0304], Loss: 0.0360 | Elapsed: 0:03:12\n",
      "| TRAIN SET | Epoch [04/04], Step [0292/0304], Loss: 0.0000 | Elapsed: 0:03:13\n",
      "| TRAIN SET | Epoch [04/04], Step [0293/0304], Loss: 0.1202 | Elapsed: 0:03:14\n",
      "| TRAIN SET | Epoch [04/04], Step [0294/0304], Loss: 0.1914 | Elapsed: 0:03:14\n",
      "| TRAIN SET | Epoch [04/04], Step [0295/0304], Loss: 0.0775 | Elapsed: 0:03:15\n",
      "| TRAIN SET | Epoch [04/04], Step [0296/0304], Loss: 0.0000 | Elapsed: 0:03:16\n",
      "| TRAIN SET | Epoch [04/04], Step [0297/0304], Loss: 0.0000 | Elapsed: 0:03:16\n",
      "| TRAIN SET | Epoch [04/04], Step [0298/0304], Loss: 0.0163 | Elapsed: 0:03:17\n",
      "| TRAIN SET | Epoch [04/04], Step [0299/0304], Loss: 0.1971 | Elapsed: 0:03:17\n",
      "| TRAIN SET | Epoch [04/04], Step [0300/0304], Loss: 0.0000 | Elapsed: 0:03:19\n",
      "| TRAIN SET | Epoch [04/04], Step [0301/0304], Loss: 0.4029 | Elapsed: 0:03:20\n",
      "| TRAIN SET | Epoch [04/04], Step [0302/0304], Loss: 0.0398 | Elapsed: 0:03:20\n",
      "| TRAIN SET | Epoch [04/04], Step [0303/0304], Loss: 0.1169 | Elapsed: 0:03:21\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epoch took: 0:03:22\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:13:23 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_stats = []\n",
    "history = defaultdict(list)\n",
    "\n",
    "resume_epoch = 0\n",
    "print_every = 1 # 10\n",
    "save_every = 200 # 1000\n",
    "\n",
    "print('Initializing ...')\n",
    "print(\"Training...\")\n",
    "\n",
    "total_t0 = time.time()\n",
    "for epoch_idx in range(resume_epoch, num_epochs):\n",
    "    total_loss = 0\n",
    "    total_score = 0\n",
    "\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_idx + 1, num_epochs))\n",
    "    print('Training...')\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    net.train()  # TODO: IMPORTANT !\n",
    "    for batch_idx, train_batch_data in enumerate(train_dataloader):\n",
    "        # Clear gradients\n",
    "        net.zero_grad()  # TODO: check validity !\n",
    "        opti.zero_grad()\n",
    "\n",
    "        # Converting these to cuda tensors\n",
    "        pos_ids, pos_mask, pos_type_ids, \\\n",
    "        neg_ids, neg_mask, neg_type_ids, \\\n",
    "        seqA_len, posSeqB_len, negSeqB_len, \\\n",
    "        label = train_batch_data\n",
    "\n",
    "        pos_ids, pos_mask, pos_type_ids, \\\n",
    "        neg_ids, neg_mask, neg_type_ids, \\\n",
    "        seqA_len, posSeqB_len, negSeqB_len, \\\n",
    "        label = pos_ids.to(device), pos_mask.to(device), pos_type_ids.to(device), \\\n",
    "                neg_ids.to(device), neg_mask.to(device), neg_type_ids.to(device), \\\n",
    "                seqA_len.to(device), posSeqB_len.to(device), negSeqB_len.to(device), \\\n",
    "                label.to(device)\n",
    "\n",
    "        pos_net_output = net(pos_ids, attn_masks=pos_mask, type_ids=pos_type_ids)\n",
    "        neg_net_output = net(neg_ids, attn_masks=neg_mask, type_ids=neg_type_ids)\n",
    "        # # TODO: do i need a softmax or not ?\n",
    "\n",
    "        # Computing loss\n",
    "        # loss = criterion(net_output, label.float())\n",
    "        loss = criterion(pos_net_output, neg_net_output, label.float())\n",
    "        batch_loss = loss.item()\n",
    "        # total_train_loss += loss.item()\n",
    "\n",
    "        # Back propagating the gradients\n",
    "        loss.backward()\n",
    "        if config.training['gradient_clipping']['use']:\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), config.training['gradient_clipping']['clip_value'])\n",
    "\n",
    "        # Optimization step\n",
    "        opti.step()\n",
    "\n",
    "        # Progress update every display_step batches.\n",
    "        # if batch_idx % display_step == 0 and not batch_idx == 0:\n",
    "        #     elapsed = format_time(time.time() - t0)\n",
    "        #     # print('  Batch {:>5,}  of  {:>5,}  :  loss - {:>5,.2f}    Elapsed: {:}.'.format(batch_idx,\n",
    "        #     #                                                                                 len(train_dataloader),\n",
    "        #     #                                                                                 loss, elapsed))\n",
    "        #     print('  Epoch {:>5,}  of  {:>5,}  :  Batch {:>5,}  of  {:>5,}  :  \\\n",
    "        #     loss - {:>5,.2f}    Elapsed: {:}.'.format(epoch_idx + 1, num_epochs,\n",
    "        #                                               batch_idx + 1, len(train_dataloader),\n",
    "        #                                               loss, elapsed))\n",
    "        #     training_stats.append(\n",
    "        #         {\n",
    "        #             'epoch': epoch_idx + 1,\n",
    "        #             'batch': batch_idx + 1,\n",
    "        #             'step': (epoch_idx * n_train_batches) + batch_idx + 1,\n",
    "        #             'Training Loss': loss,\n",
    "        #             # 'Training Loss': avg_train_loss,\n",
    "        #             # 'Training Time': training_time,\n",
    "        #         }\n",
    "        #     )\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        with open(os.path.join(config.data['results_dir'], 'train-log-epoch.txt' ), 'a') as f:\n",
    "                f.write(str(batch_idx+1) + '\\t' + str(batch_idx+1) + '\\t' + str(batch_loss) + '\\t' + '\\n')\n",
    "        # writer.add_scalar('training loss', loss.item(), epoch * n_train_batches + batch_idx)\n",
    "        # writer.add_scalar('training score', batch_score, epoch * n_train_batches + batch_idx)\n",
    "\n",
    "        training_stats.append(\n",
    "                {\n",
    "                    'epoch': epoch_idx + 1,\n",
    "                    'batch': batch_idx + 1,\n",
    "                    'step': (epoch_idx * n_train_batches) + batch_idx + 1,\n",
    "                    'Training Loss': batch_loss,\n",
    "                    # 'Training Loss': avg_train_loss,\n",
    "                    # 'Training Time': training_time,\n",
    "                }\n",
    "            )\n",
    "                \n",
    "        if batch_idx % print_every == 0: # Print progress\n",
    "            total_loss_avg = total_loss / print_every \n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('| TRAIN SET | Epoch [{:02d}/{:02d}], Step [{:04d}/{:04d}], Loss: {:.4f} | Elapsed: {:}'\n",
    "                          .format(epoch_idx+1, num_epochs, batch_idx, int(n_train_batches), total_loss_avg, elapsed))\n",
    "            total_loss = 0              \n",
    "        \n",
    "        if ( (batch_idx == n_train_batches-1) or ((batch_idx+1) % save_every == 0) ): # Save checkpoint\n",
    "            directory = os.path.join(config.data['results_dir'], 'ranking-pytorch-model')\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save(net.state_dict(),\n",
    "                       os.path.join(directory, 'epoch-{}.batch-{}.{}.pt'.format(epoch_idx+1, batch_idx+1, 'checkpoint')))\n",
    "\n",
    "\n",
    "    scheduler.step()  # TODO: IMPORTANT !\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "history_df = pd.DataFrame({\"step\": [e['step'] for e in training_stats],\n",
    "                           \"Training Loss\": [e['Training Loss'] for e in training_stats]})\n",
    "# history_df.to_csv(os.path.join(config.data['results_dir'], \"history.csv\"), index=False)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "\n",
    "if not config.cmd_args['mode'] == \"experiment\":\n",
    "    torch.save(net, os.path.join(config.data['results_dir'], \"model-dump.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_csv(os.path.join(config.data['results_dir'], \"history.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dimensional-titanium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# history_df = pd.DataFrame({\"step\": [e['step'] for e in training_stats],\n",
    "#                            \"Training Loss\": [e['Training Loss'].cpu() for e in training_stats]})\n",
    "# # history_df.to_csv(os.path.join(config.data['results_dir'], \"history.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "involved-pizza",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete!\n",
      "Total training took 0:13:23 (h:mm:ss)\n",
      "\n",
      "Validation...\n",
      "Number of test batches :  880 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TRECCARModel(\n",
       "  (bert_layer): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls_layer): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))\n",
    "\n",
    "if not config.cmd_args['mode'] == \"experiment\":\n",
    "    torch.save(net, os.path.join(config.data['results_dir'], \"model-dump.pkl\"))\n",
    "# ========================================\n",
    "#               NOT Validation, Just Testing\n",
    "# ========================================\n",
    "print(\"\")\n",
    "print(\"Validation...\")\n",
    "t0 = time.time()\n",
    "\n",
    "test_dataset = TestTRECDataset(config.data['test_data'], config, is_train=False, bert_tokenizer=tokenizer)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=config.training[\"test_batch_size\"],\n",
    "                             pin_memory=config.cmd_args['device'] == 'cuda',\n",
    "                             num_workers=config.training['num_workers'],\n",
    "                             shuffle=True)\n",
    "n_test_batches = len(test_dataloader)\n",
    "print(\"Number of test batches : \", n_test_batches, \"\\n\")\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "floral-creativity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 11.90 GiB total capacity; 10.92 GiB already allocated; 171.69 MiB free; 10.97 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d98e34b1bcc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mnet_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mnet_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/2021/ir/entity-reranking/best-text-BERT/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, seq, attn_masks, type_ids)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;34m-\u001b[0m\u001b[0mattn_masks\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mattention\u001b[0m \u001b[0mmasks\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mavoid\u001b[0m \u001b[0mcontribution\u001b[0m \u001b[0mof\u001b[0m \u001b[0mPAD\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcont_reps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;31m# cls_rep = cont_reps[:, 0]  # TODO: why selecting index-0 ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0membedding_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         encoder_outputs = self.encoder(embedding_output,\n\u001b[0m\u001b[1;32m    709\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                        head_mask=head_mask)\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mself_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/raid6/home/ramraj/anaconda3/envs/ir-research-py3.8/lib/python3.8/site-packages/pytorch_transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB (GPU 0; 11.90 GiB total capacity; 10.92 GiB already allocated; 171.69 MiB free; 10.97 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "qID_list = []\n",
    "paraID_list = []\n",
    "pScore_list = []\n",
    "t1 = time.time()\n",
    "for batch_idx, test_batch_data in enumerate(test_dataloader):\n",
    "    # Converting these to cuda tensors\n",
    "    input_seq, input_mask, input_type_ids, label, qID, passageID, seqA_len, seqB_len = test_batch_data\n",
    "    input_seq, input_mask, input_type_ids, \\\n",
    "    seqA_len, seqB_len = input_seq.to(device), input_mask.to(device), input_type_ids.to(device), \\\n",
    "                         seqA_len.to(device), seqB_len.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        net_output = net(input_seq, attn_masks=input_mask, type_ids=input_type_ids)\n",
    "        net_output = net_output.detach().cpu().numpy()\n",
    "\n",
    "        for i in range(len(qID)):\n",
    "            qID_list.append(qID[i])\n",
    "            paraID_list.append(passageID[i])\n",
    "            pScore_list.append(net_output[i])\n",
    "    elapsed = format_time(time.time() - t1)\n",
    "    \n",
    "    if batch_idx % 50 == 0:\n",
    "        print('  Batch {:>5,}  of  {:>5,}  :  processed    Elapsed: {:}.'.format(batch_idx,\n",
    "                                                                             n_test_batches,\n",
    "                                                                             elapsed))\n",
    "\n",
    "pScore_list = [float(e) for e in pScore_list]\n",
    "predicted_df = pd.DataFrame({\"qID\": qID_list,\n",
    "                             \"pID\": paraID_list,\n",
    "                             \"pScore\": pScore_list}, columns=[\"qID\", \"pID\", \"pScore\"])\n",
    "if not config.cmd_args['mode'] == \"experiment\":\n",
    "    predicted_df.to_csv(os.path.join(config.data['results_dir'], \"predictions.csv\"))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "#               Reverse Sorting Relevance\n",
    "# ================================================\n",
    "predicted_df = predicted_df[['qID', 'pID', 'pScore']]\n",
    "grouped_pred_df = predicted_df.groupby([\"qID\"])\n",
    "num_queries = len(grouped_pred_df)\n",
    "missing_q_sets = 0\n",
    "save_ranked_file = os.path.join(config.data['results_dir'], \"ranked.test.relevance.txt\")\n",
    "with open(save_ranked_file, 'w') as write_file:\n",
    "    q_cnt = 1\n",
    "    for name, row_group in grouped_pred_df:\n",
    "        rank_cnt = 1\n",
    "\n",
    "        # ======= SORTING =======\n",
    "        sorted_row_group = row_group.sort_values(by='pScore', ascending=False, inplace=False)\n",
    "        # =======================\n",
    "\n",
    "        if len(sorted_row_group) != 100:\n",
    "            # print(\">>>>>>>>>>> Missing query %s with shape %s\" % (name, sorted_row_group.shape))\n",
    "            # print(\">>>>>>>>>>> Missing query with size %s\" % sorted_row_group.shape[0])\n",
    "            missing_q_sets += 1\n",
    "\n",
    "        for i, row in sorted_row_group.iterrows():\n",
    "            write_file.write(\"%s\\tQ0\\t%s\\t%s\\t%s\\trchan31\\n\" % \\\n",
    "                             (row[\"qID\"], row[\"pID\"], rank_cnt, row[\"pScore\"]))\n",
    "            rank_cnt += 1\n",
    "\n",
    "        if q_cnt % 100 == 0: print(\"Finished composing for query number : %s / %s\" % (q_cnt, num_queries))\n",
    "        q_cnt += 1\n",
    "print()\n",
    "print(\"Missing query-doc pairs : \", missing_q_sets)\n",
    "print(\"Done train, val, and test !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ready-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranked.test.relevance.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amazing-proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\tcbf3d5427fd8d7956c027fddd46e14b3779aa94b\t96\t2.5369160175323486\trchan31\r\n",
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\te2d8413a1f00b1a8c29bea03766fbd7bb5d7b309\t97\t2.5269246101379395\trchan31\r\n",
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\t97596ad40e87e4528aac5f7b22005884819853d1\t98\t2.51876163482666\trchan31\r\n",
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\t8b3652a6bc32fb5b9a0b8efebb02f5609a43d075\t99\t2.4430224895477295\trchan31\r\n",
      "enwiki:Yellowstone%20National%20Park/Recreation\tQ0\tc13cea34c7beba80a6026cc1721a1bad12e77497\t100\t2.0023608207702637\trchan31\r\n"
     ]
    }
   ],
   "source": [
    "! tail -5 exp1/ranked.test.relevance.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stopped-injection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatic-test.pages.cbor-hierarchical.qrels\r\n",
      "lenient.benchmarkY1test.cbor.hierarchical.qrels\r\n",
      "manual.benchmarkY1test.cbor.hierarchical.qrels\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../Eval/qrelsY1-test.V2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "oriental-survey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\trchan31\r\n",
      "num_q                 \tall\t2254\r\n",
      "num_ret               \tall\t225156\r\n",
      "num_rel               \tall\t6192\r\n",
      "num_rel_ret           \tall\t2375\r\n",
      "map                   \tall\t0.0935\r\n",
      "gm_map                \tall\t0.0034\r\n",
      "Rprec                 \tall\t0.0572\r\n",
      "bpref                 \tall\t0.4689\r\n",
      "recip_rank            \tall\t0.1524\r\n",
      "iprec_at_recall_0.00  \tall\t0.1565\r\n",
      "iprec_at_recall_0.10  \tall\t0.1562\r\n",
      "iprec_at_recall_0.20  \tall\t0.1461\r\n",
      "iprec_at_recall_0.30  \tall\t0.1229\r\n",
      "iprec_at_recall_0.40  \tall\t0.0981\r\n",
      "iprec_at_recall_0.50  \tall\t0.0941\r\n",
      "iprec_at_recall_0.60  \tall\t0.0684\r\n",
      "iprec_at_recall_0.70  \tall\t0.0665\r\n",
      "iprec_at_recall_0.80  \tall\t0.0591\r\n",
      "iprec_at_recall_0.90  \tall\t0.0585\r\n",
      "iprec_at_recall_1.00  \tall\t0.0585\r\n",
      "P_5                   \tall\t0.0491\r\n",
      "P_10                  \tall\t0.0388\r\n",
      "P_15                  \tall\t0.0331\r\n",
      "P_20                  \tall\t0.0290\r\n",
      "P_30                  \tall\t0.0234\r\n",
      "P_100                 \tall\t0.0105\r\n",
      "P_200                 \tall\t0.0053\r\n",
      "P_500                 \tall\t0.0021\r\n",
      "P_1000                \tall\t0.0011\r\n"
     ]
    }
   ],
   "source": [
    "! ../Eval/trec_eval-master/trec_eval ../Eval/qrelsY1-test.V2.0/automatic-test.pages.cbor-hierarchical.qrels exp1/ranked.test.relevance.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-accessory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
