{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "romantic-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "virgin-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = \"/raid6/home/ramraj/2021/ir/Contextual-Reranking/Data/\"\n",
    "\n",
    "BENCHMARK_TRAIN_FOLD_FOLDER = os.path.join(ROOT_FOLDER, \"benchmark-train-relevance-v2.0\")\n",
    "BENCHMARK_TEST_FILE = os.path.join(ROOT_FOLDER, \"test-data\", \"ramraj-test-data-top100-BM25.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-alignment",
   "metadata": {},
   "source": [
    "# 1. Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "marine-royalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = sorted(glob.glob(os.path.join(BENCHMARK_TRAIN_FOLD_FOLDER, \"fold-*-train.pages.cbor-hierarchical.benchmark.json\")))\n",
    "len(train_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "atmospheric-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1937"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "for train_file in train_files:\n",
    "    tmp_data = json.load(open(train_file, 'r'))\n",
    "    train_data.extend(tmp_data)\n",
    "    \n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "supreme-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qString': 'Ice bath Techniques Ice baths versus cold baths',\n",
       " 'RelevantDocuments': [{'docScore': 1.0,\n",
       "   'docID': '54bacb1c81f70a1db3d4d8e16fb551a5298eafbf',\n",
       "   'docText': 'Several sources suggest that cold baths (60â\\x80\\x9375 degrees Fahrenheit) were preferable to ice baths. Physiotherapist Tony Wilson of the University of Southampton said that extremely cold temperatures were unnecessary and a \"cold bath\" would be just as effective as an ice bath. Another agreed that a mere cold bath is preferable to ice baths which are \"unnecessary.\" A third report suggested that cool water (60â\\x80\\x9375 degrees Fahrenheit) was just as good as cold water (54â\\x80\\x9360 degrees Fahrenheit) and that eight to ten minutes should be sufficient time, and warned against exceeding ten minutes.'}],\n",
       " 'qID': 'enwiki:Ice%20bath/Techniques/Ice%20baths%20versus%20cold%20baths'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "natural-ground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4863"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cnt = 0\n",
    "for train_data_sample in train_data:    \n",
    "    for rel_docs in train_data_sample['RelevantDocuments']:        \n",
    "        doc_cnt += 1\n",
    "        \n",
    "doc_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-korean",
   "metadata": {},
   "source": [
    "# 2. Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "naked-chicken",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225156"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = json.load(open(BENCHMARK_TEST_FILE, 'r'))\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "studied-peoples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DocID': 'a28ff3028b5669ed187a0a7138350af332ec7ed1', 'Feedback': '', 'QueryID': 'enwiki:Aftertaste', 'DocText': \"In wine tasting the aftertaste or finish of a wine, is an important part of the evaluation. After tasting a wine, a taster will determine the wine's aftertaste, which is a major determinant of the wine's quality. The aftertaste of a wine can be described as bitter, persistent, short, sweet, smooth, or even non-existent. Included in assessing the aftertaste of a wine is consideration of the aromas still present after swallowing. High quality wines typically have long finishes accompanied by pleasant aromas. By assessing the combination of olfactory and aftertaste sensations, wine tasting actually determines not only the aftertaste profile of a wine, but its flavor profile as well.\", 'QueryText': 'Aftertaste'}\n"
     ]
    }
   ],
   "source": [
    "# easier format\n",
    "\n",
    "for tmp in test_data:\n",
    "    print(tmp)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-scoop",
   "metadata": {},
   "source": [
    "# 3. Analyze vocab in train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "danish-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    # Replace annoying unicode with a space\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    # The following replacements are suggested in the paper\n",
    "    # BidAF (Seo et al., 2016)\n",
    "    text = text.replace(\"''\", '\" ')\n",
    "    text = text.replace(\"``\", '\" ')\n",
    "\n",
    "    # Space out punctuation\n",
    "    space_list = \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    space_list = \"!\\\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    text = text.translate(str.maketrans({key: \" {0} \".format(key) for key in space_list}))\n",
    "\n",
    "    # space out singlequotes a bit better (and like stanford)\n",
    "    text = text.replace(\"'\", \" '\")\n",
    "    \n",
    "    # use any APIs\n",
    "    text = text.replace('\\t', '').replace('\\n', '').lower().strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "retired-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1988, 26990)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_q_vocab = set()\n",
    "train_d_vocab = set()\n",
    "\n",
    "for train_data_sample in train_data:\n",
    "    q_text = tokenise( train_data_sample['qString'] )\n",
    "    train_q_vocab.update( q_text.split() )\n",
    "    \n",
    "    for rel_docs in train_data_sample['RelevantDocuments']:\n",
    "        doc_text = tokenise( rel_docs['docText'] )\n",
    "        \n",
    "        train_d_vocab.update( doc_text.split() )\n",
    "\n",
    "    \n",
    "len(train_q_vocab), len(train_d_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "metallic-nelson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 189721)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_q_vocab = set()\n",
    "test_d_vocab = set()\n",
    "\n",
    "for idx, test_data_sample in enumerate(test_data):\n",
    "    q_text = tokenise( test_data_sample['QueryText'] )\n",
    "    doc_text = tokenise( test_data_sample['DocText'] )\n",
    "\n",
    "    test_q_vocab.update(q_text.split())\n",
    "    test_d_vocab.update(doc_text.split())\n",
    "    \n",
    "    if idx % 10000 == 0: print(\"Finished : \", idx)\n",
    "    \n",
    "len(test_q_vocab), len(test_d_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-history",
   "metadata": {},
   "source": [
    "# Format test-data to convenient format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "inner-district",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225156, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# test_qd_map = defaultdict(list)\n",
    "\n",
    "qID_list = []\n",
    "qText_list = []\n",
    "dID_list = []\n",
    "dText_list = []\n",
    "\n",
    "for idx, test_data_sample in enumerate(test_data):\n",
    "    q_text = test_data_sample['QueryText']\n",
    "    doc_text = test_data_sample['DocText']\n",
    "    \n",
    "    qID = test_data_sample['QueryID']\n",
    "    dID = test_data_sample['DocID']\n",
    "    \n",
    "    qID_list.append(qID)\n",
    "    qText_list.append(q_text)\n",
    "    dID_list.append(dID)\n",
    "    dText_list.append(doc_text)\n",
    "\n",
    "#     if idx % 10000 == 0: print(\"Finished : \", idx)\n",
    "        \n",
    "df = pd.DataFrame({\"qID\": qID_list, \"docID\": dID_list, \"qText\": qText_list, \"docText\": dText_list})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "instant-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2254, 93124)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['qID'])), len(set(df['docID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "super-agency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Not 100 search retrievals\n",
      "... Not 100 search retrievals\n",
      "... Not 100 search retrievals\n",
      "... Not 100 search retrievals\n",
      "... Not 100 search retrievals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = df.groupby('qID')\n",
    "\n",
    "test_qd_map = []\n",
    "\n",
    "missing_100_retrievals_queries_cnt = 0\n",
    "\n",
    "for key, query_df in grouped_df:\n",
    "    \n",
    "    qID = query_df.iloc[0]['qID']\n",
    "    qText = query_df.iloc[0]['qText']\n",
    "    \n",
    "    query_sample_info = {}\n",
    "    query_sample_info['qID'] = qID\n",
    "    query_sample_info['qString'] = qText\n",
    "    query_sample_info['RelevantDocuments'] = []\n",
    "    \n",
    "    if query_df.shape[0] != 100:\n",
    "        print('... Not 100 search retrievals')\n",
    "        missing_100_retrievals_queries_cnt += 1\n",
    "    \n",
    "    rank_cnt = 0\n",
    "    for idx, row in query_df.iterrows():\n",
    "        \n",
    "        docID = row['docID']\n",
    "        docText = row['docText']        \n",
    "        \n",
    "        query_sample_info['RelevantDocuments'].append({'docID': docID, 'docText': docText, 'docScore': rank_cnt})\n",
    "        rank_cnt += 1\n",
    "        \n",
    "    test_qd_map.append( query_sample_info )\n",
    "       \n",
    "missing_100_retrievals_queries_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "extra-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NEW_FORMAT_TEST_FILE = os.path.join(ROOT_FOLDER, \"test-data\", \"ramraj-test-data-top100-BM25-opt.json\")\n",
    "\n",
    "with open(SAVE_NEW_FORMAT_TEST_FILE, 'w') as f:\n",
    "    json.dump(test_qd_map, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-sailing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
