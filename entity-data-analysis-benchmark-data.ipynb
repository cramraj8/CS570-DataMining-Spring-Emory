{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romantic-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "listed-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data with Entities\n",
    "\n",
    "ROOT_FOLDER = \"/raid6/home/ramraj/2021/ir/entity-reranking/Entity-Linking/\"\n",
    "\n",
    "# BENCHMARK_TRAIN_FOLD_FOLDER = os.path.join(ROOT_FOLDER, \"benchmark-train-relevance-v2.0\")\n",
    "# BENCHMARK_TEST_FILE = os.path.join(ROOT_FOLDER, \"test-data\", \"ramraj-test-data-top100-BM25.json\")\n",
    "BENCHMARK_TRAIN_FOLD_FOLDER = os.path.join(ROOT_FOLDER, \"Train-with-entities\")\n",
    "BENCHMARK_TEST_FILE = os.path.join(ROOT_FOLDER, \"Test-with-entities/ramraj-test-data-top100-BM25-opt.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-alignment",
   "metadata": {},
   "source": [
    "# 1. Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "marine-royalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files = sorted(glob.glob(os.path.join(BENCHMARK_TRAIN_FOLD_FOLDER, \"fold-*.json\")))\n",
    "len(train_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atmospheric-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1937"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = []\n",
    "for train_file in train_files:\n",
    "    tmp_data = json.load(open(train_file, 'r'))\n",
    "    train_data.extend(tmp_data)\n",
    "    \n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supreme-grammar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qString': 'Ice bath Techniques Ice baths versus cold baths',\n",
       " 'RelevantDocuments': [{'docScore': 1.0,\n",
       "   'docID': '54bacb1c81f70a1db3d4d8e16fb551a5298eafbf',\n",
       "   'docText': 'Several sources suggest that cold baths (60â\\x80\\x9375 degrees Fahrenheit) were preferable to ice baths. Physiotherapist Tony Wilson of the University of Southampton said that extremely cold temperatures were unnecessary and a \"cold bath\" would be just as effective as an ice bath. Another agreed that a mere cold bath is preferable to ice baths which are \"unnecessary.\" A third report suggested that cool water (60â\\x80\\x9375 degrees Fahrenheit) was just as good as cold water (54â\\x80\\x9360 degrees Fahrenheit) and that eight to ten minutes should be sufficient time, and warned against exceeding ten minutes.',\n",
       "   'dEntities': [{'mention': 'Fahrenheit',\n",
       "     'entity_title': 'Fahrenheit',\n",
       "     'score': 0.2771810293197632,\n",
       "     'entity_id': 11524},\n",
       "    {'mention': 'ice',\n",
       "     'entity_title': 'Ice',\n",
       "     'score': 0.19626471400260925,\n",
       "     'entity_id': 14946},\n",
       "    {'mention': 'baths',\n",
       "     'entity_title': 'Bathing',\n",
       "     'score': 0.1665409505367279,\n",
       "     'entity_id': 730219},\n",
       "    {'mention': 'Physiotherapist',\n",
       "     'entity_title': 'Physical therapy',\n",
       "     'score': 0.26700273156166077,\n",
       "     'entity_id': 24022},\n",
       "    {'mention': 'Tony Wilson',\n",
       "     'entity_title': 'Tony Wilson',\n",
       "     'score': 0.4693140685558319,\n",
       "     'entity_id': 298546},\n",
       "    {'mention': 'University of Southampton',\n",
       "     'entity_title': 'University of Southampton',\n",
       "     'score': 0.4723958373069763,\n",
       "     'entity_id': 98078},\n",
       "    {'mention': 'ice bath',\n",
       "     'entity_title': 'Ice bath',\n",
       "     'score': 0.1599999964237213,\n",
       "     'entity_id': 32750328},\n",
       "    {'mention': 'cold bath',\n",
       "     'entity_title': 'Cooling bath',\n",
       "     'score': 0.1670088768005371,\n",
       "     'entity_id': 10176902},\n",
       "    {'mention': 'bath',\n",
       "     'entity_title': 'Bathing',\n",
       "     'score': 0.19184431433677673,\n",
       "     'entity_id': 730219},\n",
       "    {'mention': 'ice',\n",
       "     'entity_title': 'Ice',\n",
       "     'score': 0.2125830203294754,\n",
       "     'entity_id': 14946},\n",
       "    {'mention': 'baths',\n",
       "     'entity_title': 'Thermae',\n",
       "     'score': 0.16272060573101044,\n",
       "     'entity_id': 432937},\n",
       "    {'mention': 'Fahrenheit',\n",
       "     'entity_title': 'Fahrenheit',\n",
       "     'score': 0.14081145823001862,\n",
       "     'entity_id': 11524},\n",
       "    {'mention': 'water',\n",
       "     'entity_title': 'Water',\n",
       "     'score': 0.19323697686195374,\n",
       "     'entity_id': 33306},\n",
       "    {'mention': 'Fahrenheit',\n",
       "     'entity_title': 'Fahrenheit',\n",
       "     'score': 0.3200743794441223,\n",
       "     'entity_id': 11524},\n",
       "    {'mention': 'eight',\n",
       "     'entity_title': '8 (number)',\n",
       "     'score': 0.21514774858951569,\n",
       "     'entity_id': 208174},\n",
       "    {'mention': 'ten',\n",
       "     'entity_title': '10 (number)',\n",
       "     'score': 0.22089672088623047,\n",
       "     'entity_id': 208151},\n",
       "    {'mention': 'time',\n",
       "     'entity_title': 'Time',\n",
       "     'score': 0.10155002772808075,\n",
       "     'entity_id': 30012}]}],\n",
       " 'qID': 'enwiki:Ice%20bath/Techniques/Ice%20baths%20versus%20cold%20baths',\n",
       " 'qEntities': [{'mention': 'Ice bath',\n",
       "   'entity_title': 'Ice bath',\n",
       "   'score': 0.1599999964237213,\n",
       "   'entity_id': 32750328},\n",
       "  {'mention': 'Techniques',\n",
       "   'entity_title': 'Technology',\n",
       "   'score': 0.17657826840877533,\n",
       "   'entity_id': 29816},\n",
       "  {'mention': 'Ice',\n",
       "   'entity_title': 'Ice',\n",
       "   'score': 0.20710322260856628,\n",
       "   'entity_id': 14946},\n",
       "  {'mention': 'baths',\n",
       "   'entity_title': 'Bathing',\n",
       "   'score': 0.14025042951107025,\n",
       "   'entity_id': 730219},\n",
       "  {'mention': 'cold',\n",
       "   'entity_title': 'Cold',\n",
       "   'score': 0.1462778002023697,\n",
       "   'entity_id': 19725090}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "natural-ground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4863"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_cnt = 0\n",
    "for train_data_sample in train_data:    \n",
    "    for rel_docs in train_data_sample['RelevantDocuments']:        \n",
    "        doc_cnt += 1\n",
    "        \n",
    "doc_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-korean",
   "metadata": {},
   "source": [
    "# 2. Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "naked-chicken",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2254"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = json.load(open(BENCHMARK_TEST_FILE, 'r'))\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier format\n",
    "\n",
    "for tmp in test_data:\n",
    "    print(tmp)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-scoop",
   "metadata": {},
   "source": [
    "# 3. Analyze vocab in train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "danish-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    # Replace annoying unicode with a space\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    # The following replacements are suggested in the paper\n",
    "    # BidAF (Seo et al., 2016)\n",
    "    text = text.replace(\"''\", '\" ')\n",
    "    text = text.replace(\"``\", '\" ')\n",
    "\n",
    "    # Space out punctuation\n",
    "    space_list = \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    space_list = \"!\\\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~\"\n",
    "    text = text.translate(str.maketrans({key: \" {0} \".format(key) for key in space_list}))\n",
    "\n",
    "    # space out singlequotes a bit better (and like stanford)\n",
    "    text = text.replace(\"'\", \" '\")\n",
    "    \n",
    "    # use any APIs\n",
    "    text = text.replace('\\t', '').replace('\\n', '').lower().strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-threshold",
   "metadata": {},
   "source": [
    "# 4. Count Entities in Q & D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "checked-router",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1576, 19642)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_q_ent_vocab = set()\n",
    "train_d_ent_vocab = set()\n",
    "\n",
    "for train_data_sample in train_data:\n",
    "    q_ent_list = train_data_sample['qEntities']\n",
    "    for ent in q_ent_list:\n",
    "        train_q_ent_vocab.add(ent['entity_title'])\n",
    "    \n",
    "    \n",
    "    for rel_docs in train_data_sample['RelevantDocuments']:\n",
    "        d_ent_list = rel_docs['dEntities']\n",
    "        for ent in d_ent_list:\n",
    "            train_d_ent_vocab.add(ent['entity_title'])\n",
    "\n",
    "    \n",
    "len(train_q_ent_vocab), len(train_d_ent_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "silent-access",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1830, 168710)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_q_ent_vocab = set()\n",
    "test_d_ent_vocab = set()\n",
    "\n",
    "for test_data_sample in test_data:\n",
    "    q_ent_list = test_data_sample['qEntities']\n",
    "    for ent in q_ent_list:\n",
    "        test_q_ent_vocab.add(ent['entity_title'])\n",
    "    \n",
    "    \n",
    "    for rel_docs in test_data_sample['RelevantDocuments']:\n",
    "        d_ent_list = rel_docs['dEntities']\n",
    "        for ent in d_ent_list:\n",
    "            test_d_ent_vocab.add(ent['entity_title'])\n",
    "\n",
    "    \n",
    "len(test_q_ent_vocab), len(test_d_ent_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-blowing",
   "metadata": {},
   "source": [
    "# 5. Sample-wise entity & word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sexual-secret",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities -> Query : Min:  0  Max :  11\n",
      "Entities -> Doc   : Min:  0  Max :  117\n",
      "Words    -> Query : Min:  1  Max :  29\n",
      "Words    -> Doc   : Min:  2  Max :  404\n"
     ]
    }
   ],
   "source": [
    "train_q_ent_cnt = []\n",
    "train_d_ent_cnt = []\n",
    "train_q_word_cnt = []\n",
    "train_d_word_cnt = []\n",
    "\n",
    "for train_data_sample in train_data:\n",
    "    q_ent_list = train_data_sample['qEntities']\n",
    "    train_q_ent_cnt.append(len(q_ent_list))\n",
    "    \n",
    "    q_text = tokenise( train_data_sample['qString'] ).split()\n",
    "    train_q_word_cnt.append(len(q_text))\n",
    "    \n",
    "    \n",
    "    for rel_docs in train_data_sample['RelevantDocuments']:\n",
    "        d_ent_list = rel_docs['dEntities']\n",
    "        train_d_ent_cnt.append(len(d_ent_list))\n",
    "\n",
    "        doc_text = tokenise( rel_docs['docText'] ).split()\n",
    "        \n",
    "        train_d_word_cnt.append(len(doc_text))\n",
    "\n",
    "    \n",
    "print(\"Entities -> Query : Min: \", min(train_q_ent_cnt), \" Max : \", max(train_q_ent_cnt))\n",
    "print(\"Entities -> Doc   : Min: \", min(train_d_ent_cnt), \" Max : \", max(train_d_ent_cnt))\n",
    "print(\"Words    -> Query : Min: \", min(train_q_word_cnt), \" Max : \", max(train_q_word_cnt))\n",
    "print(\"Words    -> Doc   : Min: \", min(train_d_word_cnt), \" Max : \", max(train_d_word_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "painful-adapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Entities -> Query :  41\n",
      "0 Entities -> Doc   :  31\n",
      "1 Words    -> Query :  48\n",
      "2 Words    -> Doc   :  6\n"
     ]
    }
   ],
   "source": [
    "train_q_0_ent_samples = 0\n",
    "train_q_1_word_samples = 0\n",
    "# train_2_ent_samples = 0\n",
    "# train_2_word_samples = 0\n",
    "train_d_0_ent_samples = 0\n",
    "train_d_2_word_samples = 0\n",
    "\n",
    "for train_data_sample in train_data:\n",
    "    q_ent_list = train_data_sample['qEntities']\n",
    "    \n",
    "    if len(q_ent_list) == 0:\n",
    "        train_q_0_ent_samples += 1\n",
    "\n",
    "    q_text = tokenise( train_data_sample['qString'] ).split()\n",
    "    \n",
    "    if len(q_text) == 1:\n",
    "        train_q_1_word_samples += 1\n",
    "\n",
    "    \n",
    "    for rel_docs in train_data_sample['RelevantDocuments']:\n",
    "        d_ent_list = rel_docs['dEntities']\n",
    "        \n",
    "        if len(d_ent_list) == 0:\n",
    "            train_d_0_ent_samples += 1\n",
    "\n",
    "        doc_text = tokenise( rel_docs['docText'] ).split()\n",
    "        \n",
    "        if len(doc_text) == 2:\n",
    "            train_d_2_word_samples += 1\n",
    "\n",
    "    \n",
    "print(\"0 Entities -> Query : \", train_q_0_ent_samples)\n",
    "print(\"0 Entities -> Doc   : \", train_d_0_ent_samples)\n",
    "print(\"1 Words    -> Query : \", train_q_1_word_samples)\n",
    "print(\"2 Words    -> Doc   : \", train_d_2_word_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-level",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-chicago",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-softball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-colombia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-syria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-cannon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-grave",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-gravity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
